{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import torch\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from metrics import evaluation_metrics\n",
    "\n",
    "from slim import SLIMDataModule\n",
    "import torch.nn as nn\n",
    "\n",
    "# Instantiate the DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to load ./data/hr_train.csv: 3.316359519958496 seconds\n",
      "Time taken to load ./data/lr_train.csv: 0.5543906688690186 seconds\n",
      "Converting vectors to matrices\n",
      "Converting vectors to matrices\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_module = SLIMDataModule(data_dir=\"./data\", batch_size=1)\n",
    "train_dataloader = data_module.train_dataloader()\n",
    "# Get first batch\n",
    "batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetric_normalize(A_tilde):\n",
    "    \"\"\"\n",
    "    Performs symmetric normalization of A_tilde (Adj. matrix with self loops):\n",
    "      A_norm = D^{-1/2} * A_tilde * D^{-1/2}\n",
    "    Where D_{ii} = sum of row i in A_tilde.\n",
    "\n",
    "    A_tilde (N, N): Adj. matrix with self loops\n",
    "    Returns:\n",
    "      A_norm : (N, N)\n",
    "    \"\"\"\n",
    "\n",
    "    eps = 1e-5\n",
    "    d = A_tilde.sum(dim=1) + eps\n",
    "    D_inv = torch.diag(torch.pow(d, -0.5))\n",
    "    return D_inv @ A_tilde @ D_inv\n",
    "\n",
    "\n",
    "def batch_normalize(batch):\n",
    "    batch_n = torch.zeros_like(batch)\n",
    "    for i, A in enumerate(batch):\n",
    "        batch_n[i] = symmetric_normalize(A + torch.eye(n=A.shape[0]))\n",
    "    return batch_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m optimizer\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m param_group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\n\u001b[0;32m----> 7\u001b[0m     model: \u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule,\n\u001b[1;32m      8\u001b[0m     train_dataloader: DataLoader,\n\u001b[1;32m      9\u001b[0m     val_dataloader: DataLoader,\n\u001b[1;32m     10\u001b[0m     train_node_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m     val_node_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     13\u001b[0m     lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m     14\u001b[0m     validate_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     15\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     16\u001b[0m     criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m     intermediate_losses\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m     skip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     19\u001b[0m ):\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    Train the model, validate every 'validate_every' epochs, and pick the\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    checkpoint with best validation accuracy.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m        The state dictionary of the model achieving the best validation accuracy.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group[\"lr\"]\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_dataloader: DataLoader,\n",
    "    val_dataloader: DataLoader,\n",
    "    train_node_features=None,\n",
    "    val_node_features=None,\n",
    "    num_epochs=100,\n",
    "    lr=0.01,\n",
    "    validate_every=1,\n",
    "    patience=10,\n",
    "    criterion=None,\n",
    "    intermediate_losses=False,\n",
    "    skip=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the model, validate every 'validate_every' epochs, and pick the\n",
    "    checkpoint with best validation accuracy.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : torch.nn.Module\n",
    "        The PyTorch model to train.\n",
    "    train_dataloader : torch.utils.data.DataLoader\n",
    "        DataLoader for the training set.\n",
    "    val_dataloader : torch.utils.data.DataLoader\n",
    "        DataLoader for the validation set.\n",
    "    num_epochs : int\n",
    "        Number of training epochs.\n",
    "    lr : float\n",
    "        Learning rate for the optimizer.\n",
    "    validate_every : int\n",
    "        Validate (and possibly checkpoint) every 'validate_every' epochs.\n",
    "    patience : int\n",
    "        Patience for learning rate scheduler.\n",
    "    criterion : torch.nn.Module\n",
    "        Loss function.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    best_loss_history : list\n",
    "        The training loss history across epochs.\n",
    "    best_model_state_dict : dict\n",
    "        The state dictionary of the model achieving the best validation accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", patience=patience\n",
    "    )\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    lr_history = []\n",
    "\n",
    "    best_val_loss = torch.inf\n",
    "    best_model_state_dict = None\n",
    "    val_loss = 0.0\n",
    "\n",
    "    progress_bar = tqdm(range(num_epochs))\n",
    "    for epoch in progress_bar:\n",
    "        progress_bar.set_description(f\"Epoch {epoch}|{num_epochs}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for i, batch in enumerate(train_dataloader):\n",
    "            inputs, targets = batch\n",
    "            # inputs = batch_normalize(inputs)\n",
    "            inputs = inputs.squeeze(0)\n",
    "            targets = targets.squeeze(0)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            X = train_node_features[i] if train_node_features is not None else None\n",
    "\n",
    "            # Forward pass on training data\n",
    "            outputs, A_hist, A_recon_hist = model.forward(A=inputs, X=X, skip=skip)\n",
    "            loss = criterion(\n",
    "                outputs,\n",
    "                targets.to(model.device),\n",
    "                A_hist,\n",
    "                A_recon_hist,\n",
    "                intermediate_losses=intermediate_losses,\n",
    "            )\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Record training loss\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(train_dataloader)\n",
    "        train_loss_history.append(avg_loss)\n",
    "\n",
    "        # Validation step\n",
    "        if (epoch + 1) % validate_every == 0 or (epoch + 1) == num_epochs:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for i, batch in enumerate(val_dataloader):\n",
    "                    inputs, targets = batch\n",
    "                    inputs = inputs.squeeze(0)\n",
    "                    targets = targets.squeeze(0)\n",
    "                    X = val_node_features[i] if val_node_features is not None else None\n",
    "                    outputs, A_hist, A_recon_hist = model(A=inputs, X=X, skip=skip)\n",
    "\n",
    "                    val_loss += criterion(\n",
    "                        outputs,\n",
    "                        targets.to(model.device),\n",
    "                        A_hist,\n",
    "                        A_recon_hist,\n",
    "                        intermediate_losses,\n",
    "                    ).item()\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            val_loss_history.append(val_loss)\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "            lr = get_lr(optimizer)\n",
    "            lr_history.append(lr)\n",
    "\n",
    "            # Check if this is the best f1 score so far\n",
    "            if val_loss > best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_state_dict = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            if lr < 1e-5:\n",
    "                break\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            {\"train_loss\": avg_loss, \"val_loss\": val_loss, \"lr\": lr}\n",
    "        )\n",
    "\n",
    "    # If we have a best model, load it\n",
    "    if best_model_state_dict is not None:\n",
    "        model.load_state_dict(best_model_state_dict)\n",
    "\n",
    "    return train_loss_history, val_loss_history, lr_history, best_model_state_dict\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, dataloader):\n",
    "    \"\"\"\n",
    "    Runs forward pass, calculates binary predictions (threshold=0.5),\n",
    "    and returns the accuracy score.\n",
    "    \"\"\"\n",
    "    from metrics import evaluation_metrics\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    true = []\n",
    "    for batch in dataloader:\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.squeeze(0)\n",
    "        targets = targets.squeeze(0)\n",
    "        inputs.to(model.device)\n",
    "        outputs, _, _ = model(inputs)\n",
    "        preds.append(outputs.detach().cpu().numpy())\n",
    "        true.append(targets.detach().cpu().numpy())\n",
    "\n",
    "    batch_metrics = evaluation_metrics(preds, true)\n",
    "\n",
    "    return batch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting it all together - code taken from https://github.com/HongyangGao/Graph-U-Nets/tree/master\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def reconstruct_adjacency(X, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Reconstruct adjacency from node embeddings while preserving fMRI-like structure.\n",
    "\n",
    "    Args:\n",
    "        X (torch.Tensor): Node embeddings of shape [num_nodes, hidden_dim]\n",
    "        threshold (float): Value below which edges are removed for sparsity\n",
    "\n",
    "    Returns:\n",
    "        adj (torch.Tensor): Reconstructed weighted adjacency matrix\n",
    "    \"\"\"\n",
    "    X_norm = X\n",
    "    # Compute cosine similarity matrix\n",
    "    adj = F.relu(X_norm @ X_norm.T)  # Values in range [-1, 1]\n",
    "\n",
    "    # adj = torch.sigmoid(adj)\n",
    "\n",
    "    # Apply sparsification: Keep only values above threshold\n",
    "    # adj = torch.where(adj > threshold, adj, torch.zeros_like(adj))\n",
    "\n",
    "    return adj\n",
    "\n",
    "\n",
    "class GraphUpsampler(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim,\n",
    "        hidden_dim,\n",
    "        n_nodes,\n",
    "        m_nodes,\n",
    "        act,\n",
    "        drop_p,\n",
    "        num_iterations=3,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - in_dim: Input node feature dimension\n",
    "        - hidden_dim: Hidden dimension for message passing\n",
    "        - num_iterations: Number of iterative updates\n",
    "        - upsample_factor: Factor by which to increase node count\n",
    "        \"\"\"\n",
    "        super(GraphUpsampler, self).__init__()\n",
    "        self.num_iterations = num_iterations\n",
    "        self.n_nodes = n_nodes\n",
    "        self.m_nodes = m_nodes\n",
    "\n",
    "        # Message passing layers\n",
    "        self.conv1 = GCN(in_dim, hidden_dim, act, drop_p)\n",
    "        self.conv2 = GCN(hidden_dim, hidden_dim, act, drop_p)\n",
    "\n",
    "        # MLP for new node generation\n",
    "        self.upsample_mlp = nn.Linear(n_nodes, m_nodes)\n",
    "\n",
    "    def forward(self, X, A, refine=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - x: Node features [num_nodes, in_dim]\n",
    "        - adj_matrix: Initial adjacency matrix [num_nodes, num_nodes]\n",
    "\n",
    "        Returns:\n",
    "        - Upsampled adjacency matrix [self.m_nodes, self.m_nodes]\n",
    "        - Upsampled node features [new_num_nodes, in_dim]\n",
    "        \"\"\"\n",
    "\n",
    "        # Generate new nodes by transforming existing ones\n",
    "        X_upsampled = torch.sigmoid(self.upsample_mlp(X.T).T)  # [num_nodes, in_dim]\n",
    "        # Concatenate old and new nodes\n",
    "\n",
    "        A_upsampled = reconstruct_adjacency(X=X_upsampled)\n",
    "\n",
    "        # Message passing to refine embeddings\n",
    "        if refine:\n",
    "            for _ in range(self.num_iterations):\n",
    "                X_upsampled = self.conv1(A_upsampled, X_upsampled)\n",
    "                X_upsampled = F.relu(X_upsampled)\n",
    "                A_upsampled = reconstruct_adjacency(X_upsampled)\n",
    "\n",
    "                X_upsampled = self.conv2(A_upsampled, X_upsampled)\n",
    "                X_upsampled = F.relu(X_upsampled)\n",
    "\n",
    "                # Reconstruct adjacency with updated embeddings\n",
    "                A_upsampled = reconstruct_adjacency(A_upsampled)\n",
    "\n",
    "        return A_upsampled\n",
    "\n",
    "\n",
    "class GraphUnet(nn.Module):\n",
    "\n",
    "    def __init__(self, ks, n_nodes, m_nodes, dim, act, drop_p):\n",
    "        super(GraphUnet, self).__init__()\n",
    "        self.ks = ks\n",
    "        self.dim = dim\n",
    "\n",
    "        self.down_gcns = nn.ModuleList()\n",
    "        self.up_gcns = nn.ModuleList()\n",
    "        self.pools = nn.ModuleList()\n",
    "        self.unpools = nn.ModuleList()\n",
    "        self.upsampler = GraphUpsampler(\n",
    "            in_dim=dim,\n",
    "            hidden_dim=dim,\n",
    "            n_nodes=n_nodes,\n",
    "            m_nodes=m_nodes,\n",
    "            act=act,\n",
    "            drop_p=drop_p,\n",
    "        )\n",
    "        self.l_n = len(ks)\n",
    "        for k in ks:\n",
    "            # out_dim = dim\n",
    "            out_dim = int(dim / k)\n",
    "            self.down_gcns.append(GCN(dim, out_dim, act, drop_p))\n",
    "            self.up_gcns.append(GCN(out_dim, dim, act, drop_p))\n",
    "            self.pools.append(Pool(k, out_dim, drop_p))\n",
    "            self.unpools.append(Unpool(dim, dim, drop_p))\n",
    "            dim = out_dim\n",
    "\n",
    "        self.up_gcns = self.up_gcns[::-1]\n",
    "        # self.node_features = nn.Parameter(torch.randn(n_nodes, dim))\n",
    "        self.bottom_gcn = GCN(dim, dim, act, drop_p)\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def build_batch_features(\n",
    "        self, batch: list[torch.Tensor], n_jobs: int = 1\n",
    "    ) -> torch.Tensor:\n",
    "        # Build batch features using topological information\n",
    "        from joblib import Parallel, delayed\n",
    "\n",
    "        # Use the build_node_features function to build features for each graph in the batch\n",
    "        features = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(self.build_node_features)(adjacency) for adjacency in batch\n",
    "        )\n",
    "        return torch.stack(features, dim=0)\n",
    "\n",
    "    def build_node_features(self, adjacency: torch.Tensor) -> torch.Tensor:\n",
    "        # Build node features using topological information\n",
    "\n",
    "        # Compute degree matrix\n",
    "        D = torch.diag(torch.sum(adjacency, dim=1)).cpu()\n",
    "\n",
    "        # Compute Node betweenness centrality\n",
    "        G = nx.from_numpy_array(adjacency.cpu().numpy())\n",
    "        betweenness = torch.tensor(\n",
    "            list(nx.betweenness_centrality(G).values()), dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        # Compute Node closeness centrality\n",
    "        closeness = torch.tensor(\n",
    "            list(nx.closeness_centrality(G).values()), dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        # Compute Node clustering coefficient\n",
    "        clustering = torch.tensor(list(nx.clustering(G).values()), dtype=torch.float32)\n",
    "\n",
    "        # Compute eigenvector centrality\n",
    "        eigenvector = torch.tensor(\n",
    "            list(nx.eigenvector_centrality(G).values()), dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        # Compute Laplacian eigenvecs\n",
    "        eigvals, eigvecs = torch.linalg.eigh(D - adjacency.cpu())\n",
    "        laplacian_eigenvecs = eigvecs[:, 1 : self.dim - 3]\n",
    "\n",
    "        # Concatenate all features\n",
    "        node_features = torch.stack(\n",
    "            [betweenness, closeness, clustering, eigenvector], dim=1\n",
    "        )\n",
    "        # Include Laplacian eigenvecs\n",
    "        node_features = torch.cat([node_features, laplacian_eigenvecs], dim=1)\n",
    "\n",
    "        return node_features\n",
    "\n",
    "    def forward(\n",
    "        self, A: torch.Tensor, skip: bool = False, threshold: float = -1, X=None\n",
    "    ):\n",
    "        # Process A\n",
    "        if threshold > 0:\n",
    "            A = torch.where(A > threshold, A, torch.zeros_like(A))\n",
    "        A = A + torch.eye(A.shape[0])\n",
    "        A = symmetric_normalize(A)\n",
    "        A = A.to(self.device)\n",
    "\n",
    "        if X is None:\n",
    "            X = torch.randn(A.shape[0], self.dim, device=self.device)\n",
    "        else:\n",
    "            X = X.to(self.device)\n",
    "\n",
    "        A_history = []\n",
    "        A_recon_history = []\n",
    "        indices_list = []\n",
    "        down_outs = []\n",
    "        org_A = A.clone()\n",
    "        if skip:\n",
    "            org_X = X.clone()\n",
    "        for i in range(self.l_n):\n",
    "            X = self.down_gcns[i](A, X)\n",
    "            A_history.append(A)\n",
    "            down_outs.append(X)\n",
    "            A, X, idx = self.pools[i](A, X)\n",
    "            indices_list.append(idx)\n",
    "\n",
    "        X = self.bottom_gcn(A, X)\n",
    "        for i in range(self.l_n):\n",
    "            up_idx = self.l_n - i - 1\n",
    "            A, idx = A_history[up_idx], indices_list[up_idx]\n",
    "            A, X = self.unpools[i](A, X, down_outs[up_idx], idx)\n",
    "            X = self.up_gcns[i](A, X)\n",
    "\n",
    "            A_recon = reconstruct_adjacency(X)\n",
    "            A_recon_history.append(A_recon)\n",
    "            if skip:\n",
    "\n",
    "                X = X.add(down_outs[up_idx])\n",
    "\n",
    "        if skip:\n",
    "            X = X.add(org_X)\n",
    "\n",
    "        A_upsampled = self.upsampler.forward(X, A)\n",
    "\n",
    "        return A_upsampled, A_history, A_recon_history\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, out_dim, act, p):\n",
    "        super(GCN, self).__init__()\n",
    "        self.proj = nn.Linear(in_dim, out_dim, bias=False)\n",
    "        self.act = act\n",
    "        self.drop = nn.Dropout(p=p) if p > 0.0 else nn.Identity()\n",
    "\n",
    "    def forward(self, A, X):\n",
    "        X = self.drop(X)  # they have added dropout\n",
    "        X = torch.matmul(A, X)\n",
    "        X = self.proj(X)\n",
    "        X = self.act(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "class Pool(nn.Module):\n",
    "\n",
    "    def __init__(self, k, in_dim, p):\n",
    "        super(Pool, self).__init__()\n",
    "        self.k = k\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.proj = nn.Linear(in_dim, 1)\n",
    "        self.drop = nn.Dropout(p=p) if p > 0 else nn.Identity()  # added dropout here\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        Z = self.drop(h)\n",
    "        weights = self.proj(Z).squeeze()\n",
    "        scores = self.sigmoid(weights)\n",
    "        return top_k_graph(scores, g, h, self.k)\n",
    "\n",
    "\n",
    "class Unpool(nn.Module):\n",
    "\n",
    "    def __init__(self, *args):\n",
    "        super(Unpool, self).__init__()\n",
    "\n",
    "    def forward(self, A, X, pre_h, idx):\n",
    "        new_h = X.new_zeros([A.shape[0], X.shape[1]])\n",
    "        new_h[idx] = X\n",
    "        return A, new_h\n",
    "\n",
    "\n",
    "def top_k_graph(scores, A, X, k):\n",
    "    num_nodes = A.shape[0]\n",
    "    values, idx = torch.topk(\n",
    "        scores, max(2, int(k * num_nodes))\n",
    "    )  # make sure k works based on number of current nodes\n",
    "    X_pooled = X[idx, :]\n",
    "    values = torch.unsqueeze(values, -1)\n",
    "    X_pooled = torch.mul(X_pooled, values)\n",
    "    A_treshold = torch.where(A > 0.10, torch.ones_like(A), torch.zeros_like(A))\n",
    "    A_pooled = A_treshold.bool().float()\n",
    "    A_pooled = (\n",
    "        torch.matmul(A_pooled, A_pooled).bool().float()\n",
    "    )  # second power to reduce chance of isolated nodes\n",
    "    A_pooled = A[idx, :]\n",
    "    A_pooled = A_pooled[:, idx]\n",
    "    A_pooled = symmetric_normalize(A_pooled)\n",
    "    return A_pooled, X_pooled, idx\n",
    "\n",
    "\n",
    "def symmetric_normalize(A_tilde):\n",
    "    \"\"\"\n",
    "    Performs symmetric normalization of A_tilde (Adj. matrix with self loops):\n",
    "      A_norm = D^{-1/2} * A_tilde * D^{-1/2}\n",
    "    Where D_{ii} = sum of row i in A_tilde.\n",
    "\n",
    "    A_tilde (N, N): Adj. matrix with self loops\n",
    "    Returns:\n",
    "      A_norm : (N, N)\n",
    "    \"\"\"\n",
    "\n",
    "    eps = 1e-5\n",
    "    d = A_tilde.sum(dim=1) + eps\n",
    "    D_inv = torch.diag(torch.pow(d, -0.5))\n",
    "    return D_inv @ A_tilde @ D_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(\n",
    "    A_true, A_pred, A_hist=None, A_recon_hist=None, intermediate_losses: bool = False\n",
    "):\n",
    "    loss = F.mse_loss(A_true, A_pred)\n",
    "    if intermediate_losses:\n",
    "        i = 1\n",
    "        for A, A_recon in zip(A_hist, A_recon_hist[::-1]):\n",
    "            loss += F.mse_loss(A, A_recon)\n",
    "            i += 1\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_loss(\n",
    "    A_true, A_pred, A_hist=None, A_recon_hist=None, intermediate_losses: bool = False\n",
    "):\n",
    "    loss = F.l1_loss(A_true, A_pred)\n",
    "    if intermediate_losses:\n",
    "        i = 1\n",
    "        for A, A_recon in zip(A_hist, A_recon_hist[::-1]):\n",
    "            loss += F.l1_loss(A, A_recon)\n",
    "            i += 1\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian_mse(\n",
    "    A_true, A_pred, A_hist=None, A_recon_hist=None, intermediate_losses: bool = False\n",
    "):\n",
    "    L_true = torch.diag(A_true.sum(dim=1)) - A_true\n",
    "    L_pred = torch.diag(A_pred.sum(dim=1)) - A_pred\n",
    "    loss = F.mse_loss(L_true, L_pred)\n",
    "    if intermediate_losses:\n",
    "        i = 1\n",
    "        for A, A_recon in zip(A_hist, A_recon_hist[::-1]):\n",
    "            L = torch.diag(A.sum(dim=1)) - A\n",
    "            L_recon = torch.diag(A_recon.sum(dim=1)) - A_recon\n",
    "            loss += F.mse_loss(L, L_recon)\n",
    "            i += 1\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_laplacian_mse(\n",
    "    A_true, A_pred, A_hist=None, A_recon_hist=None, intermediate_losses: bool = False\n",
    "):\n",
    "    loss = l1_loss(A_true, A_pred, A_hist, A_recon_hist, intermediate_losses)\n",
    "    loss += laplacian_mse(A_true, A_pred, A_hist, A_recon_hist, intermediate_losses)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphUnet(\n",
       "  (down_gcns): ModuleList(\n",
       "    (0): GCN(\n",
       "      (proj): Linear(in_features=15, out_features=20, bias=False)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): GCN(\n",
       "      (proj): Linear(in_features=20, out_features=26, bias=False)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): GCN(\n",
       "      (proj): Linear(in_features=26, out_features=34, bias=False)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (up_gcns): ModuleList(\n",
       "    (0): GCN(\n",
       "      (proj): Linear(in_features=34, out_features=26, bias=False)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): GCN(\n",
       "      (proj): Linear(in_features=26, out_features=20, bias=False)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): GCN(\n",
       "      (proj): Linear(in_features=20, out_features=15, bias=False)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (pools): ModuleList(\n",
       "    (0): Pool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=20, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): Pool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=26, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): Pool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=34, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (unpools): ModuleList(\n",
       "    (0-2): 3 x Unpool()\n",
       "  )\n",
       "  (upsampler): GraphUpsampler(\n",
       "    (conv1): GCN(\n",
       "      (proj): Linear(in_features=15, out_features=15, bias=False)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv2): GCN(\n",
       "      (proj): Linear(in_features=15, out_features=15, bias=False)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (upsample_mlp): Linear(in_features=160, out_features=268, bias=True)\n",
       "  )\n",
       "  (bottom_gcn): GCN(\n",
       "    (proj): Linear(in_features=34, out_features=34, bias=False)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model, loss function, and optimizer\n",
    "\n",
    "# Clear CUDA cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Define the model\n",
    "in_dim = batch[0].shape[1]\n",
    "out_dim = batch[1].shape[1]\n",
    "dim = 15\n",
    "model = GraphUnet(\n",
    "    ks=[\n",
    "        0.75,\n",
    "        0.75,\n",
    "        0.75,\n",
    "    ],\n",
    "    n_nodes=in_dim,\n",
    "    m_nodes=out_dim,\n",
    "    dim=dim,\n",
    "    act=torch.relu,\n",
    "    drop_p=0.1,\n",
    ")\n",
    "model.to(torch.device(\"cuda:2\"))\n",
    "# model.load_state_dict(torch.load(\"unet-26-02.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing train node features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [01:00<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing val node features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:15<00:00,  2.18it/s]\n",
      "100%|██████████| 112/112 [00:49<00:00,  2.26it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing train node features...\")\n",
    "train_node_features = [\n",
    "    model.build_node_features(A[0].squeeze(0))\n",
    "    for A in tqdm(data_module.train_dataloader())\n",
    "]\n",
    "\n",
    "print(\"Computing val node features...\")\n",
    "val_node_features = [\n",
    "    model.build_node_features(A[0].squeeze(0))\n",
    "    for A in tqdm(data_module.val_dataloader())\n",
    "]\n",
    "\n",
    "from slim import create_test_dataloader\n",
    "\n",
    "test_dataloader = create_test_dataloader(data_dir=\"./data\", batch_size=1)\n",
    "X_val = [model.build_node_features(A[0].squeeze(0)) for A in tqdm(test_dataloader)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89|200:  44%|████▍     | 89/200 [03:51<04:48,  2.60s/it, train_loss=2.27, val_loss=2.28]    \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_losses, val_losses, lr, _ = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=data_module.train_dataloader(),\n",
    "    val_dataloader=data_module.val_dataloader(),\n",
    "    train_node_features=train_node_features,\n",
    "    val_node_features=val_node_features,\n",
    "    num_epochs=200,\n",
    "    lr=2e-4,\n",
    "    validate_every=1,\n",
    "    patience=5,\n",
    "    criterion=l1_laplacian_mse,\n",
    "    intermediate_losses=True,\n",
    "    skip=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_losses, val_losses, lr=None, title=\"Losses\", log: bool = False):\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label=\"Train Loss\")\n",
    "    plt.plot(val_losses, label=\"Val Loss\")\n",
    "    if lr:\n",
    "        plt.plot(lr, label=\"Learning Rate\")\n",
    "    if log:\n",
    "        plt.yscale(\"log\")\n",
    "        plt.ylabel(\"Loss (logscale)\")\n",
    "    else:\n",
    "        plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(\n",
    "    train_losses=train_losses,\n",
    "    val_losses=val_losses,\n",
    "    log=True,\n",
    "    title=\"Losses (UNet, 3 down, 3 up, hidden dim 15)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MatrixVectorizer import MatrixVectorizer\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "def evaluation_metrics(pred, true, print: bool = False, n_jobs=1):\n",
    "\n",
    "    def compute_metrics(i):\n",
    "        # Convert adjacency matrices to NetworkX graphs\n",
    "        pred_graph = nx.from_numpy_array(pred[i], edge_attr=\"weight\")\n",
    "        gt_graph = nx.from_numpy_array(true[i], edge_attr=\"weight\")\n",
    "\n",
    "        # Compute centrality measures\n",
    "        pred_bc = nx.betweenness_centrality(pred_graph, weight=\"weight\")\n",
    "        pred_ec = nx.eigenvector_centrality(pred_graph, weight=\"weight\")\n",
    "        pred_pc = nx.pagerank(pred_graph, weight=\"weight\")\n",
    "\n",
    "        gt_bc = nx.betweenness_centrality(gt_graph, weight=\"weight\")\n",
    "        gt_ec = nx.eigenvector_centrality(gt_graph, weight=\"weight\")\n",
    "        gt_pc = nx.pagerank(gt_graph, weight=\"weight\")\n",
    "\n",
    "        # Convert centrality dictionaries to lists\n",
    "        pred_bc_values = list(pred_bc.values())\n",
    "        pred_ec_values = list(pred_ec.values())\n",
    "        pred_pc_values = list(pred_pc.values())\n",
    "\n",
    "        gt_bc_values = list(gt_bc.values())\n",
    "        gt_ec_values = list(gt_ec.values())\n",
    "        gt_pc_values = list(gt_pc.values())\n",
    "\n",
    "        # Compute MAEs\n",
    "        mae_bc = mean_absolute_error(pred_bc_values, gt_bc_values)\n",
    "        mae_ec = mean_absolute_error(pred_ec_values, gt_ec_values)\n",
    "        mae_pc = mean_absolute_error(pred_pc_values, gt_pc_values)\n",
    "\n",
    "        # Vectorize matrices\n",
    "        pred_1d = MatrixVectorizer.vectorize(pred[i])\n",
    "        gt_1d = MatrixVectorizer.vectorize(true[i])\n",
    "\n",
    "        return mae_bc, mae_ec, mae_pc, pred_1d, gt_1d\n",
    "\n",
    "    mae_bc = []\n",
    "    mae_ec = []\n",
    "    mae_pc = []\n",
    "\n",
    "    pred_1d_list = []\n",
    "    gt_1d_list = []\n",
    "\n",
    "    num_test_samples = len(pred)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=n_jobs) as executor:\n",
    "        results = list(executor.map(compute_metrics, range(num_test_samples)))\n",
    "\n",
    "    for result in results:\n",
    "        mae_bc.append(result[0])\n",
    "        mae_ec.append(result[1])\n",
    "        mae_pc.append(result[2])\n",
    "        pred_1d_list.append(result[3])\n",
    "        gt_1d_list.append(result[4])\n",
    "\n",
    "    # Compute average MAEs\n",
    "    avg_mae_bc = sum(mae_bc) / len(mae_bc)\n",
    "    avg_mae_ec = sum(mae_ec) / len(mae_ec)\n",
    "    avg_mae_pc = sum(mae_pc) / len(mae_pc)\n",
    "\n",
    "    # Concatenate flattened matrices\n",
    "    pred_1d = np.concatenate(pred_1d_list)\n",
    "    gt_1d = np.concatenate(gt_1d_list)\n",
    "\n",
    "    # Compute metrics\n",
    "    mae = mean_absolute_error(pred_1d, gt_1d)\n",
    "    pcc = pearsonr(pred_1d, gt_1d)[0]\n",
    "    js_dis = jensenshannon(pred_1d, gt_1d)\n",
    "\n",
    "    if print:\n",
    "        print(\"MAE: \", mae)\n",
    "        print(\"PCC: \", pcc)\n",
    "        print(\"Jensen-Shannon Distance: \", js_dis)\n",
    "        print(\"Average MAE betweenness centrality:\", avg_mae_bc)\n",
    "        print(\"Average MAE eigenvector centrality:\", avg_mae_ec)\n",
    "        print(\"Average MAE PageRank centrality:\", avg_mae_pc)\n",
    "\n",
    "    return {\n",
    "        \"mae\": mae,\n",
    "        \"pcc\": pcc,\n",
    "        \"js_dis\": js_dis,\n",
    "        \"avg_mae_bc\": avg_mae_bc,\n",
    "        \"avg_mae_ec\": avg_mae_ec,\n",
    "        \"avg_mae_pc\": avg_mae_pc,\n",
    "    }\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, dataloader, X_val=None, n_jobs=1):\n",
    "    \"\"\"\n",
    "    Runs forward pass, calculates binary predictions (threshold=0.5),\n",
    "    and returns the accuracy score.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    true = []\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    progress_bar.set_description(\"Evaluating...\")\n",
    "    for i, batch in progress_bar:\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.squeeze(0)\n",
    "        targets = targets.squeeze(0)\n",
    "        inputs.to(model.device)\n",
    "        if X_val is not None:\n",
    "            X = X_val[i]\n",
    "        else:\n",
    "            X = None\n",
    "        outputs, _, _ = model(A=inputs, X=X)\n",
    "        preds.append(outputs.detach().cpu().numpy())\n",
    "        true.append(targets.detach().cpu().numpy())\n",
    "\n",
    "    batch_metrics = evaluation_metrics(preds, true, n_jobs=n_jobs)\n",
    "    # Convert to python float\n",
    "    batch_metrics = {k: float(v) for k, v in batch_metrics.items()}\n",
    "\n",
    "    return batch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|██████████| 34/34 [00:00<00:00, 144.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae': 0.17186230421066284, 'pcc': 0.3703899383544922, 'js_dis': 0.3485758602619171, 'avg_mae_bc': 0.019158734131003788, 'avg_mae_ec': 0.014677770285368565, 'avg_mae_pc': 0.0005654893157475034}\n"
     ]
    }
   ],
   "source": [
    "## Evaluation metrics\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "\n",
    "eval_metrics = evaluate_model(\n",
    "    model,\n",
    "    data_module.val_dataloader(),\n",
    "    X_val=val_node_features,\n",
    ")\n",
    "\n",
    "print(eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"outputs/unet/eval_metrics-27-02.json\", \"w\") as f:\n",
    "    json.dump({k: float(v) for k, v in eval_metrics.items()}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MatrixVectorizer import MatrixVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, dataloader, X_test=None):\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    progress_bar.set_description(\"Predicting...\")\n",
    "    for i, batch in progress_bar:\n",
    "\n",
    "        inputs = batch.squeeze(0)\n",
    "        inputs.to(model.device)\n",
    "        X = X_test[i] if X_test is not None else None\n",
    "        outputs, _, _ = model(inputs, X=X)\n",
    "        preds.append(outputs.detach().cpu().numpy())\n",
    "\n",
    "    # Vectorize matrices\n",
    "    preds = [MatrixVectorizer.vectorize(p) for p in preds]\n",
    "    preds = np.array(preds)\n",
    "\n",
    "    # Submission format\n",
    "    print(preds.shape)\n",
    "    submission_df = pd.DataFrame(\n",
    "        {\"ID\": range(1, len(preds.flatten()) + 1), \"Predicted\": preds.flatten()}\n",
    "    )\n",
    "    submission_df.to_csv(\"outputs/unet/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 112/112 [00:00<00:00, 240.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 35778)\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import slim\n",
    "\n",
    "importlib.reload(slim)\n",
    "\n",
    "\n",
    "predict(model, test_dataloader, X_test=X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.280145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.308506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.279578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.273571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.248254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007131</th>\n",
       "      <td>4007132</td>\n",
       "      <td>0.159210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007132</th>\n",
       "      <td>4007133</td>\n",
       "      <td>0.083816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007133</th>\n",
       "      <td>4007134</td>\n",
       "      <td>0.151342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007134</th>\n",
       "      <td>4007135</td>\n",
       "      <td>0.066043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007135</th>\n",
       "      <td>4007136</td>\n",
       "      <td>0.096740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4007136 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID  Predicted\n",
       "0              1   0.280145\n",
       "1              2   0.308506\n",
       "2              3   0.279578\n",
       "3              4   0.273571\n",
       "4              5   0.248254\n",
       "...          ...        ...\n",
       "4007131  4007132   0.159210\n",
       "4007132  4007133   0.083816\n",
       "4007133  4007134   0.151342\n",
       "4007134  4007135   0.066043\n",
       "4007135  4007136   0.096740\n",
       "\n",
       "[4007136 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"outputs/unet/submission.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 70.6M/70.6M [00:02<00:00, 28.0MB/s]\n",
      "Successfully submitted to DGL 2025: Brain Graph Super-Resolution Challenge"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c dgl-2025-brain-graph-super-resolution-challenge -f outputs/unet/submission.csv -m \"UNet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"outputs/unet/unet-27-02.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
