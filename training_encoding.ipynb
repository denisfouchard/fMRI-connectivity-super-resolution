{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T00:06:48.775872Z",
     "start_time": "2025-03-02T00:06:45.364490Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" \n",
    "\n",
    "\n",
    "import torch_geometric\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, TopKPooling, global_mean_pool, GraphUNet\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from utils.data import GraphDataModule, save_prediction\n",
    "from utils.training import train_model\n",
    "from utils.metrics import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d3a6ae3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T00:07:13.123356Z",
     "start_time": "2025-03-02T00:07:13.109763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e34fa3e9ebc9bb47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T00:07:20.093551Z",
     "start_time": "2025-03-02T00:07:15.538182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to load ./data/hr_train.csv: 4.006866455078125 seconds\n",
      "Time taken to load ./data/lr_train.csv: 0.5768356323242188 seconds\n",
      "Time taken to load ./data/lr_test.csv: 0.42595481872558594 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting vectors to graphs: 100%|██████████| 133/133 [00:00<00:00, 297.42it/s]\n",
      "Converting vectors to graphs: 100%|██████████| 34/34 [00:00<00:00, 284.22it/s]\n",
      "Converting vectors to graphs: 100%|██████████| 112/112 [00:00<00:00, 763.68it/s]\n"
     ]
    }
   ],
   "source": [
    "data_module = GraphDataModule(\"./data\", num_workers=1, batch_size=1)\n",
    "train_loader = data_module.self_train_dataloader()\n",
    "val_loader = data_module.self_val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "334b874b7023c51b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T00:26:47.945049Z",
     "start_time": "2025-03-02T00:26:47.934746Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn import Linear, BatchNorm1d, Dropout, TransformerEncoder, TransformerEncoderLayer\n",
    "from torch_geometric.nn import GATConv, GCNConv, GINConv, global_add_pool\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "\n",
    "class TopologyAwareGNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=3, dropout=0.2):\n",
    "        super(TopologyAwareGNN, self).__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "        self.lns = nn.ModuleList()\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # First layer with GCN for local neighborhood aggregation\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels, add_self_loops=True, normalize=True))\n",
    "        self.lns.append(Linear(hidden_channels+in_channels, hidden_channels))\n",
    "        self.bns.append(BatchNorm1d(hidden_channels))\n",
    "        \n",
    "        # Middle layers with GAT for capturing node importance\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GCNConv(hidden_channels, hidden_channels, add_self_loops=True, normalize=True ))\n",
    "            self.lns.append(Linear(2*hidden_channels, hidden_channels))\n",
    "            self.bns.append(BatchNorm1d(hidden_channels))\n",
    "        \n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x = batch.x\n",
    "        edge_index, edge_weight = add_self_loops(batch.edge_index, num_nodes=batch.num_nodes, fill_value=1.0)\n",
    "\n",
    "        for conv, ln, bn in zip(self.convs, self.lns, self.bns):\n",
    "            x2 = conv(x, edge_index, edge_weight)\n",
    "            x = torch.concat((x, x2), dim=1)\n",
    "            x = ln(x)\n",
    "            x = bn(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UpscalerGNN(nn.Module):\n",
    "    def __init__(self, input_features, hidden_nodes, out_channels, attention_dim):\n",
    "        super().__init__()\n",
    "        self.input_nodes = 160\n",
    "        self.output_nodes = 160\n",
    "        \n",
    "        self.layer1 = TopologyAwareGNN(input_features, 2*hidden_nodes, out_channels)\n",
    "        # self.layer2 = nn.Linear(self.output_nodes-self.input_nodes, out_channels)\n",
    "\n",
    "        encoder_layer = TransformerEncoderLayer(d_model=out_channels, nhead=8)\n",
    "        self.transformer = TransformerEncoder(encoder_layer, num_layers=3)\n",
    "                \n",
    "        self.key = nn.Linear(out_channels, attention_dim)\n",
    "        self.query = nn.Linear(out_channels, attention_dim)\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def forward(self, samples: Batch):\n",
    "        X1 = self.layer1(samples)\n",
    "                \n",
    "        X2 = torch.eye(self.output_nodes-self.input_nodes).to(self.device)\n",
    "        # X2 = self.layer2(X2)\n",
    "           \n",
    "        # X = torch.concat((X1, X2), dim=0)\n",
    "        X = X1\n",
    "        X = self.transformer(X.unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "        K = self.key(X)\n",
    "        Q = self.query(X)\n",
    "        A = K @ Q.transpose(-1, -2)\n",
    "        A = F.sigmoid(A)\n",
    "        A = A.unsqueeze(0)\n",
    "        \n",
    "        return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5c15b0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T00:26:48.537483Z",
     "start_time": "2025-03-02T00:26:48.530222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 160 160\n"
     ]
    }
   ],
   "source": [
    "batch,target_batch = next(iter(train_loader))\n",
    "input_dim = batch[0].x.shape[0]\n",
    "output_dim = target_batch[0].x.shape[0]\n",
    "input_features = batch[0].x.shape[1]\n",
    "print(input_features,input_dim,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6cd7ae3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T00:26:49.520888Z",
     "start_time": "2025-03-02T00:26:49.507098Z"
    }
   },
   "outputs": [],
   "source": [
    "model = UpscalerGNN(\n",
    "    input_features=input_features,\n",
    "    hidden_nodes=128, \n",
    "    out_channels=64, \n",
    "    attention_dim=16\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60478db46877fe03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T00:27:12.555892200Z",
     "start_time": "2025-03-02T00:26:51.150648Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [01:07<01:37,  1.65s/it, train_loss=0.0354, val_loss=0.0407, lr=1e-5]  \n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_loss_history, val_loss_history, lr_history, best_model_state_dict = train_model(\n",
    "    model=model, \n",
    "    train_dataloader=train_loader, \n",
    "    val_dataloader=val_loader,\n",
    "    criterion=criterion,\n",
    "    num_epochs=100,\n",
    "    lr=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96cfee88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T00:12:05.873778Z",
     "start_time": "2025-03-02T00:12:05.689368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16056694\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(best_model_state_dict)\n",
    "loss = evaluate_model(model, val_loader)\n",
    "print(loss)\n",
    "\n",
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "737d15d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loss_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtrain_loss_history\u001b[49m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loss_history' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(train_loss_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c22f927",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"model.pth\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "914e84d0f1dba99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = data_module.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f14c7a044c71f324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 0)\n"
     ]
    }
   ],
   "source": [
    "submission_file = \"outputs/test/submission.csv\"\n",
    "save_prediction(model, test_dataloader, submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f2efd30d9c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab8416213942339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle competitions submit -c dgl-2025-brain-graph-super-resolution-challenge -f outputs/test/submission.csv -m \"test\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
