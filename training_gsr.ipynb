{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T18:08:17.101640Z",
     "start_time": "2025-03-11T18:08:15.711083Z"
    }
   },
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T18:08:19.241303Z",
     "start_time": "2025-03-11T18:08:18.517214Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from utils.preprocessing import *\n",
    "from models.gsr_model import GSRNet\n",
    "from utils.gsr_train import train, test\n",
    "from models.ops import GraphUnet\n"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'layers'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptim\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01moptim\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpreprocessing\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgsr_model\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m GSRNet\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgsr_train\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m train, test\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m GraphUnet\n",
      "File \u001B[1;32m~\\Documents\\Imperial\\DGL\\CW2\\models\\gsr_model.py:3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mlayers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpreprocessing\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m normalize_adj_torch\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'layers'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define model arguments\n",
    "class Args:\n",
    "    epochs = 200\n",
    "    lr = 0.0001\n",
    "    splits = 5\n",
    "    lmbda = 16\n",
    "    lr_dim = 160\n",
    "    hr_dim = 268  # Adapted for dataset\n",
    "    hidden_dim = 268\n",
    "    padding = 0  # No padding\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Load dataset\n",
    "subjects_adj, subjects_labels, test_adj = data()\n",
    "\n",
    "# Cross-validation split\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=args.splits, shuffle=True, random_state=42)\n",
    "\n",
    "ks = [0.9, 0.7, 0.6, 0.5]  # Pooling rates\n",
    "model = GSRNet(ks, args).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.5674083564514505, Error (MAE): 0.23988297592876548\n",
      "Epoch: 2, Loss: 1.244831723378117, Error (MAE): 0.20391422835059633\n",
      "Epoch: 3, Loss: 1.0981995736745964, Error (MAE): 0.19760659583529136\n",
      "Epoch: 4, Loss: 1.0179410043515658, Error (MAE): 0.1955843179073549\n",
      "Epoch: 5, Loss: 0.9718425704124278, Error (MAE): 0.19449561285345177\n",
      "Epoch: 6, Loss: 0.9429309901438261, Error (MAE): 0.19360809252226263\n",
      "Epoch: 7, Loss: 0.9229554870074853, Error (MAE): 0.1928677919663881\n",
      "Epoch: 8, Loss: 0.9082591242359993, Error (MAE): 0.19220534919347979\n",
      "Epoch: 9, Loss: 0.895342242897005, Error (MAE): 0.1916287592927316\n",
      "Epoch: 10, Loss: 0.883061923478779, Error (MAE): 0.19112721679354072\n",
      "Epoch: 11, Loss: 0.8711485741730023, Error (MAE): 0.19066869540322096\n",
      "Epoch: 12, Loss: 0.8596598362564144, Error (MAE): 0.19026086641881698\n",
      "Epoch: 13, Loss: 0.8478992025655016, Error (MAE): 0.18990123395184824\n",
      "Epoch: 14, Loss: 0.8366044248853411, Error (MAE): 0.18957540628157163\n",
      "Epoch: 15, Loss: 0.8254556445250834, Error (MAE): 0.18928182001848867\n",
      "Epoch: 16, Loss: 0.8145291747007155, Error (MAE): 0.1890167787783128\n",
      "Epoch: 17, Loss: 0.8036417580188665, Error (MAE): 0.18877588234897844\n",
      "Epoch: 18, Loss: 0.7929816263958924, Error (MAE): 0.18855499963563188\n",
      "Epoch: 19, Loss: 0.7824798271172029, Error (MAE): 0.18835403081169702\n",
      "Epoch: 20, Loss: 0.7725857765154731, Error (MAE): 0.18816892477802763\n",
      "Epoch: 21, Loss: 0.7621281635492367, Error (MAE): 0.1879977940168596\n",
      "Epoch: 22, Loss: 0.7520606163749122, Error (MAE): 0.1878365101222705\n",
      "Epoch: 23, Loss: 0.7423042399542672, Error (MAE): 0.18768484699994997\n",
      "Epoch: 24, Loss: 0.7326510409663495, Error (MAE): 0.18754310256108306\n",
      "Epoch: 25, Loss: 0.7232927948908698, Error (MAE): 0.1874120326194548\n",
      "Epoch: 26, Loss: 0.7136026360934838, Error (MAE): 0.18728461592717277\n",
      "Epoch: 27, Loss: 0.704183680670602, Error (MAE): 0.187168394824616\n",
      "Epoch: 28, Loss: 0.6950098773590604, Error (MAE): 0.18705823972709196\n",
      "Epoch: 29, Loss: 0.6862481415719914, Error (MAE): 0.18695782427500962\n",
      "Epoch: 30, Loss: 0.6771511269691295, Error (MAE): 0.18685965553710335\n",
      "Epoch: 31, Loss: 0.6686587387457826, Error (MAE): 0.18677112908291638\n",
      "Epoch: 32, Loss: 0.6596598799963643, Error (MAE): 0.1866879747774368\n",
      "Epoch: 33, Loss: 0.6513963364120713, Error (MAE): 0.18660637389000198\n",
      "Epoch: 34, Loss: 0.6429198769698465, Error (MAE): 0.18653443265230135\n",
      "Epoch: 35, Loss: 0.6347667763107702, Error (MAE): 0.18646674373544248\n",
      "Epoch: 36, Loss: 0.6264533768022867, Error (MAE): 0.18640068285447314\n",
      "Epoch: 37, Loss: 0.6186247992336302, Error (MAE): 0.18634094085012162\n",
      "Epoch: 38, Loss: 0.6106929747681868, Error (MAE): 0.18628344063023874\n",
      "Epoch: 39, Loss: 0.6032656565644687, Error (MAE): 0.18623288883302444\n",
      "Epoch: 40, Loss: 0.5955330908746648, Error (MAE): 0.18618275583686686\n",
      "Epoch: 41, Loss: 0.5882349619291779, Error (MAE): 0.18613767724736294\n",
      "Epoch: 42, Loss: 0.5806660333970436, Error (MAE): 0.18609531974433957\n",
      "Epoch: 43, Loss: 0.5733800682806431, Error (MAE): 0.18605387726224454\n",
      "Epoch: 44, Loss: 0.5662951908613506, Error (MAE): 0.18601351248142414\n",
      "Epoch: 45, Loss: 0.5592730215617588, Error (MAE): 0.18597726086924846\n",
      "Epoch: 46, Loss: 0.5523304137072169, Error (MAE): 0.1859433329419086\n",
      "Epoch: 47, Loss: 0.545490296711599, Error (MAE): 0.18591065660007017\n",
      "Epoch: 48, Loss: 0.5388737285047546, Error (MAE): 0.18587894603273922\n",
      "Epoch: 49, Loss: 0.5323326112632465, Error (MAE): 0.1858489836068978\n",
      "Epoch: 50, Loss: 0.5259522027090976, Error (MAE): 0.18581920626916384\n",
      "Epoch: 51, Loss: 0.5197859845663372, Error (MAE): 0.18579445499226563\n",
      "Epoch: 52, Loss: 0.5133522773595681, Error (MAE): 0.1857705030002092\n",
      "Epoch: 53, Loss: 0.507296328481875, Error (MAE): 0.18574675133353785\n",
      "Epoch: 54, Loss: 0.501340646716885, Error (MAE): 0.18572542183381274\n",
      "Epoch: 55, Loss: 0.49537264718148943, Error (MAE): 0.18570159084366678\n",
      "Epoch: 56, Loss: 0.48963079058138054, Error (MAE): 0.18568144066441328\n",
      "Epoch: 57, Loss: 0.48388837154646563, Error (MAE): 0.18566101778270608\n",
      "Epoch: 58, Loss: 0.47848616103480635, Error (MAE): 0.1856416620706257\n",
      "Epoch: 59, Loss: 0.472817749905407, Error (MAE): 0.18562400296218412\n",
      "Epoch: 60, Loss: 0.4675768676557039, Error (MAE): 0.18560509652571572\n",
      "Epoch: 61, Loss: 0.4621732929595431, Error (MAE): 0.18558941434200546\n",
      "Epoch: 62, Loss: 0.457010658387851, Error (MAE): 0.18557439352336683\n",
      "Epoch: 63, Loss: 0.4520593798698339, Error (MAE): 0.18555858552007748\n",
      "Epoch: 64, Loss: 0.4469420031497353, Error (MAE): 0.185542434005809\n",
      "Epoch: 65, Loss: 0.4420525738619324, Error (MAE): 0.18552827151646292\n",
      "Epoch: 66, Loss: 0.4371620127581116, Error (MAE): 0.18551442441635563\n",
      "Epoch: 67, Loss: 0.4324671982374406, Error (MAE): 0.18550250707264232\n",
      "Epoch: 68, Loss: 0.4277514297711222, Error (MAE): 0.18548811355927833\n",
      "Epoch: 69, Loss: 0.42322507791949393, Error (MAE): 0.18547528399560684\n",
      "Epoch: 70, Loss: 0.4188167869596553, Error (MAE): 0.1854625845089891\n",
      "Epoch: 71, Loss: 0.41444516473246695, Error (MAE): 0.18544926219864896\n",
      "Epoch: 72, Loss: 0.4100784643700248, Error (MAE): 0.1854384301748491\n",
      "Epoch: 73, Loss: 0.4059504440852574, Error (MAE): 0.18542874542842233\n",
      "Epoch: 74, Loss: 0.40186359828576107, Error (MAE): 0.1854134668084912\n",
      "Epoch: 75, Loss: 0.397879864040174, Error (MAE): 0.18540577568057784\n",
      "Epoch: 76, Loss: 0.3939253450336313, Error (MAE): 0.18539813586643764\n",
      "Epoch: 77, Loss: 0.3900951819312304, Error (MAE): 0.18538533050314823\n",
      "Epoch: 78, Loss: 0.3861499923960607, Error (MAE): 0.1853753040383633\n",
      "Epoch: 79, Loss: 0.38246544254453557, Error (MAE): 0.18536509002061716\n",
      "Epoch: 80, Loss: 0.3789084011450746, Error (MAE): 0.18535539126933964\n",
      "Epoch: 81, Loss: 0.37537367518683123, Error (MAE): 0.1853439303717219\n",
      "Epoch: 82, Loss: 0.37181971911200906, Error (MAE): 0.1853360692809399\n",
      "Epoch: 83, Loss: 0.36843245594125046, Error (MAE): 0.18532942123431012\n",
      "Epoch: 84, Loss: 0.36512789219841923, Error (MAE): 0.18532086001302964\n",
      "Epoch: 85, Loss: 0.3618087580329494, Error (MAE): 0.18531114243923275\n",
      "Epoch: 86, Loss: 0.3586555145736924, Error (MAE): 0.18530323149118208\n",
      "Epoch: 87, Loss: 0.35556406118816003, Error (MAE): 0.18529526810897023\n",
      "Epoch: 88, Loss: 0.35243497598440127, Error (MAE): 0.18528752925252556\n",
      "Epoch: 89, Loss: 0.3494632575744973, Error (MAE): 0.1852784296847824\n",
      "Epoch: 90, Loss: 0.3465956238875712, Error (MAE): 0.18527174735427798\n",
      "Epoch: 91, Loss: 0.3437502216127582, Error (MAE): 0.18526332158791392\n",
      "Epoch: 92, Loss: 0.341063852597, Error (MAE): 0.18525606203348116\n",
      "Epoch: 93, Loss: 0.3382844201156071, Error (MAE): 0.1852484720766096\n",
      "Epoch: 94, Loss: 0.33563307218981864, Error (MAE): 0.18524231397567836\n",
      "Epoch: 95, Loss: 0.3330077730623403, Error (MAE): 0.18523347232126652\n",
      "Epoch: 96, Loss: 0.33046587136455047, Error (MAE): 0.1852270694155442\n",
      "Epoch: 97, Loss: 0.32808903576736165, Error (MAE): 0.18522155576182486\n",
      "Epoch: 98, Loss: 0.32561915082142767, Error (MAE): 0.1852140834456996\n",
      "Epoch: 99, Loss: 0.32326758378430415, Error (MAE): 0.18520562317138328\n",
      "Epoch: 100, Loss: 0.32104478249872537, Error (MAE): 0.18520162853979527\n",
      "Epoch: 101, Loss: 0.31873615366175656, Error (MAE): 0.18519088435441927\n",
      "Epoch: 102, Loss: 0.3165587271962847, Error (MAE): 0.18518683415158352\n",
      "Epoch: 103, Loss: 0.31449146154231594, Error (MAE): 0.18517955812744627\n",
      "Epoch: 104, Loss: 0.31232890307455136, Error (MAE): 0.185173467025721\n",
      "Epoch: 105, Loss: 0.31030665304427757, Error (MAE): 0.18517108933818072\n",
      "Epoch: 106, Loss: 0.3083433905490359, Error (MAE): 0.18516447557542556\n",
      "Epoch: 107, Loss: 0.3064032149942298, Error (MAE): 0.18515704740258984\n",
      "Epoch: 108, Loss: 0.3045052036755067, Error (MAE): 0.18515111237092124\n",
      "Epoch: 109, Loss: 0.30280063900732457, Error (MAE): 0.18514643620727653\n",
      "Epoch: 110, Loss: 0.30097723096833195, Error (MAE): 0.18513990412081094\n",
      "Epoch: 111, Loss: 0.2991079114433518, Error (MAE): 0.18513406477028266\n",
      "Epoch: 112, Loss: 0.29747945137490006, Error (MAE): 0.18512784247111558\n",
      "Epoch: 113, Loss: 0.2957485938878884, Error (MAE): 0.18511748358719332\n",
      "Epoch: 114, Loss: 0.29416568991833164, Error (MAE): 0.18511463768948289\n",
      "Epoch: 115, Loss: 0.2925115113419698, Error (MAE): 0.18510708313687405\n",
      "Epoch: 116, Loss: 0.2910182473802925, Error (MAE): 0.18510125465410993\n",
      "Epoch: 117, Loss: 0.2896603108348703, Error (MAE): 0.18509040022254886\n",
      "Epoch: 118, Loss: 0.2880805123569374, Error (MAE): 0.1850865133722922\n",
      "Epoch: 119, Loss: 0.2866810667783694, Error (MAE): 0.18507980616917288\n",
      "Epoch: 120, Loss: 0.2853754554924212, Error (MAE): 0.1850732611982446\n",
      "Epoch: 121, Loss: 0.2839460565631551, Error (MAE): 0.18506585700171335\n",
      "Epoch: 122, Loss: 0.2826903083718809, Error (MAE): 0.1850577658952627\n",
      "Epoch: 123, Loss: 0.281433323720344, Error (MAE): 0.18505098922808366\n",
      "Epoch: 124, Loss: 0.28020766556711124, Error (MAE): 0.18504332823860914\n",
      "Epoch: 125, Loss: 0.2790229266747496, Error (MAE): 0.1850370993291525\n",
      "Epoch: 126, Loss: 0.2777546504162308, Error (MAE): 0.18502690144499442\n",
      "Epoch: 127, Loss: 0.27669292184195127, Error (MAE): 0.18502017026557063\n",
      "Epoch: 128, Loss: 0.27562105834932255, Error (MAE): 0.18501180320754088\n",
      "Epoch: 129, Loss: 0.2745130287301272, Error (MAE): 0.18500517241488723\n",
      "Epoch: 130, Loss: 0.27346825521243245, Error (MAE): 0.18499772138613507\n",
      "Epoch: 131, Loss: 0.2725957310513446, Error (MAE): 0.18498930290229337\n",
      "Epoch: 132, Loss: 0.27151534947237577, Error (MAE): 0.18498097696250543\n",
      "Epoch: 133, Loss: 0.27056046222385605, Error (MAE): 0.18497150217680106\n",
      "Epoch: 134, Loss: 0.26963538603675097, Error (MAE): 0.1849627383893594\n",
      "Epoch: 135, Loss: 0.2687510788664782, Error (MAE): 0.1849559062629714\n",
      "Epoch: 136, Loss: 0.2677996900296749, Error (MAE): 0.18494649690792972\n",
      "Epoch: 137, Loss: 0.26696142128535677, Error (MAE): 0.1849396394607716\n",
      "Epoch: 138, Loss: 0.26615306354106816, Error (MAE): 0.18492807974492698\n",
      "Epoch: 139, Loss: 0.2653679205734927, Error (MAE): 0.1849193086749629\n",
      "Epoch: 140, Loss: 0.2645469388567415, Error (MAE): 0.18491335784582266\n",
      "Epoch: 141, Loss: 0.2638619331488932, Error (MAE): 0.18490097531698702\n",
      "Epoch: 142, Loss: 0.26309354065504287, Error (MAE): 0.1848918280207125\n",
      "Epoch: 143, Loss: 0.26234810950612664, Error (MAE): 0.18488029082466786\n",
      "Epoch: 144, Loss: 0.2616129801013416, Error (MAE): 0.1848705270908829\n",
      "Epoch: 145, Loss: 0.2609603158513406, Error (MAE): 0.18486107471293972\n",
      "Epoch: 146, Loss: 0.26026197517276706, Error (MAE): 0.18485224359017566\n",
      "Epoch: 147, Loss: 0.25962122882667343, Error (MAE): 0.18483824478952507\n",
      "Epoch: 148, Loss: 0.25905648882227733, Error (MAE): 0.18482855051979982\n",
      "Epoch: 149, Loss: 0.2583617994883903, Error (MAE): 0.18481721342506266\n",
      "Epoch: 150, Loss: 0.2577869104487555, Error (MAE): 0.18480525496310757\n",
      "Epoch: 151, Loss: 0.257222462305449, Error (MAE): 0.18479521830279128\n",
      "Epoch: 152, Loss: 0.2566731830960826, Error (MAE): 0.18478288350248695\n",
      "Epoch: 153, Loss: 0.2562021094381361, Error (MAE): 0.18476774246620953\n",
      "Epoch: 154, Loss: 0.25559963756485987, Error (MAE): 0.18475736879316487\n",
      "Epoch: 155, Loss: 0.2552009327967364, Error (MAE): 0.18474382386171728\n",
      "Epoch: 156, Loss: 0.25459186553506924, Error (MAE): 0.18473296685326368\n",
      "Epoch: 157, Loss: 0.25410794337889303, Error (MAE): 0.18471925655253849\n",
      "Epoch: 158, Loss: 0.2536248172584333, Error (MAE): 0.18470780629860728\n",
      "Epoch: 159, Loss: 0.25314122740935563, Error (MAE): 0.1846928769036343\n",
      "Epoch: 160, Loss: 0.2527067498829132, Error (MAE): 0.18467807355231808\n",
      "Epoch: 161, Loss: 0.25229873233719874, Error (MAE): 0.1846628018787929\n",
      "Epoch: 162, Loss: 0.2518913408643321, Error (MAE): 0.18464998430327365\n",
      "Epoch: 163, Loss: 0.25145598439345684, Error (MAE): 0.18463198896637537\n",
      "Epoch: 164, Loss: 0.25106503898487953, Error (MAE): 0.18462161977488295\n",
      "Epoch: 165, Loss: 0.25068148589672, Error (MAE): 0.18460561973708017\n",
      "Epoch: 166, Loss: 0.250324674342808, Error (MAE): 0.1845916059232296\n",
      "Epoch: 167, Loss: 0.24994496239307232, Error (MAE): 0.1845724919908925\n",
      "Epoch: 168, Loss: 0.24960981757569134, Error (MAE): 0.18455673474118225\n",
      "Epoch: 169, Loss: 0.24924318470004805, Error (MAE): 0.18454121243684812\n",
      "Epoch: 170, Loss: 0.24894155483496816, Error (MAE): 0.1845234210105767\n",
      "Epoch: 171, Loss: 0.24858776373522623, Error (MAE): 0.1845048233530575\n",
      "Epoch: 172, Loss: 0.2483782305529243, Error (MAE): 0.18448890207853533\n",
      "Epoch: 173, Loss: 0.2479815112244814, Error (MAE): 0.18447294696829372\n",
      "Epoch: 174, Loss: 0.2476896775844402, Error (MAE): 0.1844527883861298\n",
      "Epoch: 175, Loss: 0.2474700369332966, Error (MAE): 0.18443578167965538\n",
      "Epoch: 176, Loss: 0.24708750619924158, Error (MAE): 0.18441512026733026\n",
      "Epoch: 177, Loss: 0.24684063429222966, Error (MAE): 0.18440044654491253\n",
      "Epoch: 178, Loss: 0.24670251430873585, Error (MAE): 0.18437836840188593\n",
      "Epoch: 179, Loss: 0.24634503746839395, Error (MAE): 0.18435967506322645\n",
      "Epoch: 180, Loss: 0.24603590638117684, Error (MAE): 0.18433644841039987\n",
      "Epoch: 181, Loss: 0.24579501376116186, Error (MAE): 0.18431986453837917\n",
      "Epoch: 182, Loss: 0.2455533442640663, Error (MAE): 0.18430156938563613\n",
      "Epoch: 183, Loss: 0.24536751950145663, Error (MAE): 0.1842780813462752\n",
      "Epoch: 184, Loss: 0.2451356614666774, Error (MAE): 0.184255698681774\n",
      "Epoch: 185, Loss: 0.24490625338446825, Error (MAE): 0.18423803061022795\n",
      "Epoch: 186, Loss: 0.24462659164030748, Error (MAE): 0.18421463085744613\n",
      "Epoch: 187, Loss: 0.24442471978359653, Error (MAE): 0.18419041725477778\n",
      "Epoch: 188, Loss: 0.2442765122741685, Error (MAE): 0.18417208344864666\n",
      "Epoch: 189, Loss: 0.24402820761490585, Error (MAE): 0.18414965876959322\n",
      "Epoch: 190, Loss: 0.24383966008523353, Error (MAE): 0.1841257468874293\n",
      "Epoch: 191, Loss: 0.2436364744614838, Error (MAE): 0.1840979298926834\n",
      "Epoch: 192, Loss: 0.2434538816823099, Error (MAE): 0.1840737534868986\n",
      "Epoch: 193, Loss: 0.24327407934163747, Error (MAE): 0.1840482029251586\n",
      "Epoch: 194, Loss: 0.2431106086736335, Error (MAE): 0.1840236786388813\n",
      "Epoch: 195, Loss: 0.24291888170672538, Error (MAE): 0.18399480623858316\n",
      "Epoch: 196, Loss: 0.2427341152626769, Error (MAE): 0.18396626356849097\n",
      "Epoch: 197, Loss: 0.24257412317552066, Error (MAE): 0.18393691926074207\n",
      "Epoch: 198, Loss: 0.24240574453558242, Error (MAE): 0.18390463897608278\n",
      "Epoch: 199, Loss: 0.2422426876268889, Error (MAE): 0.18387106901272796\n",
      "Epoch: 200, Loss: 0.24206706791892088, Error (MAE): 0.18383671881112837\n",
      "MAE: 0.18305876851081848\n",
      "MAE: 0.1823526918888092\n",
      "MAE: 0.1728457808494568\n",
      "MAE: 0.2179989069700241\n",
      "MAE: 0.1743164360523224\n",
      "MAE: 0.181499645113945\n",
      "MAE: 0.1588505655527115\n",
      "MAE: 0.16566996276378632\n",
      "MAE: 0.2025730311870575\n",
      "MAE: 0.16876737773418427\n",
      "MAE: 0.22035378217697144\n",
      "MAE: 0.17107103765010834\n",
      "MAE: 0.17115533351898193\n",
      "MAE: 0.17215174436569214\n",
      "MAE: 0.19001267850399017\n",
      "MAE: 0.1760704517364502\n",
      "MAE: 0.17419113218784332\n",
      "MAE: 0.19322732090950012\n",
      "MAE: 0.1956741064786911\n",
      "MAE: 0.16873927414417267\n",
      "MAE: 0.1884741336107254\n",
      "MAE: 0.18456768989562988\n",
      "MAE: 0.1711004376411438\n",
      "MAE: 0.16621381044387817\n",
      "MAE: 0.16968251764774323\n",
      "MAE: 0.17453782260417938\n",
      "MAE: 0.18243440985679626\n",
      "MAE: 0.1729208528995514\n",
      "MAE: 0.1753903180360794\n",
      "MAE: 0.1759745329618454\n",
      "MAE: 0.1733592450618744\n",
      "MAE: 0.1927213966846466\n",
      "MAE: 0.175638347864151\n",
      "MAE: 0.1656884402036667\n",
      "Test error MAE: 0.17968482305021846\n",
      "Epoch: 1, Loss: 0.24310737142437383, Error (MAE): 0.18482594785833717\n",
      "Epoch: 2, Loss: 0.24287277280836178, Error (MAE): 0.18477629987817062\n",
      "Epoch: 3, Loss: 0.2426871093816327, Error (MAE): 0.1847209817260728\n",
      "Epoch: 4, Loss: 0.2425071537718737, Error (MAE): 0.18466941922678984\n",
      "Epoch: 5, Loss: 0.2423193965639387, Error (MAE): 0.18461236794640248\n",
      "Epoch: 6, Loss: 0.24228712098490923, Error (MAE): 0.1845494020254092\n",
      "Epoch: 7, Loss: 0.24200033659773662, Error (MAE): 0.18448409919900105\n",
      "Epoch: 8, Loss: 0.2418308733101178, Error (MAE): 0.18440751451298706\n",
      "Epoch: 9, Loss: 0.2416138994066339, Error (MAE): 0.18431900105530158\n",
      "Epoch: 10, Loss: 0.24138797920449337, Error (MAE): 0.18421486210554167\n",
      "Epoch: 11, Loss: 0.2412474353734712, Error (MAE): 0.18409341797792822\n",
      "Epoch: 12, Loss: 0.2410101180237935, Error (MAE): 0.18396863632632376\n",
      "Epoch: 13, Loss: 0.24075310145105636, Error (MAE): 0.18383618147301495\n",
      "Epoch: 14, Loss: 0.24063567167386077, Error (MAE): 0.18369303587684058\n",
      "Epoch: 15, Loss: 0.24033686664319576, Error (MAE): 0.18354911990183637\n",
      "Epoch: 16, Loss: 0.2401362470442191, Error (MAE): 0.1834009944048143\n",
      "Epoch: 17, Loss: 0.23991441816315615, Error (MAE): 0.18325564119600712\n",
      "Epoch: 18, Loss: 0.23970810105477958, Error (MAE): 0.18312385532640874\n",
      "Epoch: 19, Loss: 0.2395145237669909, Error (MAE): 0.18299173345243125\n",
      "Epoch: 20, Loss: 0.23932979440778718, Error (MAE): 0.1828562844740717\n",
      "Epoch: 21, Loss: 0.2391146365413092, Error (MAE): 0.18272357170743153\n",
      "Epoch: 22, Loss: 0.23892090531220114, Error (MAE): 0.18258048224269896\n",
      "Epoch: 23, Loss: 0.23872787589417363, Error (MAE): 0.18244953565579608\n",
      "Epoch: 24, Loss: 0.23851476912211655, Error (MAE): 0.18232607057220057\n",
      "Epoch: 25, Loss: 0.23835988533227964, Error (MAE): 0.18222419536651524\n",
      "Epoch: 26, Loss: 0.23819548328568166, Error (MAE): 0.18212766732488359\n",
      "Epoch: 27, Loss: 0.23802705927002699, Error (MAE): 0.18203082568663403\n",
      "Epoch: 28, Loss: 0.23790133100255093, Error (MAE): 0.18194284116415152\n",
      "Epoch: 29, Loss: 0.23775957311902726, Error (MAE): 0.1818589896411824\n",
      "Epoch: 30, Loss: 0.2376136399973604, Error (MAE): 0.1817705755619178\n",
      "Epoch: 31, Loss: 0.23748814992438583, Error (MAE): 0.18169314139767698\n",
      "Epoch: 32, Loss: 0.23736018973185605, Error (MAE): 0.18161591573765404\n",
      "Epoch: 33, Loss: 0.2372484765106574, Error (MAE): 0.18154213403848776\n",
      "Epoch: 34, Loss: 0.23707329857170134, Error (MAE): 0.18146016006182908\n",
      "Epoch: 35, Loss: 0.23697824014308758, Error (MAE): 0.18138855281180905\n",
      "Epoch: 36, Loss: 0.23685938276742635, Error (MAE): 0.18131524694145174\n",
      "Epoch: 37, Loss: 0.23676618093386628, Error (MAE): 0.1812435641772765\n",
      "Epoch: 38, Loss: 0.23664438534051851, Error (MAE): 0.18116253681648942\n",
      "Epoch: 39, Loss: 0.23654847967445403, Error (MAE): 0.1810773823942457\n",
      "Epoch: 40, Loss: 0.23638354465925604, Error (MAE): 0.1809928216656348\n",
      "Epoch: 41, Loss: 0.23628569478379155, Error (MAE): 0.18090460365428065\n",
      "Epoch: 42, Loss: 0.23614139417956645, Error (MAE): 0.18081556036508173\n",
      "Epoch: 43, Loss: 0.23601727198837394, Error (MAE): 0.18072491480891867\n",
      "Epoch: 44, Loss: 0.23591803776142292, Error (MAE): 0.18063680581132271\n",
      "Epoch: 45, Loss: 0.23582788820105388, Error (MAE): 0.18055441841147\n",
      "Epoch: 46, Loss: 0.23564813302871876, Error (MAE): 0.1804622309772592\n",
      "Epoch: 47, Loss: 0.2355393153384216, Error (MAE): 0.1803686456348663\n",
      "Epoch: 48, Loss: 0.23540601145504111, Error (MAE): 0.18028060363647633\n",
      "Epoch: 49, Loss: 0.23530208717163345, Error (MAE): 0.18019160986842966\n",
      "Epoch: 50, Loss: 0.23517644618238723, Error (MAE): 0.18010090157053524\n",
      "Epoch: 51, Loss: 0.2350590685032364, Error (MAE): 0.1800030338809006\n",
      "Epoch: 52, Loss: 0.23493142459625588, Error (MAE): 0.17990563216066002\n",
      "Epoch: 53, Loss: 0.23482124709097066, Error (MAE): 0.17980452363652394\n",
      "Epoch: 54, Loss: 0.23467771955450675, Error (MAE): 0.1796984865253133\n",
      "Epoch: 55, Loss: 0.23452546430709667, Error (MAE): 0.17958415148401619\n",
      "Epoch: 56, Loss: 0.23435101540465103, Error (MAE): 0.17946787649079374\n",
      "Epoch: 57, Loss: 0.2342251529146854, Error (MAE): 0.17935644740000703\n",
      "Epoch: 58, Loss: 0.23411929416925387, Error (MAE): 0.17924658842104718\n",
      "Epoch: 59, Loss: 0.23397143812556015, Error (MAE): 0.17912928894498295\n",
      "Epoch: 60, Loss: 0.23382634563105448, Error (MAE): 0.17902288647522605\n",
      "Epoch: 61, Loss: 0.23371746105359012, Error (MAE): 0.17891932811055863\n",
      "Epoch: 62, Loss: 0.2335526977938817, Error (MAE): 0.17880190415938096\n",
      "Epoch: 63, Loss: 0.23345558457356647, Error (MAE): 0.17869383970597633\n",
      "Epoch: 64, Loss: 0.23335001096689612, Error (MAE): 0.17858517965427914\n",
      "Epoch: 65, Loss: 0.23324949804105258, Error (MAE): 0.1784788585246954\n",
      "Epoch: 66, Loss: 0.23311253474619156, Error (MAE): 0.17837640116537423\n",
      "Epoch: 67, Loss: 0.232973714184044, Error (MAE): 0.17828171997142017\n",
      "Epoch: 68, Loss: 0.2329302278900505, Error (MAE): 0.17817259518275583\n",
      "Epoch: 69, Loss: 0.23273913876006477, Error (MAE): 0.17808396117131514\n",
      "Epoch: 70, Loss: 0.23262128222705727, Error (MAE): 0.17797772239025375\n",
      "Epoch: 71, Loss: 0.23249874874613338, Error (MAE): 0.17788741283846976\n",
      "Epoch: 72, Loss: 0.23237094159861257, Error (MAE): 0.17779836495567983\n",
      "Epoch: 73, Loss: 0.2322315802251486, Error (MAE): 0.17770126069846906\n",
      "Epoch: 74, Loss: 0.23214153754980044, Error (MAE): 0.1776103936415866\n",
      "Epoch: 75, Loss: 0.23202973189658688, Error (MAE): 0.17751378874133403\n",
      "Epoch: 76, Loss: 0.2319408615953044, Error (MAE): 0.1774273198798187\n",
      "Epoch: 77, Loss: 0.23181325488520743, Error (MAE): 0.1773276208038617\n",
      "Epoch: 78, Loss: 0.2317248588441906, Error (MAE): 0.17724410125187465\n",
      "Epoch: 79, Loss: 0.23163800905073495, Error (MAE): 0.17715691186879812\n",
      "Epoch: 80, Loss: 0.231477395484322, Error (MAE): 0.17705702815288887\n",
      "Epoch: 81, Loss: 0.2314244526669495, Error (MAE): 0.1769769331790451\n",
      "Epoch: 82, Loss: 0.23128205582611544, Error (MAE): 0.1768777372693657\n",
      "Epoch: 83, Loss: 0.2312078731400626, Error (MAE): 0.17679295672061748\n",
      "Epoch: 84, Loss: 0.23108215249122532, Error (MAE): 0.17669998613515295\n",
      "Epoch: 85, Loss: 0.23092645798858843, Error (MAE): 0.17661503024567338\n",
      "Epoch: 86, Loss: 0.23086367435473248, Error (MAE): 0.17652496942003867\n",
      "Epoch: 87, Loss: 0.23078627581883193, Error (MAE): 0.17643693739310243\n",
      "Epoch: 88, Loss: 0.23066809022785129, Error (MAE): 0.17634430449259908\n",
      "Epoch: 89, Loss: 0.23055587003105565, Error (MAE): 0.17625993310957028\n",
      "Epoch: 90, Loss: 0.2304293555872781, Error (MAE): 0.17616135094847\n",
      "Epoch: 91, Loss: 0.23034520693739555, Error (MAE): 0.17607246294505613\n",
      "Epoch: 92, Loss: 0.2302940309719932, Error (MAE): 0.17598088253709607\n",
      "Epoch: 93, Loss: 0.23013933955278612, Error (MAE): 0.17589418948592997\n",
      "Epoch: 94, Loss: 0.23013643438654735, Error (MAE): 0.17579754604432815\n",
      "Epoch: 95, Loss: 0.22990077050556815, Error (MAE): 0.1756826412857027\n",
      "Epoch: 96, Loss: 0.22979528260858437, Error (MAE): 0.17555771532811618\n",
      "Epoch: 97, Loss: 0.22967934216323652, Error (MAE): 0.1754478561250787\n",
      "Epoch: 98, Loss: 0.22957215015601395, Error (MAE): 0.17534166697720835\n",
      "Epoch: 99, Loss: 0.22946158846966305, Error (MAE): 0.17522984675895004\n",
      "Epoch: 100, Loss: 0.22936238606173293, Error (MAE): 0.17512762658578113\n",
      "Epoch: 101, Loss: 0.2292092325992154, Error (MAE): 0.17501622068702727\n",
      "Epoch: 102, Loss: 0.22908554086111543, Error (MAE): 0.17491668675627028\n",
      "Epoch: 103, Loss: 0.22899317618151357, Error (MAE): 0.17480550146192536\n",
      "Epoch: 104, Loss: 0.22886689108117184, Error (MAE): 0.17469888533416547\n",
      "Epoch: 105, Loss: 0.22875967229667463, Error (MAE): 0.1745979251494085\n",
      "Epoch: 106, Loss: 0.22860984593853914, Error (MAE): 0.17449471152814708\n",
      "Epoch: 107, Loss: 0.22854187703670414, Error (MAE): 0.1743980308896617\n",
      "Epoch: 108, Loss: 0.22839586795272684, Error (MAE): 0.17430680049093147\n",
      "Epoch: 109, Loss: 0.22836552705979885, Error (MAE): 0.17421417420071766\n",
      "Epoch: 110, Loss: 0.22819555623638899, Error (MAE): 0.17409528668661764\n",
      "Epoch: 111, Loss: 0.22808452589171274, Error (MAE): 0.17402355608187223\n",
      "Epoch: 112, Loss: 0.2279947125598004, Error (MAE): 0.173919219831775\n",
      "Epoch: 113, Loss: 0.2278517202327126, Error (MAE): 0.17384122356884463\n",
      "Epoch: 114, Loss: 0.22778967986429544, Error (MAE): 0.17373700350298918\n",
      "Epoch: 115, Loss: 0.22765494546944037, Error (MAE): 0.17364310142689182\n",
      "Epoch: 116, Loss: 0.2276003626280261, Error (MAE): 0.1735400327838453\n",
      "Epoch: 117, Loss: 0.227409622498921, Error (MAE): 0.17344400365101664\n",
      "Epoch: 118, Loss: 0.22740037447975991, Error (MAE): 0.17332559958436436\n",
      "Epoch: 119, Loss: 0.2272264495828098, Error (MAE): 0.17322049396378653\n",
      "Epoch: 120, Loss: 0.22718844198642818, Error (MAE): 0.1731307069609936\n",
      "Epoch: 121, Loss: 0.22704086917683594, Error (MAE): 0.1730290720785471\n",
      "Epoch: 122, Loss: 0.22690666898300774, Error (MAE): 0.1729302587813901\n",
      "Epoch: 123, Loss: 0.22681411921529843, Error (MAE): 0.17283607828885988\n",
      "Epoch: 124, Loss: 0.22669950721407295, Error (MAE): 0.17273984087589092\n",
      "Epoch: 125, Loss: 0.22659633616755778, Error (MAE): 0.1726308010126415\n",
      "Epoch: 126, Loss: 0.2265108879795648, Error (MAE): 0.17252880491708456\n",
      "Epoch: 127, Loss: 0.22640166919034227, Error (MAE): 0.1724378463244976\n",
      "Epoch: 128, Loss: 0.2263169669567194, Error (MAE): 0.17233250430203917\n",
      "Epoch: 129, Loss: 0.22617775369855694, Error (MAE): 0.17222793501122555\n",
      "Epoch: 130, Loss: 0.22600723791839486, Error (MAE): 0.17213084722371927\n",
      "Epoch: 131, Loss: 0.2259620239860133, Error (MAE): 0.1720079347155148\n",
      "Epoch: 132, Loss: 0.22582424359214037, Error (MAE): 0.17189223773049234\n",
      "Epoch: 133, Loss: 0.2256995779007001, Error (MAE): 0.17178615894084587\n",
      "Epoch: 134, Loss: 0.22559242320239992, Error (MAE): 0.17165106635792812\n",
      "Epoch: 135, Loss: 0.22542912272134222, Error (MAE): 0.1715089656356582\n",
      "Epoch: 136, Loss: 0.2252276159990999, Error (MAE): 0.17136550173723608\n",
      "Epoch: 137, Loss: 0.22507859116658233, Error (MAE): 0.1711988996966441\n",
      "Epoch: 138, Loss: 0.22496417646569417, Error (MAE): 0.17106660987649644\n",
      "Epoch: 139, Loss: 0.22479031195766047, Error (MAE): 0.17090431953731336\n",
      "Epoch: 140, Loss: 0.2246638556620232, Error (MAE): 0.1707568620156525\n",
      "Epoch: 141, Loss: 0.22465196083810993, Error (MAE): 0.1706205450726631\n",
      "Epoch: 142, Loss: 0.22446572287638383, Error (MAE): 0.1704788460095126\n",
      "Epoch: 143, Loss: 0.22426254173418633, Error (MAE): 0.17034080703007548\n",
      "Epoch: 144, Loss: 0.22410341402641812, Error (MAE): 0.17020077801736674\n",
      "Epoch: 145, Loss: 0.22399772894113584, Error (MAE): 0.17004514132675372\n",
      "Epoch: 146, Loss: 0.2237768672910848, Error (MAE): 0.16991402186397322\n",
      "Epoch: 147, Loss: 0.22365650601853104, Error (MAE): 0.16976880646289738\n",
      "Epoch: 148, Loss: 0.22348011167425857, Error (MAE): 0.16963583343011096\n",
      "Epoch: 149, Loss: 0.2234059632720804, Error (MAE): 0.16949482979182912\n",
      "Epoch: 150, Loss: 0.22318739908978455, Error (MAE): 0.16933902705970563\n",
      "Epoch: 151, Loss: 0.22312160676583312, Error (MAE): 0.16919636412670738\n",
      "Epoch: 152, Loss: 0.222939752658507, Error (MAE): 0.16905176146586137\n",
      "Epoch: 153, Loss: 0.2227785326260373, Error (MAE): 0.1689017510279677\n",
      "Epoch: 154, Loss: 0.22260107592980666, Error (MAE): 0.16874736838770987\n",
      "Epoch: 155, Loss: 0.22239514311453454, Error (MAE): 0.16856051040323158\n",
      "Epoch: 156, Loss: 0.22227011049600473, Error (MAE): 0.16839114425325752\n",
      "Epoch: 157, Loss: 0.22209108503241287, Error (MAE): 0.16821969754265664\n",
      "Epoch: 158, Loss: 0.22186394719252908, Error (MAE): 0.16805562421791537\n",
      "Epoch: 159, Loss: 0.22171124356581753, Error (MAE): 0.1678839018918518\n",
      "Epoch: 160, Loss: 0.221507270197223, Error (MAE): 0.16770301579980923\n",
      "Epoch: 161, Loss: 0.2213885052535767, Error (MAE): 0.1675440625364619\n",
      "Epoch: 162, Loss: 0.2211707189567107, Error (MAE): 0.16734232904767632\n",
      "Epoch: 163, Loss: 0.22095777240014614, Error (MAE): 0.16715302267917118\n",
      "Epoch: 164, Loss: 0.22074309282733084, Error (MAE): 0.16695392434310197\n",
      "Epoch: 165, Loss: 0.22054244611496315, Error (MAE): 0.16673944688829265\n",
      "Epoch: 166, Loss: 0.22035254157127293, Error (MAE): 0.1664959622505016\n",
      "Epoch: 167, Loss: 0.22000910957953088, Error (MAE): 0.1662579635928448\n",
      "Epoch: 168, Loss: 0.21978273080255753, Error (MAE): 0.16600746476560607\n",
      "Epoch: 169, Loss: 0.21951531299522944, Error (MAE): 0.16574293991228692\n",
      "Epoch: 170, Loss: 0.2192273640767076, Error (MAE): 0.16549069417598553\n",
      "Epoch: 171, Loss: 0.21895334819205722, Error (MAE): 0.16522268670842163\n",
      "Epoch: 172, Loss: 0.2186823276648844, Error (MAE): 0.16495063027044884\n",
      "Epoch: 173, Loss: 0.21840663993717135, Error (MAE): 0.1646991328413325\n",
      "Epoch: 174, Loss: 0.21817805298737117, Error (MAE): 0.16444416624262817\n",
      "Epoch: 175, Loss: 0.21792443981744292, Error (MAE): 0.16418139546885527\n",
      "Epoch: 176, Loss: 0.21768619747538315, Error (MAE): 0.16394828428003125\n",
      "Epoch: 177, Loss: 0.21741867760070285, Error (MAE): 0.16371333744741023\n",
      "Epoch: 178, Loss: 0.21714549999039873, Error (MAE): 0.16347225514569677\n",
      "Epoch: 179, Loss: 0.21691237905419858, Error (MAE): 0.16325239825965768\n",
      "Epoch: 180, Loss: 0.2166961399012042, Error (MAE): 0.1630275641617022\n",
      "Epoch: 181, Loss: 0.21642450517729708, Error (MAE): 0.16279935119743633\n",
      "Epoch: 182, Loss: 0.21610864985706216, Error (MAE): 0.16257184699065702\n",
      "Epoch: 183, Loss: 0.21590197971440794, Error (MAE): 0.16234771828902395\n",
      "Epoch: 184, Loss: 0.21561080889594286, Error (MAE): 0.16211017999882088\n",
      "Epoch: 185, Loss: 0.2153763806909547, Error (MAE): 0.1618859364574117\n",
      "Epoch: 186, Loss: 0.21513535978650689, Error (MAE): 0.16168092258442612\n",
      "Epoch: 187, Loss: 0.21494418830799877, Error (MAE): 0.1614807745567838\n",
      "Epoch: 188, Loss: 0.21469968927085847, Error (MAE): 0.16128440817495934\n",
      "Epoch: 189, Loss: 0.2144747669983627, Error (MAE): 0.16108569312364535\n",
      "Epoch: 190, Loss: 0.2142377945041298, Error (MAE): 0.16088522600948363\n",
      "Epoch: 191, Loss: 0.21406709778129607, Error (MAE): 0.1606896092793099\n",
      "Epoch: 192, Loss: 0.2138286776336512, Error (MAE): 0.16049133935817203\n",
      "Epoch: 193, Loss: 0.21363144339923573, Error (MAE): 0.1603059024739086\n",
      "Epoch: 194, Loss: 0.21336779312083595, Error (MAE): 0.16011334821245723\n",
      "Epoch: 195, Loss: 0.2131879769993904, Error (MAE): 0.1599162558191701\n",
      "Epoch: 196, Loss: 0.21300004153771507, Error (MAE): 0.15972859429237538\n",
      "Epoch: 197, Loss: 0.21277639370663723, Error (MAE): 0.15954071462602543\n",
      "Epoch: 198, Loss: 0.21256829316454723, Error (MAE): 0.15935710767157993\n",
      "Epoch: 199, Loss: 0.212359444987505, Error (MAE): 0.15917379773200901\n",
      "Epoch: 200, Loss: 0.2121518867132359, Error (MAE): 0.15898359662159942\n",
      "MAE: 0.1483476459980011\n",
      "MAE: 0.1751633584499359\n",
      "MAE: 0.1541120707988739\n",
      "MAE: 0.14532150328159332\n",
      "MAE: 0.1466590017080307\n",
      "MAE: 0.14359799027442932\n",
      "MAE: 0.16746893525123596\n",
      "MAE: 0.23616446554660797\n",
      "MAE: 0.15487200021743774\n",
      "MAE: 0.1546332985162735\n",
      "MAE: 0.19492703676223755\n",
      "MAE: 0.15742303431034088\n",
      "MAE: 0.15239204466342926\n",
      "MAE: 0.15892718732357025\n",
      "MAE: 0.15209972858428955\n",
      "MAE: 0.15617437660694122\n",
      "MAE: 0.14997537434101105\n",
      "MAE: 0.1566510945558548\n",
      "MAE: 0.14051876962184906\n",
      "MAE: 0.15083414316177368\n",
      "MAE: 0.14566496014595032\n",
      "MAE: 0.16119442880153656\n",
      "MAE: 0.14780601859092712\n",
      "MAE: 0.15985026955604553\n",
      "MAE: 0.13690978288650513\n",
      "MAE: 0.19660158455371857\n",
      "MAE: 0.15753908455371857\n",
      "MAE: 0.1689605563879013\n",
      "MAE: 0.14650669693946838\n",
      "MAE: 0.1665179431438446\n",
      "MAE: 0.15632642805576324\n",
      "MAE: 0.14368309080600739\n",
      "MAE: 0.15985296666622162\n",
      "MAE: 0.14214631915092468\n",
      "Test error MAE: 0.15840656441800735\n",
      "Epoch: 1, Loss: 0.21485247607551403, Error (MAE): 0.1599926882937773\n",
      "Epoch: 2, Loss: 0.21337014614646113, Error (MAE): 0.1591574640861198\n",
      "Epoch: 3, Loss: 0.21254168228426976, Error (MAE): 0.1586166877132743\n",
      "Epoch: 4, Loss: 0.21198903546849293, Error (MAE): 0.15821012921297728\n",
      "Epoch: 5, Loss: 0.21150488428660294, Error (MAE): 0.15786806505117842\n",
      "Epoch: 6, Loss: 0.2111413736841572, Error (MAE): 0.1575647169974313\n",
      "Epoch: 7, Loss: 0.21076220774383686, Error (MAE): 0.15729182758438054\n",
      "Epoch: 8, Loss: 0.21044736933797153, Error (MAE): 0.1570370976827038\n",
      "Epoch: 9, Loss: 0.21015006904281788, Error (MAE): 0.1567992963897648\n",
      "Epoch: 10, Loss: 0.20989650098690346, Error (MAE): 0.15656606219152905\n",
      "Epoch: 11, Loss: 0.20962208398242496, Error (MAE): 0.15635450584674948\n",
      "Epoch: 12, Loss: 0.20936572206998938, Error (MAE): 0.1561395792818781\n",
      "Epoch: 13, Loss: 0.20914117547113503, Error (MAE): 0.155931580978543\n",
      "Epoch: 14, Loss: 0.20892411081203774, Error (MAE): 0.15572209545035862\n",
      "Epoch: 15, Loss: 0.20867699818379842, Error (MAE): 0.15551669739965182\n",
      "Epoch: 16, Loss: 0.2084453759798363, Error (MAE): 0.1553130880443018\n",
      "Epoch: 17, Loss: 0.20819640370892056, Error (MAE): 0.1551031124458384\n",
      "Epoch: 18, Loss: 0.2079764170877969, Error (MAE): 0.15489381017969617\n",
      "Epoch: 19, Loss: 0.2077403471096238, Error (MAE): 0.1546933670986944\n",
      "Epoch: 20, Loss: 0.20753264327102633, Error (MAE): 0.15449244695812908\n",
      "Epoch: 21, Loss: 0.20733983659032565, Error (MAE): 0.15429801827491219\n",
      "Epoch: 22, Loss: 0.20707520675748142, Error (MAE): 0.1540993439839847\n",
      "Epoch: 23, Loss: 0.2068883604300556, Error (MAE): 0.15390852071456054\n",
      "Epoch: 24, Loss: 0.2066874313932746, Error (MAE): 0.15371893001581305\n",
      "Epoch: 25, Loss: 0.20647881880624971, Error (MAE): 0.15353401005268097\n",
      "Epoch: 26, Loss: 0.2063138905301023, Error (MAE): 0.15335268694073406\n",
      "Epoch: 27, Loss: 0.20608413997870773, Error (MAE): 0.15317027326395263\n",
      "Epoch: 28, Loss: 0.20590457220130892, Error (MAE): 0.1529930144993227\n",
      "Epoch: 29, Loss: 0.20568227834665953, Error (MAE): 0.15281609746057595\n",
      "Epoch: 30, Loss: 0.2055016835011653, Error (MAE): 0.1526463128515144\n",
      "Epoch: 31, Loss: 0.2052730666612511, Error (MAE): 0.15247212216925266\n",
      "Epoch: 32, Loss: 0.20513474596525305, Error (MAE): 0.1523076866322489\n",
      "Epoch: 33, Loss: 0.20494471812870965, Error (MAE): 0.15214051172804477\n",
      "Epoch: 34, Loss: 0.20472926824395335, Error (MAE): 0.1519715437915788\n",
      "Epoch: 35, Loss: 0.20456500073422246, Error (MAE): 0.15180955182260542\n",
      "Epoch: 36, Loss: 0.20437188023951516, Error (MAE): 0.15163614778821147\n",
      "Epoch: 37, Loss: 0.2042001087718935, Error (MAE): 0.15147666588648043\n",
      "Epoch: 38, Loss: 0.20400514553731947, Error (MAE): 0.1513073224185118\n",
      "Epoch: 39, Loss: 0.20379181250707426, Error (MAE): 0.15114068629136726\n",
      "Epoch: 40, Loss: 0.20362514657760733, Error (MAE): 0.15097612876500657\n",
      "Epoch: 41, Loss: 0.20342904818591787, Error (MAE): 0.15080182977131942\n",
      "Epoch: 42, Loss: 0.20326563215522625, Error (MAE): 0.15063591446004695\n",
      "Epoch: 43, Loss: 0.2030514440874555, Error (MAE): 0.15047038213085773\n",
      "Epoch: 44, Loss: 0.20291094059374795, Error (MAE): 0.15030491018473213\n",
      "Epoch: 45, Loss: 0.20273826627144173, Error (MAE): 0.15013520275034123\n",
      "Epoch: 46, Loss: 0.20254131284222673, Error (MAE): 0.1499688901118378\n",
      "Epoch: 47, Loss: 0.20236594608025765, Error (MAE): 0.14980720395027702\n",
      "Epoch: 48, Loss: 0.20215819119962294, Error (MAE): 0.1496384131597049\n",
      "Epoch: 49, Loss: 0.20197998020631164, Error (MAE): 0.14947038344038066\n",
      "Epoch: 50, Loss: 0.20181562384562707, Error (MAE): 0.14930635212517496\n",
      "Epoch: 51, Loss: 0.20162979746932413, Error (MAE): 0.14913899040044243\n",
      "Epoch: 52, Loss: 0.20142132677693866, Error (MAE): 0.14896873173429004\n",
      "Epoch: 53, Loss: 0.20127350303219327, Error (MAE): 0.14880282570844267\n",
      "Epoch: 54, Loss: 0.20105251525320225, Error (MAE): 0.1486236804456853\n",
      "Epoch: 55, Loss: 0.20084991828719181, Error (MAE): 0.148426198192052\n",
      "Epoch: 56, Loss: 0.2006595321555636, Error (MAE): 0.1482351624698781\n",
      "Epoch: 57, Loss: 0.2004485686323536, Error (MAE): 0.14805499225187657\n",
      "Epoch: 58, Loss: 0.20025315558287635, Error (MAE): 0.14786931644402332\n",
      "Epoch: 59, Loss: 0.20004863047332905, Error (MAE): 0.14768846905720767\n",
      "Epoch: 60, Loss: 0.19985710607090992, Error (MAE): 0.14751480842259393\n",
      "Epoch: 61, Loss: 0.1997206213314142, Error (MAE): 0.1473468530422716\n",
      "Epoch: 62, Loss: 0.199493966551859, Error (MAE): 0.14717567450742222\n",
      "Epoch: 63, Loss: 0.1993209668504658, Error (MAE): 0.14701061117560116\n",
      "Epoch: 64, Loss: 0.199122305459051, Error (MAE): 0.1468460507579704\n",
      "Epoch: 65, Loss: 0.1989591345191002, Error (MAE): 0.1466851457953453\n",
      "Epoch: 66, Loss: 0.19874810160540823, Error (MAE): 0.14652823512233906\n",
      "Epoch: 67, Loss: 0.19864480063986423, Error (MAE): 0.14638106069013254\n",
      "Epoch: 68, Loss: 0.1984578684639575, Error (MAE): 0.14622775270645297\n",
      "Epoch: 69, Loss: 0.19831988493453212, Error (MAE): 0.14608142241390784\n",
      "Epoch: 70, Loss: 0.19811979403246693, Error (MAE): 0.14593449740934727\n",
      "Epoch: 71, Loss: 0.1980054170560481, Error (MAE): 0.14579472118126813\n",
      "Epoch: 72, Loss: 0.19783491129750636, Error (MAE): 0.1456531612063522\n",
      "Epoch: 73, Loss: 0.19768023179538213, Error (MAE): 0.1455104689655909\n",
      "Epoch: 74, Loss: 0.19752149984462938, Error (MAE): 0.14536889831521618\n",
      "Epoch: 75, Loss: 0.19734568082129778, Error (MAE): 0.14523584934980122\n",
      "Epoch: 76, Loss: 0.19718453521603968, Error (MAE): 0.1451024231848432\n",
      "Epoch: 77, Loss: 0.19711856310492132, Error (MAE): 0.14498359821180798\n",
      "Epoch: 78, Loss: 0.1969491454647548, Error (MAE): 0.14485895161086054\n",
      "Epoch: 79, Loss: 0.19680547536309087, Error (MAE): 0.14473510817138116\n",
      "Epoch: 80, Loss: 0.19667440552764864, Error (MAE): 0.14461926259656452\n",
      "Epoch: 81, Loss: 0.1965328957607497, Error (MAE): 0.14450253262671073\n",
      "Epoch: 82, Loss: 0.19640836442139611, Error (MAE): 0.14438909064255542\n",
      "Epoch: 83, Loss: 0.19627975016387542, Error (MAE): 0.14427285952799357\n",
      "Epoch: 84, Loss: 0.19615316780200645, Error (MAE): 0.1441513941025556\n",
      "Epoch: 85, Loss: 0.195997254839584, Error (MAE): 0.14402776044696125\n",
      "Epoch: 86, Loss: 0.1958502891348369, Error (MAE): 0.14390296539041533\n",
      "Epoch: 87, Loss: 0.19571999193572287, Error (MAE): 0.14378123947266322\n",
      "Epoch: 88, Loss: 0.1955934712913499, Error (MAE): 0.1436658627284107\n",
      "Epoch: 89, Loss: 0.19547189416280433, Error (MAE): 0.1435449035532439\n",
      "Epoch: 90, Loss: 0.19532154077914224, Error (MAE): 0.14343034008990474\n",
      "Epoch: 91, Loss: 0.19521777031581794, Error (MAE): 0.14330621186032225\n",
      "Epoch: 92, Loss: 0.1950627350762709, Error (MAE): 0.14319006192372807\n",
      "Epoch: 93, Loss: 0.1949421810125237, Error (MAE): 0.14307066620285833\n",
      "Epoch: 94, Loss: 0.19481198545267334, Error (MAE): 0.14296222105622292\n",
      "Epoch: 95, Loss: 0.1947068711047742, Error (MAE): 0.1428516917486689\n",
      "Epoch: 96, Loss: 0.19455640118068723, Error (MAE): 0.14274563862761455\n",
      "Epoch: 97, Loss: 0.19446042135580263, Error (MAE): 0.14263342682327798\n",
      "Epoch: 98, Loss: 0.1943185223794695, Error (MAE): 0.14252479630174922\n",
      "Epoch: 99, Loss: 0.19421649857688306, Error (MAE): 0.14240552123580405\n",
      "Epoch: 100, Loss: 0.1940684672167052, Error (MAE): 0.14229378604622028\n",
      "Epoch: 101, Loss: 0.19395995762810778, Error (MAE): 0.14217757161206274\n",
      "Epoch: 102, Loss: 0.19380756033890284, Error (MAE): 0.14206266814648216\n",
      "Epoch: 103, Loss: 0.19369287955671993, Error (MAE): 0.14194442170547017\n",
      "Epoch: 104, Loss: 0.19356935059846336, Error (MAE): 0.14183704082423182\n",
      "Epoch: 105, Loss: 0.1934388278802829, Error (MAE): 0.14171410657799066\n",
      "Epoch: 106, Loss: 0.19331343249598545, Error (MAE): 0.14160036679301688\n",
      "Epoch: 107, Loss: 0.193192798922311, Error (MAE): 0.14148135221938588\n",
      "Epoch: 108, Loss: 0.1930406980994922, Error (MAE): 0.14136172847738906\n",
      "Epoch: 109, Loss: 0.19287829612618063, Error (MAE): 0.1412349384444863\n",
      "Epoch: 110, Loss: 0.19276520520893495, Error (MAE): 0.14112387086028483\n",
      "Epoch: 111, Loss: 0.1926340064895687, Error (MAE): 0.14100686182726674\n",
      "Epoch: 112, Loss: 0.19249732903580166, Error (MAE): 0.14088761055869842\n",
      "Epoch: 113, Loss: 0.19239984397123108, Error (MAE): 0.14077319349370784\n",
      "Epoch: 114, Loss: 0.19224739119188108, Error (MAE): 0.14065306055456844\n",
      "Epoch: 115, Loss: 0.19212173448124928, Error (MAE): 0.14052429233691585\n",
      "Epoch: 116, Loss: 0.19195409752984546, Error (MAE): 0.14039840104419793\n",
      "Epoch: 117, Loss: 0.191833252893455, Error (MAE): 0.14026837579127568\n",
      "Epoch: 118, Loss: 0.1916681541435754, Error (MAE): 0.1401324883770587\n",
      "Epoch: 119, Loss: 0.1915230128302503, Error (MAE): 0.13998511138914235\n",
      "Epoch: 120, Loss: 0.1913748618159721, Error (MAE): 0.1398396040521451\n",
      "Epoch: 121, Loss: 0.19119264585758322, Error (MAE): 0.13967654197963317\n",
      "Epoch: 122, Loss: 0.1910195465185749, Error (MAE): 0.13952168977972287\n",
      "Epoch: 123, Loss: 0.19085369014473103, Error (MAE): 0.13936407975296475\n",
      "Epoch: 124, Loss: 0.19068745390247943, Error (MAE): 0.1392219523106938\n",
      "Epoch: 125, Loss: 0.19053578955024036, Error (MAE): 0.1390691779331485\n",
      "Epoch: 126, Loss: 0.1903765242713601, Error (MAE): 0.13892820082716087\n",
      "Epoch: 127, Loss: 0.1902271051015427, Error (MAE): 0.1387796368060717\n",
      "Epoch: 128, Loss: 0.1900735630917905, Error (MAE): 0.13864385319957093\n",
      "Epoch: 129, Loss: 0.18992890951348773, Error (MAE): 0.13849925967072374\n",
      "Epoch: 130, Loss: 0.18979760804283086, Error (MAE): 0.13837019109459064\n",
      "Epoch: 131, Loss: 0.18963126182111342, Error (MAE): 0.1382317287819599\n",
      "Epoch: 132, Loss: 0.18949227168488858, Error (MAE): 0.13810532384399157\n",
      "Epoch: 133, Loss: 0.1893879743431931, Error (MAE): 0.13797604359352766\n",
      "Epoch: 134, Loss: 0.1892660788413304, Error (MAE): 0.13785865880660156\n",
      "Epoch: 135, Loss: 0.18912529711847875, Error (MAE): 0.13772124090968674\n",
      "Epoch: 136, Loss: 0.18896591974728144, Error (MAE): 0.13759468284560672\n",
      "Epoch: 137, Loss: 0.18881570859186686, Error (MAE): 0.13744901999163983\n",
      "Epoch: 138, Loss: 0.18867474049329758, Error (MAE): 0.13732814355127848\n",
      "Epoch: 139, Loss: 0.18853079438654344, Error (MAE): 0.13718284594256486\n",
      "Epoch: 140, Loss: 0.18839960600902786, Error (MAE): 0.13705806656559902\n",
      "Epoch: 141, Loss: 0.18823436992381937, Error (MAE): 0.13691948965859058\n",
      "Epoch: 142, Loss: 0.18811257183551788, Error (MAE): 0.13680254595715607\n",
      "Epoch: 143, Loss: 0.188023493805928, Error (MAE): 0.13669044068500177\n",
      "Epoch: 144, Loss: 0.18789120285368677, Error (MAE): 0.13658633488994926\n",
      "Epoch: 145, Loss: 0.18775888877128488, Error (MAE): 0.13647119172695857\n",
      "Epoch: 146, Loss: 0.18763520891097055, Error (MAE): 0.1363686411016023\n",
      "Epoch: 147, Loss: 0.1875591228034959, Error (MAE): 0.13627033219186227\n",
      "Epoch: 148, Loss: 0.18741866590371772, Error (MAE): 0.13616768204009355\n",
      "Epoch: 149, Loss: 0.1873801862125966, Error (MAE): 0.13608181081823448\n",
      "Epoch: 150, Loss: 0.18721627177142386, Error (MAE): 0.13597650064238861\n",
      "Epoch: 151, Loss: 0.18716679268808506, Error (MAE): 0.13588247070116782\n",
      "Epoch: 152, Loss: 0.18703632935214398, Error (MAE): 0.13578326193921603\n",
      "Epoch: 153, Loss: 0.18693145931656682, Error (MAE): 0.13568472039343707\n",
      "Epoch: 154, Loss: 0.18683811310511916, Error (MAE): 0.1356007802619863\n",
      "Epoch: 155, Loss: 0.18671345510589543, Error (MAE): 0.13550364003697438\n",
      "Epoch: 156, Loss: 0.18660400741135896, Error (MAE): 0.1354189899875157\n",
      "Epoch: 157, Loss: 0.18654615398663194, Error (MAE): 0.13533462406094396\n",
      "Epoch: 158, Loss: 0.18646206862446088, Error (MAE): 0.13526280107560443\n",
      "Epoch: 159, Loss: 0.18638749754250938, Error (MAE): 0.13518069228574411\n",
      "Epoch: 160, Loss: 0.18627706359126675, Error (MAE): 0.13510167821129757\n",
      "Epoch: 161, Loss: 0.18621837047498618, Error (MAE): 0.13502897611304895\n",
      "Epoch: 162, Loss: 0.18612090420367114, Error (MAE): 0.13496006497029048\n",
      "Epoch: 163, Loss: 0.1860573302898834, Error (MAE): 0.134891008318805\n",
      "Epoch: 164, Loss: 0.18596238587329636, Error (MAE): 0.13482264156884222\n",
      "Epoch: 165, Loss: 0.18593963647066658, Error (MAE): 0.13476739996182385\n",
      "Epoch: 166, Loss: 0.1858222116507701, Error (MAE): 0.1346924659698757\n",
      "Epoch: 167, Loss: 0.1858148639326665, Error (MAE): 0.13464992443349824\n",
      "Epoch: 168, Loss: 0.18573866595528019, Error (MAE): 0.1345854558940254\n",
      "Epoch: 169, Loss: 0.18567249645937733, Error (MAE): 0.13451849824901838\n",
      "Epoch: 170, Loss: 0.18558703551986325, Error (MAE): 0.134454408577129\n",
      "Epoch: 171, Loss: 0.18554716712948102, Error (MAE): 0.13439426332044957\n",
      "Epoch: 172, Loss: 0.18547073418079918, Error (MAE): 0.13433747849802471\n",
      "Epoch: 173, Loss: 0.18538208439278958, Error (MAE): 0.13426119545057638\n",
      "Epoch: 174, Loss: 0.18529849199216758, Error (MAE): 0.13419540904795946\n",
      "Epoch: 175, Loss: 0.1852135958511438, Error (MAE): 0.13412406445661587\n",
      "Epoch: 176, Loss: 0.18512587938735733, Error (MAE): 0.13405323428894156\n",
      "Epoch: 177, Loss: 0.1850469064579081, Error (MAE): 0.133988461832502\n",
      "Epoch: 178, Loss: 0.1849676509624097, Error (MAE): 0.13392796612052776\n",
      "Epoch: 179, Loss: 0.1849226365560916, Error (MAE): 0.13387400417852757\n",
      "Epoch: 180, Loss: 0.1848507650307755, Error (MAE): 0.1338192604815782\n",
      "Epoch: 181, Loss: 0.18478431608249893, Error (MAE): 0.13376801244136113\n",
      "Epoch: 182, Loss: 0.1847173938555504, Error (MAE): 0.13371216477965242\n",
      "Epoch: 183, Loss: 0.18469408043284916, Error (MAE): 0.13366858555532213\n",
      "Epoch: 184, Loss: 0.18463144985152713, Error (MAE): 0.13361359949209797\n",
      "Epoch: 185, Loss: 0.18459113520472797, Error (MAE): 0.133563997418578\n",
      "Epoch: 186, Loss: 0.18453988966657153, Error (MAE): 0.13350146947734393\n",
      "Epoch: 187, Loss: 0.1844584762827674, Error (MAE): 0.13343217941140062\n",
      "Epoch: 188, Loss: 0.18437290647581442, Error (MAE): 0.1333545595407486\n",
      "Epoch: 189, Loss: 0.184250022715597, Error (MAE): 0.1332694488341239\n",
      "Epoch: 190, Loss: 0.18416801439737207, Error (MAE): 0.133190466841655\n",
      "Epoch: 191, Loss: 0.1841139973544363, Error (MAE): 0.1331195210231774\n",
      "Epoch: 192, Loss: 0.18402805590807503, Error (MAE): 0.1330515346420345\n",
      "Epoch: 193, Loss: 0.1839617998964751, Error (MAE): 0.13299444873831165\n",
      "Epoch: 194, Loss: 0.18390110746693256, Error (MAE): 0.1329235446764462\n",
      "Epoch: 195, Loss: 0.18391240154629324, Error (MAE): 0.13286206982473828\n",
      "Epoch: 196, Loss: 0.18377814920090918, Error (MAE): 0.1328016515098401\n",
      "Epoch: 197, Loss: 0.18367882940306593, Error (MAE): 0.132743963888332\n",
      "Epoch: 198, Loss: 0.18359193116871278, Error (MAE): 0.13267935740191544\n",
      "Epoch: 199, Loss: 0.18358065588260764, Error (MAE): 0.1326322205809515\n",
      "Epoch: 200, Loss: 0.18347471652191077, Error (MAE): 0.13256829326499753\n",
      "MAE: 0.13634350895881653\n",
      "MAE: 0.1414380669593811\n",
      "MAE: 0.15501034259796143\n",
      "MAE: 0.1367170661687851\n",
      "MAE: 0.13394995033740997\n",
      "MAE: 0.14325062930583954\n",
      "MAE: 0.17311321198940277\n",
      "MAE: 0.13856562972068787\n",
      "MAE: 0.12695515155792236\n",
      "MAE: 0.13107194006443024\n",
      "MAE: 0.13679780066013336\n",
      "MAE: 0.13387009501457214\n",
      "MAE: 0.1373293399810791\n",
      "MAE: 0.16317729651927948\n",
      "MAE: 0.13460227847099304\n",
      "MAE: 0.13718505203723907\n",
      "MAE: 0.13523775339126587\n",
      "MAE: 0.12634910643100739\n",
      "MAE: 0.1488846242427826\n",
      "MAE: 0.12956927716732025\n",
      "MAE: 0.16554659605026245\n",
      "MAE: 0.12978583574295044\n",
      "MAE: 0.16866499185562134\n",
      "MAE: 0.1647823303937912\n",
      "MAE: 0.12883611023426056\n",
      "MAE: 0.14005082845687866\n",
      "MAE: 0.15935559570789337\n",
      "MAE: 0.14672653377056122\n",
      "MAE: 0.15187270939350128\n",
      "MAE: 0.13589231669902802\n",
      "MAE: 0.2008657604455948\n",
      "MAE: 0.15296721458435059\n",
      "MAE: 0.15083178877830505\n",
      "Test error MAE: 0.14532111314210025\n",
      "Epoch: 1, Loss: 0.1878760759510211, Error (MAE): 0.1361173127791775\n",
      "Epoch: 2, Loss: 0.18686779243732565, Error (MAE): 0.13495149769222559\n",
      "Epoch: 3, Loss: 0.18644159709784522, Error (MAE): 0.134569283964029\n",
      "Epoch: 4, Loss: 0.18607386101537676, Error (MAE): 0.13421428414867886\n",
      "Epoch: 5, Loss: 0.18522863012196414, Error (MAE): 0.13379779413564882\n",
      "Epoch: 6, Loss: 0.1845616940686952, Error (MAE): 0.13338901541793524\n",
      "Epoch: 7, Loss: 0.18405877498548423, Error (MAE): 0.13308746834744267\n",
      "Epoch: 8, Loss: 0.18380283586569687, Error (MAE): 0.13290523893352765\n",
      "Epoch: 9, Loss: 0.18376304965410659, Error (MAE): 0.13276163927877127\n",
      "Epoch: 10, Loss: 0.18350836545673768, Error (MAE): 0.13264982090957128\n",
      "Epoch: 11, Loss: 0.18339310108280893, Error (MAE): 0.13254679928519833\n",
      "Epoch: 12, Loss: 0.18331052007070228, Error (MAE): 0.1324572282940594\n",
      "Epoch: 13, Loss: 0.18321121172673666, Error (MAE): 0.13237703030011547\n",
      "Epoch: 14, Loss: 0.18312277655992934, Error (MAE): 0.13228885290115627\n",
      "Epoch: 15, Loss: 0.18304597831039288, Error (MAE): 0.13220978361457142\n",
      "Epoch: 16, Loss: 0.18298386982572612, Error (MAE): 0.1321401879080196\n",
      "Epoch: 17, Loss: 0.1829278969497823, Error (MAE): 0.1320797132133548\n",
      "Epoch: 18, Loss: 0.18285605177950504, Error (MAE): 0.13201717982318864\n",
      "Epoch: 19, Loss: 0.1827960941773742, Error (MAE): 0.1319526423380446\n",
      "Epoch: 20, Loss: 0.18274190154538225, Error (MAE): 0.1318924480965778\n",
      "Epoch: 21, Loss: 0.1828097646583372, Error (MAE): 0.13186345560781992\n",
      "Epoch: 22, Loss: 0.18270723855317528, Error (MAE): 0.13179056835708333\n",
      "Epoch: 23, Loss: 0.1826029803548286, Error (MAE): 0.13170411654595118\n",
      "Epoch: 24, Loss: 0.18251032371129564, Error (MAE): 0.13161992821008411\n",
      "Epoch: 25, Loss: 0.18244739666358747, Error (MAE): 0.13154650996647663\n",
      "Epoch: 26, Loss: 0.1823237500528791, Error (MAE): 0.13146028328520148\n",
      "Epoch: 27, Loss: 0.18229839127899997, Error (MAE): 0.1314152132219343\n",
      "Epoch: 28, Loss: 0.18225322708265104, Error (MAE): 0.13133481862162477\n",
      "Epoch: 29, Loss: 0.1821597307475645, Error (MAE): 0.13126549569528495\n",
      "Epoch: 30, Loss: 0.1821128188896535, Error (MAE): 0.1312184778056038\n",
      "Epoch: 31, Loss: 0.18209913261790775, Error (MAE): 0.13117319206470873\n",
      "Epoch: 32, Loss: 0.1820784590359944, Error (MAE): 0.13112733118347267\n",
      "Epoch: 33, Loss: 0.1821051830453659, Error (MAE): 0.13110095017881535\n",
      "Epoch: 34, Loss: 0.18210910282917878, Error (MAE): 0.13108884409737231\n",
      "Epoch: 35, Loss: 0.18210947658143825, Error (MAE): 0.13108172389998365\n",
      "Epoch: 36, Loss: 0.1818848412428329, Error (MAE): 0.13092981996153719\n",
      "Epoch: 37, Loss: 0.18173672914949815, Error (MAE): 0.13081935537395192\n",
      "Epoch: 38, Loss: 0.18158909800782133, Error (MAE): 0.13073094506094704\n",
      "Epoch: 39, Loss: 0.1815154203283253, Error (MAE): 0.1306866013736867\n",
      "Epoch: 40, Loss: 0.1814858123882493, Error (MAE): 0.13064887902852315\n",
      "Epoch: 41, Loss: 0.18141177563524957, Error (MAE): 0.1305943361636418\n",
      "Epoch: 42, Loss: 0.18132459883814428, Error (MAE): 0.13054165055057895\n",
      "Epoch: 43, Loss: 0.18123707397660213, Error (MAE): 0.13047943458850705\n",
      "Epoch: 44, Loss: 0.18117168868210778, Error (MAE): 0.1304226817924585\n",
      "Epoch: 45, Loss: 0.18121893359209174, Error (MAE): 0.13039053381601376\n",
      "Epoch: 46, Loss: 0.18108246019527094, Error (MAE): 0.1303482507147006\n",
      "Epoch: 47, Loss: 0.1811181415817631, Error (MAE): 0.1303342712014469\n",
      "Epoch: 48, Loss: 0.18108757385122243, Error (MAE): 0.1302974191285781\n",
      "Epoch: 49, Loss: 0.18107805667973276, Error (MAE): 0.13027731462645886\n",
      "Epoch: 50, Loss: 0.18104932846418068, Error (MAE): 0.13025217664553157\n",
      "Epoch: 51, Loss: 0.1810450359289326, Error (MAE): 0.13021367843916168\n",
      "Epoch: 52, Loss: 0.18096084247774152, Error (MAE): 0.1301710949237667\n",
      "Epoch: 53, Loss: 0.1808727986332196, Error (MAE): 0.13008876595256932\n",
      "Epoch: 54, Loss: 0.18073129631690124, Error (MAE): 0.13001428894809822\n",
      "Epoch: 55, Loss: 0.18065883263723173, Error (MAE): 0.12995078019909004\n",
      "Epoch: 56, Loss: 0.18062395191014702, Error (MAE): 0.12991496959506577\n",
      "Epoch: 57, Loss: 0.18060918041129612, Error (MAE): 0.12989754174182663\n",
      "Epoch: 58, Loss: 0.18063334976114445, Error (MAE): 0.12989962479071832\n",
      "Epoch: 59, Loss: 0.1805288892850947, Error (MAE): 0.12984390184283257\n",
      "Epoch: 60, Loss: 0.1805685441663016, Error (MAE): 0.1298334750332939\n",
      "Epoch: 61, Loss: 0.18057800328998425, Error (MAE): 0.12981139140120193\n",
      "Epoch: 62, Loss: 0.1805440180782062, Error (MAE): 0.12977498519554068\n",
      "Epoch: 63, Loss: 0.18053254696415433, Error (MAE): 0.12974980139910286\n",
      "Epoch: 64, Loss: 0.18046180536942696, Error (MAE): 0.12974220442015733\n",
      "Epoch: 65, Loss: 0.1803680121231435, Error (MAE): 0.12966624547296496\n",
      "Epoch: 66, Loss: 0.1803158322599397, Error (MAE): 0.12961706658130262\n",
      "Epoch: 67, Loss: 0.18032494721127978, Error (MAE): 0.12957586698345283\n",
      "Epoch: 68, Loss: 0.18024534520818225, Error (MAE): 0.12953687136742606\n",
      "Epoch: 69, Loss: 0.18019149697093823, Error (MAE): 0.12949937854462595\n",
      "Epoch: 70, Loss: 0.18016776142280494, Error (MAE): 0.12947586634710653\n",
      "Epoch: 71, Loss: 0.18011185337803257, Error (MAE): 0.12942916988881667\n",
      "Epoch: 72, Loss: 0.1800062403972469, Error (MAE): 0.12937250271884362\n",
      "Epoch: 73, Loss: 0.18000176237590276, Error (MAE): 0.12934249494947606\n",
      "Epoch: 74, Loss: 0.1799751086466348, Error (MAE): 0.12933163211416843\n",
      "Epoch: 75, Loss: 0.17994877195625164, Error (MAE): 0.12930029875306942\n",
      "Epoch: 76, Loss: 0.17987657371741622, Error (MAE): 0.12926509559376917\n",
      "Epoch: 77, Loss: 0.17987933454673682, Error (MAE): 0.12923804058957455\n",
      "Epoch: 78, Loss: 0.179863392639516, Error (MAE): 0.12922271891538775\n",
      "Epoch: 79, Loss: 0.17987731032407106, Error (MAE): 0.12920936058039095\n",
      "Epoch: 80, Loss: 0.17981866669299, Error (MAE): 0.12918671459626796\n",
      "Epoch: 81, Loss: 0.17976477775555938, Error (MAE): 0.12913658569997816\n",
      "Epoch: 82, Loss: 0.17975478330210073, Error (MAE): 0.12912837449294418\n",
      "Epoch: 83, Loss: 0.17977875081905678, Error (MAE): 0.12913578859905697\n",
      "Epoch: 84, Loss: 0.17982587207164338, Error (MAE): 0.12913063630016883\n",
      "Epoch: 85, Loss: 0.17981811957572824, Error (MAE): 0.1291355125939668\n",
      "Epoch: 86, Loss: 0.1798369950100557, Error (MAE): 0.12911232794398692\n",
      "Epoch: 87, Loss: 0.1798202497745628, Error (MAE): 0.1291217122282555\n",
      "Epoch: 88, Loss: 0.17978092227409134, Error (MAE): 0.12905080377388356\n",
      "Epoch: 89, Loss: 0.17968530296834548, Error (MAE): 0.12898676753488938\n",
      "Epoch: 90, Loss: 0.17965456665451848, Error (MAE): 0.1289405422980216\n",
      "Epoch: 91, Loss: 0.1795863180018183, Error (MAE): 0.12892347707677243\n",
      "Epoch: 92, Loss: 0.17948118397104207, Error (MAE): 0.12887140402375763\n",
      "Epoch: 93, Loss: 0.17939722582475462, Error (MAE): 0.12881095273726023\n",
      "Epoch: 94, Loss: 0.17937713160888472, Error (MAE): 0.12877527924615945\n",
      "Epoch: 95, Loss: 0.17930621865080365, Error (MAE): 0.12874263736294278\n",
      "Epoch: 96, Loss: 0.1793151504513043, Error (MAE): 0.12872948019362207\n",
      "Epoch: 97, Loss: 0.17928204296240166, Error (MAE): 0.1287100230023932\n",
      "Epoch: 98, Loss: 0.17927499082106263, Error (MAE): 0.12869903995697177\n",
      "Epoch: 99, Loss: 0.17926034331321716, Error (MAE): 0.1286751719664282\n",
      "Epoch: 100, Loss: 0.17921514197516797, Error (MAE): 0.12863796321091367\n",
      "Epoch: 101, Loss: 0.17918586163823283, Error (MAE): 0.12861297296276733\n",
      "Epoch: 102, Loss: 0.17913775524096703, Error (MAE): 0.12857143314027075\n",
      "Epoch: 103, Loss: 0.17916222639493087, Error (MAE): 0.12856976042932539\n",
      "Epoch: 104, Loss: 0.1791487540771712, Error (MAE): 0.12852931033764312\n",
      "Epoch: 105, Loss: 0.1791254713464139, Error (MAE): 0.12854705912186137\n",
      "Epoch: 106, Loss: 0.17911510558715507, Error (MAE): 0.12852592221391734\n",
      "Epoch: 107, Loss: 0.1791296633544253, Error (MAE): 0.1285171306400157\n",
      "Epoch: 108, Loss: 0.17915259368384062, Error (MAE): 0.12850664444823764\n",
      "Epoch: 109, Loss: 0.17926502961720994, Error (MAE): 0.12853388249206898\n",
      "Epoch: 110, Loss: 0.17924612037726304, Error (MAE): 0.1285345718931796\n",
      "Epoch: 111, Loss: 0.17910295891672817, Error (MAE): 0.12846899972255552\n",
      "Epoch: 112, Loss: 0.17893505107555815, Error (MAE): 0.12836427363886763\n",
      "Epoch: 113, Loss: 0.17891428652983993, Error (MAE): 0.12831253397153386\n",
      "Epoch: 114, Loss: 0.17878889281358293, Error (MAE): 0.1282410534904964\n",
      "Epoch: 115, Loss: 0.17872091138095997, Error (MAE): 0.12819459194790073\n",
      "Epoch: 116, Loss: 0.17865958754251252, Error (MAE): 0.12814586670763456\n",
      "Epoch: 117, Loss: 0.17867183284973032, Error (MAE): 0.12814682988978143\n",
      "Epoch: 118, Loss: 0.17862927168607712, Error (MAE): 0.12811560823179002\n",
      "Epoch: 119, Loss: 0.17859789773599424, Error (MAE): 0.12811156656982295\n",
      "Epoch: 120, Loss: 0.17862613376841616, Error (MAE): 0.12811428458610577\n",
      "Epoch: 121, Loss: 0.1786864179728636, Error (MAE): 0.1281419126733915\n",
      "Epoch: 122, Loss: 0.1787445450674242, Error (MAE): 0.12813763831978414\n",
      "Epoch: 123, Loss: 0.1787629973754954, Error (MAE): 0.12813703182028302\n",
      "Epoch: 124, Loss: 0.17869118400918904, Error (MAE): 0.12810383787128463\n",
      "Epoch: 125, Loss: 0.17871269694904782, Error (MAE): 0.12811562963830891\n",
      "Epoch: 126, Loss: 0.1787224494254411, Error (MAE): 0.12808822996135968\n",
      "Epoch: 127, Loss: 0.17858861075408422, Error (MAE): 0.12802527728143023\n",
      "Epoch: 128, Loss: 0.17848628903947658, Error (MAE): 0.12795075535107014\n",
      "Epoch: 129, Loss: 0.17840660596961405, Error (MAE): 0.12789208286288958\n",
      "Epoch: 130, Loss: 0.1783649097405263, Error (MAE): 0.12785730093939981\n",
      "Epoch: 131, Loss: 0.17832983996885926, Error (MAE): 0.12781969557947187\n",
      "Epoch: 132, Loss: 0.17825352956554782, Error (MAE): 0.1277812017100071\n",
      "Epoch: 133, Loss: 0.1782131425257939, Error (MAE): 0.12776034853574056\n",
      "Epoch: 134, Loss: 0.1781952704733877, Error (MAE): 0.12774365723355494\n",
      "Epoch: 135, Loss: 0.17818572438919722, Error (MAE): 0.12773935124278069\n",
      "Epoch: 136, Loss: 0.17818050876037397, Error (MAE): 0.12772105656453034\n",
      "Epoch: 137, Loss: 0.17820603656235026, Error (MAE): 0.127729818558515\n",
      "Epoch: 138, Loss: 0.17817522418587955, Error (MAE): 0.1277010255673928\n",
      "Epoch: 139, Loss: 0.17816585024346165, Error (MAE): 0.1276826435950265\n",
      "Epoch: 140, Loss: 0.17815018411892564, Error (MAE): 0.12766560684166736\n",
      "Epoch: 141, Loss: 0.17819615153234397, Error (MAE): 0.1277013881437814\n",
      "Epoch: 142, Loss: 0.17820539314355424, Error (MAE): 0.12769769070975817\n",
      "Epoch: 143, Loss: 0.17819340860665733, Error (MAE): 0.12768272905429798\n",
      "Epoch: 144, Loss: 0.17814472662423975, Error (MAE): 0.12764325120778225\n",
      "Epoch: 145, Loss: 0.17817877722320272, Error (MAE): 0.12765108549327991\n",
      "Epoch: 146, Loss: 0.17813128966893724, Error (MAE): 0.1276145395614318\n",
      "Epoch: 147, Loss: 0.1780251376886866, Error (MAE): 0.1275431412591863\n",
      "Epoch: 148, Loss: 0.17796429024258656, Error (MAE): 0.12750098426172982\n",
      "Epoch: 149, Loss: 0.17793967352429432, Error (MAE): 0.12747330969171738\n",
      "Epoch: 150, Loss: 0.1779082054967311, Error (MAE): 0.1274590639036093\n",
      "Epoch: 151, Loss: 0.1779016297477395, Error (MAE): 0.12743694641029657\n",
      "Epoch: 152, Loss: 0.177866668954714, Error (MAE): 0.127429463747722\n",
      "Epoch: 153, Loss: 0.1777965409764603, Error (MAE): 0.1273834906629662\n",
      "Epoch: 154, Loss: 0.17777140627601254, Error (MAE): 0.1273456905871185\n",
      "Epoch: 155, Loss: 0.17775365176485547, Error (MAE): 0.12733360452216064\n",
      "Epoch: 156, Loss: 0.17773362182414354, Error (MAE): 0.12731152383694008\n",
      "Epoch: 157, Loss: 0.17772243360974896, Error (MAE): 0.12730209746245127\n",
      "Epoch: 158, Loss: 0.17770764776575032, Error (MAE): 0.12729420885443687\n",
      "Epoch: 159, Loss: 0.17766645951057547, Error (MAE): 0.12726055068978623\n",
      "Epoch: 160, Loss: 0.17763972104485357, Error (MAE): 0.1272363786710732\n",
      "Epoch: 161, Loss: 0.17762722275150356, Error (MAE): 0.12720650023044044\n",
      "Epoch: 162, Loss: 0.17762532785757265, Error (MAE): 0.12720504453155532\n",
      "Epoch: 163, Loss: 0.17757244397010377, Error (MAE): 0.12717273892528974\n",
      "Epoch: 164, Loss: 0.17757783073987535, Error (MAE): 0.12717593010904185\n",
      "Epoch: 165, Loss: 0.17759671073351332, Error (MAE): 0.12718078093742258\n",
      "Epoch: 166, Loss: 0.17757195990477034, Error (MAE): 0.127149711793928\n",
      "Epoch: 167, Loss: 0.1775284828757172, Error (MAE): 0.12711924853831974\n",
      "Epoch: 168, Loss: 0.17752315915787398, Error (MAE): 0.12711425047757022\n",
      "Epoch: 169, Loss: 0.17756126620876256, Error (MAE): 0.12712553404827617\n",
      "Epoch: 170, Loss: 0.17752506205839896, Error (MAE): 0.12708685219065466\n",
      "Epoch: 171, Loss: 0.177426097108357, Error (MAE): 0.1270271351755555\n",
      "Epoch: 172, Loss: 0.17739638953066583, Error (MAE): 0.12700887741660005\n",
      "Epoch: 173, Loss: 0.17740997649840454, Error (MAE): 0.12700354063244007\n",
      "Epoch: 174, Loss: 0.17742529111122018, Error (MAE): 0.12701884039969585\n",
      "Epoch: 175, Loss: 0.17746015782676525, Error (MAE): 0.1270373662683501\n",
      "Epoch: 176, Loss: 0.1773861288579542, Error (MAE): 0.12699752100812856\n",
      "Epoch: 177, Loss: 0.17733535693207783, Error (MAE): 0.12694557127890302\n",
      "Epoch: 178, Loss: 0.17733492168472775, Error (MAE): 0.12694206188863782\n",
      "Epoch: 179, Loss: 0.17737739688869733, Error (MAE): 0.12693985607197036\n",
      "Epoch: 180, Loss: 0.17731479043836024, Error (MAE): 0.12690962111549592\n",
      "Epoch: 181, Loss: 0.17725054908599427, Error (MAE): 0.12685533713048963\n",
      "Epoch: 182, Loss: 0.1772215324106501, Error (MAE): 0.12684755944716397\n",
      "Epoch: 183, Loss: 0.17719370137844512, Error (MAE): 0.12681259020273364\n",
      "Epoch: 184, Loss: 0.17720127706207447, Error (MAE): 0.12682877341980364\n",
      "Epoch: 185, Loss: 0.1772249640146298, Error (MAE): 0.1268325540334431\n",
      "Epoch: 186, Loss: 0.17720275249943804, Error (MAE): 0.1268200512919853\n",
      "Epoch: 187, Loss: 0.17719423982189664, Error (MAE): 0.12681629442012132\n",
      "Epoch: 188, Loss: 0.17718529400985633, Error (MAE): 0.1268086806495688\n",
      "Epoch: 189, Loss: 0.17718783020973206, Error (MAE): 0.1268010037158852\n",
      "Epoch: 190, Loss: 0.17720773304576304, Error (MAE): 0.12681747605996346\n",
      "Epoch: 191, Loss: 0.17719831028536184, Error (MAE): 0.12679479610341698\n",
      "Epoch: 192, Loss: 0.1770993738032099, Error (MAE): 0.12672961069576777\n",
      "Epoch: 193, Loss: 0.1771061270317035, Error (MAE): 0.1267267726917765\n",
      "Epoch: 194, Loss: 0.17709962801257176, Error (MAE): 0.1267364684547951\n",
      "Epoch: 195, Loss: 0.17710169382504562, Error (MAE): 0.12672803284072165\n",
      "Epoch: 196, Loss: 0.17703308999093612, Error (MAE): 0.12667659764636807\n",
      "Epoch: 197, Loss: 0.17702498364804395, Error (MAE): 0.12665235996246338\n",
      "Epoch: 198, Loss: 0.17702254219286478, Error (MAE): 0.12664708895469778\n",
      "Epoch: 199, Loss: 0.17700399391686739, Error (MAE): 0.12663940156796086\n",
      "Epoch: 200, Loss: 0.17694721059567892, Error (MAE): 0.12660329966847575\n",
      "MAE: 0.13249607384204865\n",
      "MAE: 0.16478902101516724\n",
      "MAE: 0.13809651136398315\n",
      "MAE: 0.1440071165561676\n",
      "MAE: 0.13160531222820282\n",
      "MAE: 0.161261186003685\n",
      "MAE: 0.1565517634153366\n",
      "MAE: 0.3051508963108063\n",
      "MAE: 0.13195770978927612\n",
      "MAE: 0.1242058202624321\n",
      "MAE: 0.12578006088733673\n",
      "MAE: 0.12766923010349274\n",
      "MAE: 0.13643935322761536\n",
      "MAE: 0.14751958847045898\n",
      "MAE: 0.1281459629535675\n",
      "MAE: 0.13296638429164886\n",
      "MAE: 0.13291573524475098\n",
      "MAE: 0.14270295202732086\n",
      "MAE: 0.13062620162963867\n",
      "MAE: 0.12027809023857117\n",
      "MAE: 0.16502311825752258\n",
      "MAE: 0.12418603897094727\n",
      "MAE: 0.12284030020236969\n",
      "MAE: 0.13952764868736267\n",
      "MAE: 0.1268816590309143\n",
      "MAE: 0.15322482585906982\n",
      "MAE: 0.15585264563560486\n",
      "MAE: 0.13890337944030762\n",
      "MAE: 0.14368624985218048\n",
      "MAE: 0.1251603662967682\n",
      "MAE: 0.15626978874206543\n",
      "MAE: 0.13556300103664398\n",
      "MAE: 0.13481329381465912\n",
      "Test error MAE: 0.14354840259660373\n",
      "Epoch: 1, Loss: 0.1826517514106053, Error (MAE): 0.1321118859880006\n",
      "Epoch: 2, Loss: 0.18116483181270202, Error (MAE): 0.1307036699866181\n",
      "Epoch: 3, Loss: 0.1803763185196848, Error (MAE): 0.12996296228757545\n",
      "Epoch: 4, Loss: 0.17997157640421568, Error (MAE): 0.12957194758884943\n",
      "Epoch: 5, Loss: 0.1796657681020338, Error (MAE): 0.12928933744777493\n",
      "Epoch: 6, Loss: 0.17947272578282142, Error (MAE): 0.1291000692924457\n",
      "Epoch: 7, Loss: 0.1793438691034246, Error (MAE): 0.12896510030129063\n",
      "Epoch: 8, Loss: 0.17924418300390244, Error (MAE): 0.12886361633218937\n",
      "Epoch: 9, Loss: 0.17912417683583587, Error (MAE): 0.12876265957506736\n",
      "Epoch: 10, Loss: 0.17905955105575164, Error (MAE): 0.12869334048522052\n",
      "Epoch: 11, Loss: 0.1789962946256595, Error (MAE): 0.12862116721139025\n",
      "Epoch: 12, Loss: 0.17893747284786024, Error (MAE): 0.12857218731695147\n",
      "Epoch: 13, Loss: 0.17887840353286089, Error (MAE): 0.12852043964302362\n",
      "Epoch: 14, Loss: 0.17885954878223476, Error (MAE): 0.1284956328793248\n",
      "Epoch: 15, Loss: 0.17876791798356753, Error (MAE): 0.12842538747102467\n",
      "Epoch: 16, Loss: 0.17875136223746768, Error (MAE): 0.1284042421672771\n",
      "Epoch: 17, Loss: 0.17869178105646105, Error (MAE): 0.12834321963253306\n",
      "Epoch: 18, Loss: 0.17867916477705115, Error (MAE): 0.12831986884572613\n",
      "Epoch: 19, Loss: 0.17859443610728676, Error (MAE): 0.12825484840727563\n",
      "Epoch: 20, Loss: 0.17857461500523694, Error (MAE): 0.12822498180972997\n",
      "Epoch: 21, Loss: 0.17851727055524713, Error (MAE): 0.12817291431684993\n",
      "Epoch: 22, Loss: 0.1785177923182943, Error (MAE): 0.12816592294778398\n",
      "Epoch: 23, Loss: 0.17845791834059047, Error (MAE): 0.12811846035852362\n",
      "Epoch: 24, Loss: 0.17848346126613332, Error (MAE): 0.12814379956072836\n",
      "Epoch: 25, Loss: 0.1784782866711047, Error (MAE): 0.1281334205127474\n",
      "Epoch: 26, Loss: 0.17845106981138684, Error (MAE): 0.1281042232442258\n",
      "Epoch: 27, Loss: 0.1784375895982358, Error (MAE): 0.12809160318392426\n",
      "Epoch: 28, Loss: 0.17845297437995228, Error (MAE): 0.12810048944692112\n",
      "Epoch: 29, Loss: 0.17838858379356898, Error (MAE): 0.1280510863706247\n",
      "Epoch: 30, Loss: 0.1783700030463845, Error (MAE): 0.12799678526040334\n",
      "Epoch: 31, Loss: 0.17827812771298993, Error (MAE): 0.1279434040744803\n",
      "Epoch: 32, Loss: 0.17828065145816377, Error (MAE): 0.12791340370009194\n",
      "Epoch: 33, Loss: 0.17820645924379577, Error (MAE): 0.12788122720015582\n",
      "Epoch: 34, Loss: 0.17816407622686073, Error (MAE): 0.12783538488976992\n",
      "Epoch: 35, Loss: 0.1781290404832185, Error (MAE): 0.12780085584120965\n",
      "Epoch: 36, Loss: 0.17813445783373136, Error (MAE): 0.12781445320640036\n",
      "Epoch: 37, Loss: 0.17812787163168636, Error (MAE): 0.12779985396052473\n",
      "Epoch: 38, Loss: 0.17807992759035596, Error (MAE): 0.12775225831723924\n",
      "Epoch: 39, Loss: 0.17807075336797915, Error (MAE): 0.12771453608327837\n",
      "Epoch: 40, Loss: 0.1780335376066948, Error (MAE): 0.1277137017294542\n",
      "Epoch: 41, Loss: 0.17803285215327988, Error (MAE): 0.12770015696313844\n",
      "Epoch: 42, Loss: 0.1780110316267654, Error (MAE): 0.1276946378065579\n",
      "Epoch: 43, Loss: 0.17798937112092972, Error (MAE): 0.1276689138430268\n",
      "Epoch: 44, Loss: 0.1779688006239151, Error (MAE): 0.12766239619744357\n",
      "Epoch: 45, Loss: 0.17794360376116056, Error (MAE): 0.1276375570737604\n",
      "Epoch: 46, Loss: 0.1779257384921188, Error (MAE): 0.1276132723511155\n",
      "Epoch: 47, Loss: 0.17790181278737624, Error (MAE): 0.12758044147891784\n",
      "Epoch: 48, Loss: 0.17787515160752765, Error (MAE): 0.12756686212856377\n",
      "Epoch: 49, Loss: 0.17794346598102084, Error (MAE): 0.12753075400172775\n",
      "Epoch: 50, Loss: 0.1778766205951349, Error (MAE): 0.12750432718155988\n",
      "Epoch: 51, Loss: 0.17781289922657298, Error (MAE): 0.1274632556892153\n",
      "Epoch: 52, Loss: 0.1777728570263777, Error (MAE): 0.12744978214822597\n",
      "Epoch: 53, Loss: 0.17775011007020722, Error (MAE): 0.12744040898422695\n",
      "Epoch: 54, Loss: 0.17775536350794693, Error (MAE): 0.12744889597394574\n",
      "Epoch: 55, Loss: 0.17770227645315342, Error (MAE): 0.1273958843701811\n",
      "Epoch: 56, Loss: 0.17766155758455618, Error (MAE): 0.1273802643947637\n",
      "Epoch: 57, Loss: 0.1776764591905608, Error (MAE): 0.12738125304232784\n",
      "Epoch: 58, Loss: 0.17769043258766629, Error (MAE): 0.12739785649438404\n",
      "Epoch: 59, Loss: 0.17762501726844418, Error (MAE): 0.12732799506899137\n",
      "Epoch: 60, Loss: 0.17756676796212126, Error (MAE): 0.12727938631354874\n",
      "Epoch: 61, Loss: 0.17754510645546132, Error (MAE): 0.12726245281189236\n",
      "Epoch: 62, Loss: 0.17759570735159205, Error (MAE): 0.12729342837831867\n",
      "Epoch: 63, Loss: 0.17754952031285015, Error (MAE): 0.12725538927227703\n",
      "Epoch: 64, Loss: 0.17750622754666343, Error (MAE): 0.12721545432708156\n",
      "Epoch: 65, Loss: 0.17752423315350688, Error (MAE): 0.12722927148439991\n",
      "Epoch: 66, Loss: 0.17756833947861372, Error (MAE): 0.12726745265188502\n",
      "Epoch: 67, Loss: 0.17750852410473042, Error (MAE): 0.12722297023926207\n",
      "Epoch: 68, Loss: 0.17744876132972204, Error (MAE): 0.12717053666710854\n",
      "Epoch: 69, Loss: 0.17743177078108288, Error (MAE): 0.12714645822546375\n",
      "Epoch: 70, Loss: 0.17745465885347395, Error (MAE): 0.12715640197049327\n",
      "Epoch: 71, Loss: 0.17740282705470697, Error (MAE): 0.12712076967999117\n",
      "Epoch: 72, Loss: 0.17736893758844974, Error (MAE): 0.12709122034373568\n",
      "Epoch: 73, Loss: 0.1773254187471831, Error (MAE): 0.12704716317022025\n",
      "Epoch: 74, Loss: 0.1773198653957737, Error (MAE): 0.12704150022855445\n",
      "Epoch: 75, Loss: 0.1772783593232952, Error (MAE): 0.12700556935881502\n",
      "Epoch: 76, Loss: 0.17726766184639575, Error (MAE): 0.1270018483498203\n",
      "Epoch: 77, Loss: 0.17724503276508247, Error (MAE): 0.12697607862638005\n",
      "Epoch: 78, Loss: 0.17724924979370033, Error (MAE): 0.12698222296451456\n",
      "Epoch: 79, Loss: 0.1772300653270821, Error (MAE): 0.12695219690230355\n",
      "Epoch: 80, Loss: 0.1772450611217698, Error (MAE): 0.12697498611549832\n",
      "Epoch: 81, Loss: 0.1771947769309158, Error (MAE): 0.1269302711224378\n",
      "Epoch: 82, Loss: 0.17720596581252654, Error (MAE): 0.12692077724791284\n",
      "Epoch: 83, Loss: 0.17719066665688557, Error (MAE): 0.12690088814541475\n",
      "Epoch: 84, Loss: 0.17722169910349064, Error (MAE): 0.12694522232484462\n",
      "Epoch: 85, Loss: 0.1771583269113925, Error (MAE): 0.12689665310196022\n",
      "Epoch: 86, Loss: 0.1771285289259099, Error (MAE): 0.12686639612735207\n",
      "Epoch: 87, Loss: 0.17712237730399885, Error (MAE): 0.1268626610512164\n",
      "Epoch: 88, Loss: 0.1771434241933609, Error (MAE): 0.12687985765845028\n",
      "Epoch: 89, Loss: 0.17707885557146213, Error (MAE): 0.12681938685587982\n",
      "Epoch: 90, Loss: 0.17704114595900722, Error (MAE): 0.1267838265135217\n",
      "Epoch: 91, Loss: 0.17704213199330798, Error (MAE): 0.1267895692431215\n",
      "Epoch: 92, Loss: 0.17707812307930704, Error (MAE): 0.1268177536774927\n",
      "Epoch: 93, Loss: 0.17704010176569668, Error (MAE): 0.12677173099633474\n",
      "Epoch: 94, Loss: 0.1770234066826194, Error (MAE): 0.1267540365346332\n",
      "Epoch: 95, Loss: 0.1770035365401809, Error (MAE): 0.12674978836926062\n",
      "Epoch: 96, Loss: 0.1770072313609408, Error (MAE): 0.12675522062093464\n",
      "Epoch: 97, Loss: 0.17696020952356395, Error (MAE): 0.12670611284339606\n",
      "Epoch: 98, Loss: 0.1769513169776148, Error (MAE): 0.1266870376890275\n",
      "Epoch: 99, Loss: 0.17690143122601865, Error (MAE): 0.1266505552539185\n",
      "Epoch: 100, Loss: 0.17692451868484269, Error (MAE): 0.12666495199968567\n",
      "Epoch: 101, Loss: 0.1769033350161652, Error (MAE): 0.12665837213619432\n",
      "Epoch: 102, Loss: 0.1769471936928692, Error (MAE): 0.12668332746669428\n",
      "Epoch: 103, Loss: 0.17688354204839735, Error (MAE): 0.12663627376974518\n",
      "Epoch: 104, Loss: 0.1768879831504466, Error (MAE): 0.12662354890090316\n",
      "Epoch: 105, Loss: 0.1768893470515066, Error (MAE): 0.12663608411354804\n",
      "Epoch: 106, Loss: 0.17690709333366422, Error (MAE): 0.1266565556401637\n",
      "Epoch: 107, Loss: 0.17684782018412404, Error (MAE): 0.1265989262332667\n",
      "Epoch: 108, Loss: 0.1767897238927101, Error (MAE): 0.126543599667389\n",
      "Epoch: 109, Loss: 0.17675113967105524, Error (MAE): 0.12650833189932267\n",
      "Epoch: 110, Loss: 0.1767290379129239, Error (MAE): 0.12650228769921545\n",
      "Epoch: 111, Loss: 0.17672131544173653, Error (MAE): 0.12647771006867067\n",
      "Epoch: 112, Loss: 0.1767140738110044, Error (MAE): 0.12646534010323127\n",
      "Epoch: 113, Loss: 0.17667168367709687, Error (MAE): 0.12643961486086916\n",
      "Epoch: 114, Loss: 0.17666486939832346, Error (MAE): 0.12644038866482563\n",
      "Epoch: 115, Loss: 0.17666973195858857, Error (MAE): 0.12644377478690288\n",
      "Epoch: 116, Loss: 0.17671259225749258, Error (MAE): 0.12647005748837742\n",
      "Epoch: 117, Loss: 0.1766682508498875, Error (MAE): 0.12643054255576275\n",
      "Epoch: 118, Loss: 0.1766254052297393, Error (MAE): 0.12638891416031922\n",
      "Epoch: 119, Loss: 0.17661378221280538, Error (MAE): 0.12638113831183803\n",
      "Epoch: 120, Loss: 0.17664218638370285, Error (MAE): 0.12641379025889865\n",
      "Epoch: 121, Loss: 0.17664750976793803, Error (MAE): 0.12641129765047956\n",
      "Epoch: 122, Loss: 0.17659029853877736, Error (MAE): 0.12636689135610168\n",
      "Epoch: 123, Loss: 0.17658314086608032, Error (MAE): 0.12634745129008793\n",
      "Epoch: 124, Loss: 0.1765679513562971, Error (MAE): 0.1263380587768199\n",
      "Epoch: 125, Loss: 0.17657972494168067, Error (MAE): 0.12633909229467163\n",
      "Epoch: 126, Loss: 0.17656590266903835, Error (MAE): 0.1263360819265024\n",
      "Epoch: 127, Loss: 0.1765700727701187, Error (MAE): 0.12634511886915165\n",
      "Epoch: 128, Loss: 0.1765887070057997, Error (MAE): 0.12634624974496328\n",
      "Epoch: 129, Loss: 0.17656731182959542, Error (MAE): 0.12633748252445193\n",
      "Epoch: 130, Loss: 0.17656337314132434, Error (MAE): 0.12633350369200777\n",
      "Epoch: 131, Loss: 0.17651562059103554, Error (MAE): 0.12629087141423084\n",
      "Epoch: 132, Loss: 0.17647808122990735, Error (MAE): 0.12624765009577596\n",
      "Epoch: 133, Loss: 0.1764359914544803, Error (MAE): 0.12620799054405582\n",
      "Epoch: 134, Loss: 0.1764443373279785, Error (MAE): 0.12621445158746705\n",
      "Epoch: 135, Loss: 0.1763955025530573, Error (MAE): 0.1261852446999123\n",
      "Epoch: 136, Loss: 0.17640433727360483, Error (MAE): 0.12617507927230934\n",
      "Epoch: 137, Loss: 0.1764024253656615, Error (MAE): 0.12618172569061392\n",
      "Epoch: 138, Loss: 0.17645085869885202, Error (MAE): 0.12621305338037547\n",
      "Epoch: 139, Loss: 0.17640496568003697, Error (MAE): 0.12618369870443844\n",
      "Epoch: 140, Loss: 0.1763762589266051, Error (MAE): 0.1261524617560764\n",
      "Epoch: 141, Loss: 0.17635584667102613, Error (MAE): 0.12613405609753595\n",
      "Epoch: 142, Loss: 0.17636133307841287, Error (MAE): 0.12614332489780525\n",
      "Epoch: 143, Loss: 0.1763430304491698, Error (MAE): 0.12612450717767673\n",
      "Epoch: 144, Loss: 0.17632608427040614, Error (MAE): 0.12610349270390042\n",
      "Epoch: 145, Loss: 0.17627738705321924, Error (MAE): 0.1260650005580774\n",
      "Epoch: 146, Loss: 0.1762915508293394, Error (MAE): 0.12607163969260543\n",
      "Epoch: 147, Loss: 0.1763114435459251, Error (MAE): 0.12609498614250725\n",
      "Epoch: 148, Loss: 0.17632286550838555, Error (MAE): 0.12610407218114653\n",
      "Epoch: 149, Loss: 0.17626715451478958, Error (MAE): 0.12604266883277182\n",
      "Epoch: 150, Loss: 0.17620732145967768, Error (MAE): 0.12598847247548958\n",
      "Epoch: 151, Loss: 0.176262979743196, Error (MAE): 0.12600998535974703\n",
      "Epoch: 152, Loss: 0.17629285034403872, Error (MAE): 0.12606919417852785\n",
      "Epoch: 153, Loss: 0.17626226771233686, Error (MAE): 0.12605128242675936\n",
      "Epoch: 154, Loss: 0.17622224397178907, Error (MAE): 0.12600020586109872\n",
      "Epoch: 155, Loss: 0.17618759710397294, Error (MAE): 0.1259715698325812\n",
      "Epoch: 156, Loss: 0.1761857711557132, Error (MAE): 0.12596669253795895\n",
      "Epoch: 157, Loss: 0.1761642440931121, Error (MAE): 0.12595474608798526\n",
      "Epoch: 158, Loss: 0.17617206175380679, Error (MAE): 0.1259507980030864\n",
      "Epoch: 159, Loss: 0.1761579310048872, Error (MAE): 0.12594396620988846\n",
      "Epoch: 160, Loss: 0.1762073647175262, Error (MAE): 0.12594859496648633\n",
      "Epoch: 161, Loss: 0.17617221465751307, Error (MAE): 0.1259575115322177\n",
      "Epoch: 162, Loss: 0.17615095559340804, Error (MAE): 0.12594854898417174\n",
      "Epoch: 163, Loss: 0.1761155612210729, Error (MAE): 0.12589641994059975\n",
      "Epoch: 164, Loss: 0.17608037146169747, Error (MAE): 0.12586418005512723\n",
      "Epoch: 165, Loss: 0.17609081984455907, Error (MAE): 0.125892631765177\n",
      "Epoch: 166, Loss: 0.17612133686667059, Error (MAE): 0.12590415592291462\n",
      "Epoch: 167, Loss: 0.176085821060992, Error (MAE): 0.12587335177544337\n",
      "Epoch: 168, Loss: 0.17605608179053264, Error (MAE): 0.1258472565061121\n",
      "Epoch: 169, Loss: 0.1760866764321256, Error (MAE): 0.12587552083962\n",
      "Epoch: 170, Loss: 0.1760716813046541, Error (MAE): 0.1258578201505675\n",
      "Epoch: 171, Loss: 0.1760074574111113, Error (MAE): 0.12580588793576652\n",
      "Epoch: 172, Loss: 0.17599006642156573, Error (MAE): 0.1257814749408124\n",
      "Epoch: 173, Loss: 0.17600299918384693, Error (MAE): 0.1257917127613701\n",
      "Epoch: 174, Loss: 0.17600323170868318, Error (MAE): 0.12580174986106246\n",
      "Epoch: 175, Loss: 0.17599417536116357, Error (MAE): 0.12579041219024517\n",
      "Epoch: 176, Loss: 0.17595414761731873, Error (MAE): 0.12574845435681628\n",
      "Epoch: 177, Loss: 0.1759115239577507, Error (MAE): 0.12571079934488483\n",
      "Epoch: 178, Loss: 0.17590787028198812, Error (MAE): 0.1257021350424681\n",
      "Epoch: 179, Loss: 0.17591851382558024, Error (MAE): 0.12571790680956485\n",
      "Epoch: 180, Loss: 0.17589998623328423, Error (MAE): 0.12569998477154704\n",
      "Epoch: 181, Loss: 0.175864018944662, Error (MAE): 0.12567058266766035\n",
      "Epoch: 182, Loss: 0.17585688351250406, Error (MAE): 0.12566104225480734\n",
      "Epoch: 183, Loss: 0.17587597045435835, Error (MAE): 0.12567705232928048\n",
      "Epoch: 184, Loss: 0.1758980131638584, Error (MAE): 0.1256804459575397\n",
      "Epoch: 185, Loss: 0.1758616225265745, Error (MAE): 0.12566845452607567\n",
      "Epoch: 186, Loss: 0.175879284850697, Error (MAE): 0.12567608219696513\n",
      "Epoch: 187, Loss: 0.17590001258832305, Error (MAE): 0.12570488008100594\n",
      "Epoch: 188, Loss: 0.17589188622894572, Error (MAE): 0.12569894135665538\n",
      "Epoch: 189, Loss: 0.17587903575665914, Error (MAE): 0.12567946576138042\n",
      "Epoch: 190, Loss: 0.1758461865916181, Error (MAE): 0.12565841047621484\n",
      "Epoch: 191, Loss: 0.17583463062990956, Error (MAE): 0.1256466259929671\n",
      "Epoch: 192, Loss: 0.17583148070235752, Error (MAE): 0.12563420887758484\n",
      "Epoch: 193, Loss: 0.17581480085404952, Error (MAE): 0.1256204599987215\n",
      "Epoch: 194, Loss: 0.1757809923433546, Error (MAE): 0.1255931744713392\n",
      "Epoch: 195, Loss: 0.17575033287059016, Error (MAE): 0.1255616534000902\n",
      "Epoch: 196, Loss: 0.17574055648561734, Error (MAE): 0.1255501082806445\n",
      "Epoch: 197, Loss: 0.17575322147180786, Error (MAE): 0.1255539468308883\n",
      "Epoch: 198, Loss: 0.17573596670556424, Error (MAE): 0.1255457065999508\n",
      "Epoch: 199, Loss: 0.17570661931340373, Error (MAE): 0.12550703714142986\n",
      "Epoch: 200, Loss: 0.17568149706765787, Error (MAE): 0.12549070719240316\n",
      "MAE: 0.19774450361728668\n",
      "MAE: 0.13142172992229462\n",
      "MAE: 0.1379563808441162\n",
      "MAE: 0.15059448778629303\n",
      "MAE: 0.18542778491973877\n",
      "MAE: 0.1325281411409378\n",
      "MAE: 0.12165137380361557\n",
      "MAE: 0.13214410841464996\n",
      "MAE: 0.12427198141813278\n",
      "MAE: 0.1282876878976822\n",
      "MAE: 0.14267267286777496\n",
      "MAE: 0.13397683203220367\n",
      "MAE: 0.1886046975851059\n",
      "MAE: 0.12844687700271606\n",
      "MAE: 0.13568516075611115\n",
      "MAE: 0.13688869774341583\n",
      "MAE: 0.13183733820915222\n",
      "MAE: 0.12914684414863586\n",
      "MAE: 0.14685463905334473\n",
      "MAE: 0.1307484209537506\n",
      "MAE: 0.12103530764579773\n",
      "MAE: 0.12366829067468643\n",
      "MAE: 0.15327924489974976\n",
      "MAE: 0.12699705362319946\n",
      "MAE: 0.1429484635591507\n",
      "MAE: 0.1356612592935562\n",
      "MAE: 0.12244144082069397\n",
      "MAE: 0.13786347210407257\n",
      "MAE: 0.13079270720481873\n",
      "MAE: 0.13294380903244019\n",
      "MAE: 0.13135452568531036\n",
      "MAE: 0.13057520985603333\n",
      "MAE: 0.1300348937511444\n",
      "Test error MAE: 0.13837836479598825\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in cv.split(subjects_adj):\n",
    "    train_adj, val_adj = subjects_adj[train_index], subjects_adj[test_index]\n",
    "    train_labels, val_labels = subjects_labels[train_index], subjects_labels[test_index]\n",
    "\n",
    "    train(model, optimizer, train_adj, train_labels, args)\n",
    "    test(model, val_adj, val_labels, args)\n",
    "\n",
    "# Save trained model\n",
    "torch.save(model.state_dict(), \"gsr_net_trained.pth\")\n",
    "print(\"Model saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created!\n"
     ]
    }
   ],
   "source": [
    "# Load trained model\n",
    "model.load_state_dict(torch.load(\"gsr_net_trained.pth\"))\n",
    "model.eval()  # Ensure evaluation mode\n",
    "\n",
    "# Generate predictions\n",
    "preds_list = []\n",
    "for lr in test_adj:\n",
    "    lr = torch.from_numpy(lr).float().to(device)\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        preds, _, _, _ = model(lr)  # Get predictions\n",
    "    preds_list.append(preds.detach().cpu().numpy())  # Convert to NumPy\n",
    "\n",
    "# Extract only upper triangular part (excluding diagonal)\n",
    "def upper_triangular_flatten(matrix):\n",
    "    return matrix[np.triu_indices(268, k=1)]  # k=1 excludes diagonal\n",
    "\n",
    "# Apply upper triangular flattening to all predictions\n",
    "preds_list = [upper_triangular_flatten(pred) for pred in preds_list]\n",
    "\n",
    "# Create DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    \"ID\": np.arange(1, len(np.concatenate(preds_list)) + 1),  # Sequential IDs\n",
    "    \"Predicted\": np.concatenate(preds_list)  # Flattened predictions\n",
    "})\n",
    "\n",
    "# Save CSV\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Submission file created!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 71.2M/71.2M [00:02<00:00, 29.5MB/s]\n",
      "Successfully submitted to DGL 2025: Brain Graph Super-Resolution Challenge"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c dgl-2025-brain-graph-super-resolution-challenge -f submission.csv -m \"GSR-Net submission\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
