{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T00:06:48.775872Z",
     "start_time": "2025-03-02T00:06:45.364490Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" \n",
    "\n",
    "\n",
    "import torch_geometric\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, TopKPooling, global_mean_pool, GraphUNet\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from utils.data import GraphDataModule, save_prediction\n",
    "from utils.training import train_model\n",
    "from utils.metrics import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d3a6ae3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T00:07:13.123356Z",
     "start_time": "2025-03-02T00:07:13.109763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e34fa3e9ebc9bb47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T00:07:20.093551Z",
     "start_time": "2025-03-02T00:07:15.538182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to load ./data/hr_train.csv: 3.856825590133667 seconds\n",
      "Time taken to load ./data/lr_train.csv: 0.8724327087402344 seconds\n",
      "Time taken to load ./data/lr_test.csv: 0.434659481048584 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting vectors to graphs: 100%|██████████| 133/133 [00:00<00:00, 257.55it/s]\n",
      "Converting vectors to graphs: 100%|██████████| 34/34 [00:00<00:00, 263.29it/s]\n",
      "Converting vectors to graphs: 100%|██████████| 112/112 [00:00<00:00, 747.29it/s]\n"
     ]
    }
   ],
   "source": [
    "data_module = GraphDataModule(\"./data\", num_workers=1, batch_size=1)\n",
    "train_loader = data_module.train_dataloader()\n",
    "val_loader = data_module.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a6bd62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_PCA(batch, n_components=None):\n",
    "    cov_matrix = to_dense_adj(batch.edge_index, edge_attr=batch.edge_attr, batch=batch.batch)\n",
    "    eigenvalues, eigenvectors = torch.linalg.eigh(cov_matrix)\n",
    "    \n",
    "    return {\n",
    "        'eigenvalues': eigenvalues.squeeze(),\n",
    "        'eigenvectors': eigenvectors.squeeze()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5c15b0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T00:26:48.537483Z",
     "start_time": "2025-03-02T00:26:48.530222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 160 268\n"
     ]
    }
   ],
   "source": [
    "batch,target_batch = next(iter(train_loader))\n",
    "input_dim = batch[0].x.shape[0]\n",
    "output_dim = target_batch[0].x.shape[0]\n",
    "input_features = batch[0].x.shape[1]\n",
    "print(input_features,input_dim,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "723a6969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_list_features(batch_list,ncomp):\n",
    "    A_list = [\n",
    "        to_dense_adj(batch.edge_index, edge_attr=batch.edge_attr, batch=batch.batch)\n",
    "        for batch in batch_list\n",
    "    ]\n",
    "    A = torch.zeros_like(A_list[0])\n",
    "    for a in A_list: A += a\n",
    "    \n",
    "    eigenvalues, eigenvectors = torch.linalg.eigh(A)\n",
    "    \n",
    "    eigenvalues = eigenvalues.squeeze()\n",
    "    eigenvectors = eigenvectors.squeeze()\n",
    "    # Get indices of top ncomp largest absolute eigenvalues\n",
    "    _, top_indices = torch.topk(eigenvalues.abs(), k=ncomp)\n",
    "    Q = eigenvectors[:,top_indices]\n",
    "\n",
    "    return Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06bcae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_adj(batch, Q):\n",
    "    A = to_dense_adj(batch.edge_index, edge_attr=batch.edge_attr, batch=batch.batch).squeeze()\n",
    "    C = (Q.t() @ A @ Q).to(torch.cfloat)\n",
    "    C = torch.diag(torch.diag(C))\n",
    "    C = C ** (1/2)\n",
    "    return Q.to(torch.cfloat) @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c819d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(batch, ncomp):\n",
    "    pca_batch = compute_PCA(batch)\n",
    "    \n",
    "    # Get absolute eigenvalues and sort them in descending order\n",
    "    abs_eigenvalues = pca_batch[\"eigenvalues\"].abs()\n",
    "    \n",
    "    # Get indices of top ncomp largest absolute eigenvalues\n",
    "    _, top_indices = torch.topk(abs_eigenvalues, k=ncomp)\n",
    "    \n",
    "    # Select eigenvectors and eigenvalues corresponding to top ncomp\n",
    "    Q = pca_batch[\"eigenvectors\"][:,top_indices].to(torch.cfloat)\n",
    "    D = torch.diag(pca_batch[\"eigenvalues\"]).to(torch.cfloat)\n",
    "    D2 = D ** (1/2)\n",
    "    D2 = D2[:,top_indices][top_indices,:]\n",
    "    Q2 = Q @ D2\n",
    "    \n",
    "    return Q2, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89891333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.12389832756975118)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_list = [batch for batch,_ in iter(train_loader)]\n",
    "target_list = [batch for _,batch in iter(train_loader)]\n",
    "Q1 = compute_list_features(batch_list, 128)\n",
    "Q2 = compute_list_features(target_list, 256)\n",
    "\n",
    "mean_list = []\n",
    "for batch,_ in val_loader:\n",
    "    Q0 = project_adj(batch, Q1)\n",
    "\n",
    "    cov_hat = (Q0 @ Q0.t()).to(torch.float)\n",
    "    cov = to_dense_adj(batch.edge_index, edge_attr=batch.edge_attr, batch=batch.batch).squeeze()\n",
    "\n",
    "    mean_list.append(torch.mean((cov_hat-cov).abs()).item())\n",
    "\n",
    "np.mean(mean_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60c5958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, BatchNorm1d, Dropout, TransformerEncoder, TransformerEncoderLayer\n",
    "from torch_geometric.nn import GATConv, GCNConv, GINConv, global_add_pool\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class UpscalerGNN(nn.Module):\n",
    "    def __init__(self, hidden_size, hidden_layers, Q1,Q2):\n",
    "        super().__init__()\n",
    "        self.Q1 = Q1\n",
    "        self.Q2 = Q2\n",
    "        self.input_nodes = 160\n",
    "        self.output_nodes = 268\n",
    "        \n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(\n",
    "            nn.Sequential(\n",
    "                nn.Linear(in_features=128, out_features=hidden_size),\n",
    "                nn.BatchNorm1d(num_features=hidden_size),\n",
    "                nn.Dropout(p=0.1),\n",
    "                nn.LeakyReLU()\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for _ in range(hidden_layers):\n",
    "            self.layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "                    nn.BatchNorm1d(num_features=hidden_size),\n",
    "                    nn.Dropout(p=0.1),\n",
    "                    nn.LeakyReLU()\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.layers.append(\n",
    "            nn.Sequential(\n",
    "                nn.Linear(in_features=hidden_size, out_features=256),\n",
    "                nn.BatchNorm1d(num_features=hidden_size),\n",
    "                nn.Dropout(p=0.1),\n",
    "                nn.LeakyReLU()\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        \n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def forward(self, samples: Batch): \n",
    "        A = to_dense_adj(batch.edge_index, edge_attr=batch.edge_attr, batch=batch.batch).squeeze().to(self.device)\n",
    "        C = self.Q1.t() @ A @ self.Q1\n",
    "        C = C.squeeze()\n",
    "        C = torch.diag(C).unsqueeze(0)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            C = layer(C)\n",
    "\n",
    "        C = torch.diag(C.squeeze())\n",
    "        return self.Q2 @ C @ self.Q2.t()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6cd7ae3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T00:26:49.520888Z",
     "start_time": "2025-03-02T00:26:49.507098Z"
    }
   },
   "outputs": [],
   "source": [
    "model = UpscalerGNN(\n",
    "    hidden_size=256, \n",
    "    hidden_layers=1,\n",
    "    Q1=Q1.to(device),\n",
    "    Q2=Q2.to(device)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60478db46877fe03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T00:27:12.555892200Z",
     "start_time": "2025-03-02T00:26:51.150648Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected 2D or 3D input (got 1D input)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mL1Loss()\n\u001b[0;32m----> 3\u001b[0m train_loss_history, val_loss_history, lr_history, best_model_state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DGL-Group-Project/utils/training.py:92\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataloader, val_dataloader, num_epochs, lr, validate_every, optimizer, lr_scheduler, criterion, skip)\u001b[0m\n\u001b[1;32m     89\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Forward pass on training data\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Assuming y contains the target adjacency information\u001b[39;00m\n\u001b[1;32m     95\u001b[0m targets \u001b[38;5;241m=\u001b[39m to_dense_adj(target_batch\u001b[38;5;241m.\u001b[39medge_index, edge_attr\u001b[38;5;241m=\u001b[39mtarget_batch\u001b[38;5;241m.\u001b[39medge_attr, batch\u001b[38;5;241m=\u001b[39mtarget_batch\u001b[38;5;241m.\u001b[39mbatch)\n",
      "File \u001b[0;32m~/DGL-Group-Project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DGL-Group-Project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[28], line 58\u001b[0m, in \u001b[0;36mUpscalerGNN.forward\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m     55\u001b[0m C \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdiag(C)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 58\u001b[0m     C \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mC\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m C \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdiag(C)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ2 \u001b[38;5;241m@\u001b[39m C \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ2\u001b[38;5;241m.\u001b[39mt()\n",
      "File \u001b[0;32m~/DGL-Group-Project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DGL-Group-Project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/DGL-Group-Project/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/DGL-Group-Project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DGL-Group-Project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/DGL-Group-Project/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:160\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_input_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# exponential_average_factor is set to self.momentum\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# (when it is available) only so that it gets updated\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# in ONNX graph when this node is exported to ONNX.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/DGL-Group-Project/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:341\u001b[0m, in \u001b[0;36mBatchNorm1d._check_input_dim\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_input_dim\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 341\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected 2D or 3D input (got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD input)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: expected 2D or 3D input (got 1D input)"
     ]
    }
   ],
   "source": [
    "criterion = nn.L1Loss()\n",
    "\n",
    "train_loss_history, val_loss_history, lr_history, best_model_state_dict = train_model(\n",
    "    model=model, \n",
    "    train_dataloader=train_loader, \n",
    "    val_dataloader=val_loader,\n",
    "    criterion=criterion,\n",
    "    num_epochs=100,\n",
    "    lr=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96cfee88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T00:12:05.873778Z",
     "start_time": "2025-03-02T00:12:05.689368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19591764\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(best_model_state_dict)\n",
    "loss = evaluate_model(model, val_loader)\n",
    "print(loss)\n",
    "\n",
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "737d15d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c22f927",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"model.pth\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "914e84d0f1dba99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = data_module.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f14c7a044c71f324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 0)\n"
     ]
    }
   ],
   "source": [
    "submission_file = \"outputs/test/submission.csv\"\n",
    "save_prediction(model, test_dataloader, submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f2efd30d9c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab8416213942339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle competitions submit -c dgl-2025-brain-graph-super-resolution-challenge -f outputs/test/submission.csv -m \"test\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
