{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-07T13:32:53.570926Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" \n",
    "\n",
    "\n",
    "import torch_geometric\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, TopKPooling, global_mean_pool, GraphUNet\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from utils.data import GraphDataModule, save_prediction\n",
    "from utils.training import train_model\n",
    "from utils.metrics import evaluate_model\n",
    "from utils.evaluation import evaluate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a6ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9576469fe37411",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34fa3e9ebc9bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = GraphDataModule(\"./data\", num_workers=1, k_folds=k_folds, p_val=0.33)\n",
    "train_loaders = data_module.train_dataloaders()\n",
    "val_loaders = data_module.val_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334b874b7023c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from torch_geometric.data import Batch\n",
    "import torch.nn.utils.spectral_norm as spectral_norm\n",
    "\n",
    "class SuperResMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    A Multi-Layer Perceptron (MLP) for brain graph super-resolution.\n",
    "    This model maps a vectorized low-resolution brain connectivity matrix to a high-resolution version.\n",
    "    The vectorization extracts the off-diagonal upper triangular elements from the symmetric adjacency matrices.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_nodes_input: int, num_nodes_output: int, num_hidden_nodes: int, n_layers: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.num_nodes_input = num_nodes_input\n",
    "        self.num_nodes_output = num_nodes_output\n",
    "\n",
    "        # Calculate sizes based on off-diagonal upper triangular elements.\n",
    "        # Using (n * (n - 1)) // 2 instead of (n * (n + 1)) // 2 ensures the diagonal is excluded,\n",
    "        # matching the typical vectorization process for symmetric matrices.\n",
    "        input_size = (num_nodes_input * (num_nodes_input - 1)) // 2\n",
    "        output_size = (num_nodes_output * (num_nodes_output - 1)) // 2\n",
    "        hidden_size = num_hidden_nodes\n",
    "\n",
    "        # Precompute masks for vectorization and anti-vectorization.\n",
    "        # These masks are registered as buffers so they move with the modelâ€™s device.\n",
    "        self.register_buffer(\"input_mask\", torch.triu(torch.ones(num_nodes_input, num_nodes_input), diagonal=1).bool())\n",
    "        self.register_buffer(\"output_mask\", torch.triu(torch.ones(num_nodes_output, num_nodes_output), diagonal=1).bool())\n",
    "\n",
    "        # Input Layer with Spectral Normalization\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1),\n",
    "            spectral_norm(nn.Linear(input_size, hidden_size)),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "        )\n",
    "\n",
    "        # Residual Blocks with Spectral Normalization\n",
    "        self.residual_blocks = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                spectral_norm(nn.Linear(hidden_size, hidden_size)),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.LeakyReLU(negative_slope=0.01)\n",
    "            ) for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "        # Output Layer with Spectral Normalization\n",
    "        self.output_layer = nn.Sequential(\n",
    "            spectral_norm(nn.Linear(hidden_size, output_size)),\n",
    "            nn.Sigmoid(),  # Ensures outputs are in [0, 1]\n",
    "        )\n",
    "\n",
    "        # Apply Xavier Initialization to Linear layers\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Applies Xavier initialization to all Linear layers.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def forward(self, samples: Batch) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "\n",
    "        Args:\n",
    "            samples (Batch): A torch_geometric Batch object containing:\n",
    "                             - edge_index: Graph connectivity in COO format.\n",
    "                             - edge_attr: Optional edge attributes.\n",
    "                             - batch: Batch vector mapping nodes to their respective graphs.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Reconstructed high-resolution symmetric adjacency matrices.\n",
    "        \"\"\"\n",
    "        # Convert the graph to dense adjacency matrices for each sample in the batch.\n",
    "        x = to_dense_adj(samples.edge_index, edge_attr=samples.edge_attr, batch=samples.batch)\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Vectorize the dense matrices by extracting only the off-diagonal upper triangular elements.\n",
    "        x = x[:, self.input_mask]\n",
    "\n",
    "        # Process through the input layer.\n",
    "        x = self.input_layer(x)\n",
    "\n",
    "        # Apply a series of residual blocks with skip connections.\n",
    "        for block in self.residual_blocks:\n",
    "            residual = x\n",
    "            x = block(x)\n",
    "            x = x + residual\n",
    "            x = F.leaky_relu(x, negative_slope=0.01)\n",
    "\n",
    "        # Process through the output layer.\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        # Reconstruct the symmetric high-resolution adjacency matrix from the vectorized output.\n",
    "        matrix = torch.zeros((batch_size, self.num_nodes_output, self.num_nodes_output), device=x.device)\n",
    "        matrix[:, self.output_mask] = x\n",
    "        # Mirror the upper-triangular part to the lower-triangular part.\n",
    "        matrix = matrix + matrix.transpose(1, 2)\n",
    "\n",
    "        return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c15b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch,target_batch = next(iter(train_loaders[0]))\n",
    "input_dim = batch[0].x.shape[0]\n",
    "output_dim = target_batch[0].x.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60478db46877fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "for k in range(k_folds):\n",
    "    model = SuperResMLP(input_dim, output_dim, num_hidden_nodes=(input_dim+output_dim)//2, n_layers=0).to(device)\n",
    "    train_loader = train_loaders[k]\n",
    "    val_loader = val_loaders[k]\n",
    "    train_loss_history, val_loss_history, lr_history, best_model_state_dict = train_model(\n",
    "        model=model, \n",
    "        train_dataloader=train_loader, \n",
    "        val_dataloader=val_loader,\n",
    "        criterion=criterion,\n",
    "        num_epochs=100,\n",
    "    )\n",
    "    evaluate_metrics(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cfee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss = evaluate_model(model, val_loader)\n",
    "print(loss)\n",
    "\n",
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c22f927",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"model.pth\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914e84d0f1dba99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = data_module.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c7a044c71f324",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file = \"outputs/test/submission.csv\"\n",
    "save_prediction(model, test_dataloader, submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f2efd30d9c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab8416213942339",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c dgl-2025-brain-graph-super-resolution-challenge -f outputs/test/submission.csv -m \"test\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
