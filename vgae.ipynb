{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import torch\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from metrics import evaluation_metrics\n",
    "\n",
    "from slim import SLIMDataModule\n",
    "import torch.nn as nn\n",
    "\n",
    "# Instantiate the DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to load ./data/hr_train.csv: 4.84249210357666 seconds\n",
      "Time taken to load ./data/lr_train.csv: 0.6156792640686035 seconds\n",
      "Converting vectors to matrices\n",
      "Converting vectors to matrices\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_module = SLIMDataModule(data_dir=\"./data\", batch_size=1)\n",
    "train_dataloader = data_module.train_dataloader()\n",
    "# Get first batch\n",
    "batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetric_normalize(A_tilde):\n",
    "    \"\"\"\n",
    "    Performs symmetric normalization of A_tilde (Adj. matrix with self loops):\n",
    "      A_norm = D^{-1/2} * A_tilde * D^{-1/2}\n",
    "    Where D_{ii} = sum of row i in A_tilde.\n",
    "\n",
    "    A_tilde (N, N): Adj. matrix with self loops\n",
    "    Returns:\n",
    "      A_norm : (N, N)\n",
    "    \"\"\"\n",
    "\n",
    "    eps = 1e-5\n",
    "    d = A_tilde.sum(dim=1) + eps\n",
    "    D_inv = torch.diag(torch.pow(d, -0.5))\n",
    "    return D_inv @ A_tilde @ D_inv\n",
    "\n",
    "\n",
    "def batch_normalize(batch):\n",
    "    batch_n = torch.zeros_like(batch)\n",
    "    for i, A in enumerate(batch):\n",
    "        batch_n[i] = symmetric_normalize(A + torch.eye(n=A.shape[0]))\n",
    "    return batch_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group[\"lr\"]\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_dataloader: DataLoader,\n",
    "    val_dataloader: DataLoader,\n",
    "    train_node_features=None,\n",
    "    val_node_features=None,\n",
    "    num_epochs=100,\n",
    "    lr=0.01,\n",
    "    validate_every=1,\n",
    "    patience=10,\n",
    "    criterion=None,\n",
    "    intermediate_losses=False,\n",
    "    skip=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the model, validate every 'validate_every' epochs, and pick the\n",
    "    checkpoint with best validation accuracy.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : torch.nn.Module\n",
    "        The PyTorch model to train.\n",
    "    train_dataloader : torch.utils.data.DataLoader\n",
    "        DataLoader for the training set.\n",
    "    val_dataloader : torch.utils.data.DataLoader\n",
    "        DataLoader for the validation set.\n",
    "    num_epochs : int\n",
    "        Number of training epochs.\n",
    "    lr : float\n",
    "        Learning rate for the optimizer.\n",
    "    validate_every : int\n",
    "        Validate (and possibly checkpoint) every 'validate_every' epochs.\n",
    "    patience : int\n",
    "        Patience for learning rate scheduler.\n",
    "    criterion : torch.nn.Module\n",
    "        Loss function.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    best_loss_history : list\n",
    "        The training loss history across epochs.\n",
    "    best_model_state_dict : dict\n",
    "        The state dictionary of the model achieving the best validation accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", patience=patience\n",
    "    )\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    best_val_loss = torch.inf\n",
    "    best_model_state_dict = None\n",
    "    val_loss = 0.0\n",
    "\n",
    "    progress_bar = tqdm(range(num_epochs))\n",
    "    for epoch in progress_bar:\n",
    "        progress_bar.set_description(f\"Epoch {epoch}|{num_epochs}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for i, batch in enumerate(train_dataloader):\n",
    "            inputs, targets = batch\n",
    "            # inputs = batch_normalize(inputs)\n",
    "            inputs = inputs.squeeze(0)\n",
    "            targets = targets.squeeze(0)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            X = train_node_features[i] if train_node_features is not None else None\n",
    "\n",
    "            # Forward pass on training data\n",
    "            outputs, A_hist, A_recon_hist = model.forward(A=inputs, X=X, skip=skip)\n",
    "            loss = criterion(\n",
    "                outputs,\n",
    "                targets.to(model.device),\n",
    "                A_hist,\n",
    "                A_recon_hist,\n",
    "                intermediate_losses=intermediate_losses,\n",
    "            )\n",
    "            loss.backward()\n",
    "\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Record training loss\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(train_dataloader)\n",
    "        train_loss_history.append(avg_loss)\n",
    "\n",
    "        # Validation step\n",
    "        if (epoch + 1) % validate_every == 0 or (epoch + 1) == num_epochs:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for i, batch in enumerate(val_dataloader):\n",
    "                    inputs, targets = batch\n",
    "                    inputs = inputs.squeeze(0)\n",
    "                    targets = targets.squeeze(0)\n",
    "                    X = val_node_features[i] if val_node_features is not None else None\n",
    "                    outputs, A_hist, A_recon_hist = model(A=inputs, X=X, skip=skip)\n",
    "\n",
    "                    val_loss += criterion(\n",
    "                        outputs,\n",
    "                        targets.to(model.device),\n",
    "                        A_hist,\n",
    "                        A_recon_hist,\n",
    "                        intermediate_losses,\n",
    "                    ).item()\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            val_loss_history.append(val_loss)\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "            lr = get_lr(optimizer)\n",
    "\n",
    "            # Check if this is the best f1 score so far\n",
    "            if val_loss > best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_state_dict = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            if lr < 1e-5:\n",
    "                break\n",
    "\n",
    "        progress_bar.set_postfix({\"train_loss\": avg_loss, \"val_loss\": val_loss})\n",
    "\n",
    "    # If we have a best model, load it\n",
    "    if best_model_state_dict is not None:\n",
    "        model.load_state_dict(best_model_state_dict)\n",
    "\n",
    "    return train_loss_history, val_loss_history, best_model_state_dict\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, dataloader):\n",
    "    \"\"\"\n",
    "    Runs forward pass, calculates binary predictions (threshold=0.5),\n",
    "    and returns the accuracy score.\n",
    "    \"\"\"\n",
    "    from metrics import evaluation_metrics\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    true = []\n",
    "    for batch in dataloader:\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.squeeze(0)\n",
    "        targets = targets.squeeze(0)\n",
    "        inputs.to(model.device)\n",
    "        outputs, _, _ = model(inputs)\n",
    "        preds.append(outputs.detach().cpu().numpy())\n",
    "        true.append(targets.detach().cpu().numpy())\n",
    "\n",
    "    batch_metrics = evaluation_metrics(preds, true)\n",
    "\n",
    "    return batch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting it all together - code taken from https://github.com/HongyangGao/Graph-U-Nets/tree/master\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def reconstruct_adjacency(X, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Reconstruct adjacency from node embeddings while preserving fMRI-like structure.\n",
    "\n",
    "    Args:\n",
    "        X (torch.Tensor): Node embeddings of shape [num_nodes, hidden_dim]\n",
    "        threshold (float): Value below which edges are removed for sparsity\n",
    "\n",
    "    Returns:\n",
    "        adj (torch.Tensor): Reconstructed weighted adjacency matrix\n",
    "    \"\"\"\n",
    "    X_norm = X\n",
    "    # Compute cosine similarity matrix\n",
    "    adj = F.relu(X_norm @ X_norm.T)  # Values in range [-1, 1]\n",
    "\n",
    "    # adj = torch.sigmoid(adj)\n",
    "\n",
    "    # Apply sparsification: Keep only values above threshold\n",
    "    # adj = torch.where(adj > threshold, adj, torch.zeros_like(adj))\n",
    "\n",
    "    return adj\n",
    "\n",
    "\n",
    "class GraphUpsampler(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim,\n",
    "        hidden_dim,\n",
    "        n_nodes,\n",
    "        m_nodes,\n",
    "        act,\n",
    "        drop_p,\n",
    "        num_iterations=1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - in_dim: Input node feature dimension\n",
    "        - hidden_dim: Hidden dimension for message passing\n",
    "        - num_iterations: Number of iterative updates\n",
    "        - upsample_factor: Factor by which to increase node count\n",
    "        \"\"\"\n",
    "        super(GraphUpsampler, self).__init__()\n",
    "        self.num_iterations = num_iterations\n",
    "        self.n_nodes = n_nodes\n",
    "        self.m_nodes = m_nodes\n",
    "\n",
    "        # Message passing layers\n",
    "        self.conv1 = GCN(in_dim, hidden_dim, act, drop_p)\n",
    "        self.conv2 = GCN(hidden_dim, hidden_dim, act, drop_p)\n",
    "\n",
    "        # MLP for new node generation\n",
    "        self.upsample_mlp = nn.Linear(n_nodes, m_nodes)\n",
    "\n",
    "    def forward(self, X, A, refine=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - x: Node features [num_nodes, in_dim]\n",
    "        - adj_matrix: Initial adjacency matrix [num_nodes, num_nodes]\n",
    "\n",
    "        Returns:\n",
    "        - Upsampled adjacency matrix [self.m_nodes, self.m_nodes]\n",
    "        - Upsampled node features [new_num_nodes, in_dim]\n",
    "        \"\"\"\n",
    "\n",
    "        # Generate new nodes by transforming existing ones\n",
    "        X_upsampled = torch.sigmoid(self.upsample_mlp(X.T).T)  # [num_nodes, in_dim]\n",
    "        # Concatenate old and new nodes\n",
    "        # X_upsampled = torch.cat([X, new_nodes], dim=0)\n",
    "\n",
    "        A_upsampled = reconstruct_adjacency(X=X_upsampled)\n",
    "\n",
    "        # print(\"Mean : \", A_upsampled.mean().item(), \"Std :\", A_upsampled.std().item())\n",
    "\n",
    "        # Message passing to refine embeddings\n",
    "        if refine:\n",
    "            for _ in range(self.num_iterations):\n",
    "                X_upsampled = self.conv1(A_upsampled, X_upsampled)\n",
    "                X_upsampled = F.relu(X_upsampled)\n",
    "                A_upsampled = reconstruct_adjacency(X_upsampled)\n",
    "\n",
    "                X_upsampled = self.conv2(A_upsampled, X_upsampled)\n",
    "                X_upsampled = F.relu(X_upsampled)\n",
    "\n",
    "                # Reconstruct adjacency with updated embeddings\n",
    "                A_upsampled = reconstruct_adjacency(A_upsampled)\n",
    "\n",
    "        return A_upsampled\n",
    "\n",
    "\n",
    "class GraphUnet(nn.Module):\n",
    "\n",
    "    def __init__(self, ks, n_nodes, m_nodes, dim, act, drop_p):\n",
    "        super(GraphUnet, self).__init__()\n",
    "        self.ks = ks\n",
    "        self.dim = dim\n",
    "\n",
    "        self.down_gcns = nn.ModuleList()\n",
    "        self.up_gcns = nn.ModuleList()\n",
    "        self.pools = nn.ModuleList()\n",
    "        self.unpools = nn.ModuleList()\n",
    "        self.upsampler = GraphUpsampler(\n",
    "            in_dim=dim,\n",
    "            hidden_dim=dim,\n",
    "            n_nodes=n_nodes,\n",
    "            m_nodes=m_nodes,\n",
    "            act=act,\n",
    "            drop_p=drop_p,\n",
    "        )\n",
    "        self.l_n = len(ks)\n",
    "        for k in ks:\n",
    "            # out_dim = dim\n",
    "            out_dim = int(dim / k)\n",
    "            self.down_gcns.append(GCN(dim, out_dim, act, drop_p))\n",
    "            self.up_gcns.append(GCN(out_dim, dim, act, drop_p))\n",
    "            self.pools.append(Pool(k, out_dim, drop_p))\n",
    "            self.unpools.append(Unpool(dim, dim, drop_p))\n",
    "            dim = out_dim\n",
    "\n",
    "        self.up_gcns = self.up_gcns[::-1]\n",
    "        # self.node_features = nn.Parameter(torch.randn(n_nodes, dim))\n",
    "        self.bottom_gcn = GCN(dim, dim, act, drop_p)\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def build_batch_features(\n",
    "        self, batch: list[torch.Tensor], n_jobs: int = 1\n",
    "    ) -> torch.Tensor:\n",
    "        # Build batch features using topological information\n",
    "        from joblib import Parallel, delayed\n",
    "\n",
    "        # Use the build_node_features function to build features for each graph in the batch\n",
    "        features = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(self.build_node_features)(adjacency) for adjacency in batch\n",
    "        )\n",
    "        return torch.stack(features, dim=0)\n",
    "\n",
    "    def build_node_features(self, adjacency: torch.Tensor) -> torch.Tensor:\n",
    "        # Build node features using topological information\n",
    "\n",
    "        # Compute degree matrix\n",
    "        D = torch.diag(torch.sum(adjacency, dim=1)).cpu()\n",
    "\n",
    "        # Compute Node betweenness centrality\n",
    "        G = nx.from_numpy_array(adjacency.cpu().numpy())\n",
    "        betweenness = torch.tensor(\n",
    "            list(nx.betweenness_centrality(G).values()), dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        # Compute Node closeness centrality\n",
    "        closeness = torch.tensor(\n",
    "            list(nx.closeness_centrality(G).values()), dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        # Compute Node clustering coefficient\n",
    "        clustering = torch.tensor(list(nx.clustering(G).values()), dtype=torch.float32)\n",
    "\n",
    "        # Compute eigenvector centrality\n",
    "        eigenvector = torch.tensor(\n",
    "            list(nx.eigenvector_centrality(G).values()), dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        # Compute Laplacian eigenvecs\n",
    "        eigvals, eigvecs = torch.linalg.eigh(D - adjacency.cpu())\n",
    "        laplacian_eigenvecs = eigvecs[:, 1 : self.dim - 3]\n",
    "\n",
    "        # Concatenate all features\n",
    "        node_features = torch.stack(\n",
    "            [betweenness, closeness, clustering, eigenvector], dim=1\n",
    "        )\n",
    "        # Include Laplacian eigenvecs\n",
    "        node_features = torch.cat([node_features, laplacian_eigenvecs], dim=1)\n",
    "\n",
    "        return node_features\n",
    "\n",
    "    def forward(\n",
    "        self, A: torch.Tensor, skip: bool = False, threshold: float = -1, X=None\n",
    "    ):\n",
    "        # Process A\n",
    "        if threshold > 0:\n",
    "            A = torch.where(A > threshold, A, torch.zeros_like(A))\n",
    "        A = A + torch.eye(A.shape[0])\n",
    "        A = symmetric_normalize(A)\n",
    "        A = A.to(self.device)\n",
    "\n",
    "        if X is None:\n",
    "            X = torch.randn(A.shape[0], self.dim, device=self.device)\n",
    "        else:\n",
    "            X = X.to(self.device)\n",
    "\n",
    "        A_history = []\n",
    "        A_recon_history = []\n",
    "        indices_list = []\n",
    "        down_outs = []\n",
    "        org_A = A.clone()\n",
    "        if skip:\n",
    "            org_X = X.clone()\n",
    "        for i in range(self.l_n):\n",
    "            X = self.down_gcns[i](A, X)\n",
    "            A_history.append(A)\n",
    "            down_outs.append(X)\n",
    "            A, X, idx = self.pools[i](A, X)\n",
    "            indices_list.append(idx)\n",
    "\n",
    "        X = self.bottom_gcn(A, X)\n",
    "        for i in range(self.l_n):\n",
    "            up_idx = self.l_n - i - 1\n",
    "            A, idx = A_history[up_idx], indices_list[up_idx]\n",
    "            A, X = self.unpools[i](A, X, down_outs[up_idx], idx)\n",
    "            X = self.up_gcns[i](A, X)\n",
    "\n",
    "            A_recon = reconstruct_adjacency(X)\n",
    "            A_recon_history.append(A_recon)\n",
    "            if skip:\n",
    "\n",
    "                X = X.add(down_outs[up_idx])\n",
    "\n",
    "        if skip:\n",
    "            X = X.add(org_X)\n",
    "\n",
    "        A_upsampled = self.upsampler.forward(X, org_A)\n",
    "\n",
    "        return A_upsampled, A_history, A_recon_history\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, out_dim, act, p):\n",
    "        super(GCN, self).__init__()\n",
    "        self.proj = nn.Linear(in_dim, out_dim, bias=False)\n",
    "        self.act = act\n",
    "        self.drop = nn.Dropout(p=p) if p > 0.0 else nn.Identity()\n",
    "\n",
    "    def forward(self, A, X):\n",
    "        X = self.drop(X)  # they have added dropout\n",
    "        X = torch.matmul(A, X)\n",
    "        X = self.proj(X)\n",
    "        X = self.act(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "class Pool(nn.Module):\n",
    "\n",
    "    def __init__(self, k, in_dim, p):\n",
    "        super(Pool, self).__init__()\n",
    "        self.k = k\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.proj = nn.Linear(in_dim, 1)\n",
    "        self.drop = nn.Dropout(p=p) if p > 0 else nn.Identity()  # added dropout here\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        Z = self.drop(h)\n",
    "        weights = self.proj(Z).squeeze()\n",
    "        scores = self.sigmoid(weights)\n",
    "        return top_k_graph(scores, g, h, self.k)\n",
    "\n",
    "\n",
    "class Unpool(nn.Module):\n",
    "\n",
    "    def __init__(self, *args):\n",
    "        super(Unpool, self).__init__()\n",
    "\n",
    "    def forward(self, A, X, pre_h, idx):\n",
    "        new_h = X.new_zeros([A.shape[0], X.shape[1]])\n",
    "        new_h[idx] = X\n",
    "        return A, new_h\n",
    "\n",
    "\n",
    "def top_k_graph(scores, A, X, k):\n",
    "    num_nodes = A.shape[0]\n",
    "    values, idx = torch.topk(\n",
    "        scores, max(2, int(k * num_nodes))\n",
    "    )  # make sure k works based on number of current nodes\n",
    "    X_pooled = X[idx, :]\n",
    "    values = torch.unsqueeze(values, -1)\n",
    "    X_pooled = torch.mul(X_pooled, values)\n",
    "    A_treshold = torch.where(A > 0.10, torch.ones_like(A), torch.zeros_like(A))\n",
    "    A_pooled = A_treshold.bool().float()\n",
    "    A_pooled = (\n",
    "        torch.matmul(A_pooled, A_pooled).bool().float()\n",
    "    )  # second power to reduce chance of isolated nodes\n",
    "    A_pooled = A[idx, :]\n",
    "    A_pooled = A_pooled[:, idx]\n",
    "    A_pooled = symmetric_normalize(A_pooled)\n",
    "    return A_pooled, X_pooled, idx\n",
    "\n",
    "\n",
    "def symmetric_normalize(A_tilde):\n",
    "    \"\"\"\n",
    "    Performs symmetric normalization of A_tilde (Adj. matrix with self loops):\n",
    "      A_norm = D^{-1/2} * A_tilde * D^{-1/2}\n",
    "    Where D_{ii} = sum of row i in A_tilde.\n",
    "\n",
    "    A_tilde (N, N): Adj. matrix with self loops\n",
    "    Returns:\n",
    "      A_norm : (N, N)\n",
    "    \"\"\"\n",
    "\n",
    "    eps = 1e-5\n",
    "    d = A_tilde.sum(dim=1) + eps\n",
    "    D_inv = torch.diag(torch.pow(d, -0.5))\n",
    "    return D_inv @ A_tilde @ D_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(\n",
    "    A_true, A_pred, A_hist=None, A_recon_hist=None, intermediate_losses: bool = False\n",
    "):\n",
    "    loss = F.mse_loss(A_true, A_pred)\n",
    "    if intermediate_losses:\n",
    "        i = 1\n",
    "        for A, A_recon in zip(A_hist, A_recon_hist[::-1]):\n",
    "            loss += F.mse_loss(A, A_recon)\n",
    "            i += 1\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphUnet(\n",
       "  (down_gcns): ModuleList(\n",
       "    (0): GCN(\n",
       "      (proj): Linear(in_features=15, out_features=20, bias=False)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): GCN(\n",
       "      (proj): Linear(in_features=20, out_features=26, bias=False)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): GCN(\n",
       "      (proj): Linear(in_features=26, out_features=34, bias=False)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (up_gcns): ModuleList(\n",
       "    (0): GCN(\n",
       "      (proj): Linear(in_features=34, out_features=26, bias=False)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): GCN(\n",
       "      (proj): Linear(in_features=26, out_features=20, bias=False)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): GCN(\n",
       "      (proj): Linear(in_features=20, out_features=15, bias=False)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (pools): ModuleList(\n",
       "    (0): Pool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=20, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): Pool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=26, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): Pool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=34, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (unpools): ModuleList(\n",
       "    (0-2): 3 x Unpool()\n",
       "  )\n",
       "  (upsampler): GraphUpsampler(\n",
       "    (conv1): GCN(\n",
       "      (proj): Linear(in_features=15, out_features=15, bias=False)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv2): GCN(\n",
       "      (proj): Linear(in_features=15, out_features=15, bias=False)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (upsample_mlp): Linear(in_features=160, out_features=268, bias=True)\n",
       "  )\n",
       "  (bottom_gcn): GCN(\n",
       "    (proj): Linear(in_features=34, out_features=34, bias=False)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model, loss function, and optimizer\n",
    "\n",
    "# Clear CUDA cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Define the model\n",
    "in_dim = batch[0].shape[1]\n",
    "out_dim = batch[1].shape[1]\n",
    "dim = 15\n",
    "model = GraphUnet(\n",
    "    ks=[\n",
    "        0.75,\n",
    "        0.75,\n",
    "        0.75,\n",
    "    ],\n",
    "    n_nodes=in_dim,\n",
    "    m_nodes=out_dim,\n",
    "    dim=dim,\n",
    "    act=torch.relu,\n",
    "    drop_p=0.1,\n",
    ")\n",
    "model.to(torch.device(\"cuda:2\"))\n",
    "# model.load_state_dict(torch.load(\"unet-26-02.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing train node features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/133 [00:02<01:25,  1.50it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing train node features...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m train_node_features \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_node_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m A \u001b[38;5;129;01min\u001b[39;00m tqdm(data_module\u001b[38;5;241m.\u001b[39mtrain_dataloader())\n\u001b[1;32m      5\u001b[0m ]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing val node features...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m val_node_features \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     model\u001b[38;5;241m.\u001b[39mbuild_node_features(A[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m A \u001b[38;5;129;01min\u001b[39;00m tqdm(data_module\u001b[38;5;241m.\u001b[39mval_dataloader())\n\u001b[1;32m     11\u001b[0m ]\n",
      "Cell \u001b[0;32mIn[51], line 160\u001b[0m, in \u001b[0;36mGraphUnet.build_node_features\u001b[0;34m(self, adjacency)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# Compute Node betweenness centrality\u001b[39;00m\n\u001b[1;32m    158\u001b[0m G \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mfrom_numpy_array(adjacency\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m    159\u001b[0m betweenness \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28mlist\u001b[39m(\u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbetweenness_centrality\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues()), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[1;32m    161\u001b[0m )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# Compute Node closeness centrality\u001b[39;00m\n\u001b[1;32m    164\u001b[0m closeness \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28mlist\u001b[39m(nx\u001b[38;5;241m.\u001b[39mcloseness_centrality(G)\u001b[38;5;241m.\u001b[39mvalues()), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[1;32m    166\u001b[0m )\n",
      "File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 17:4\u001b[0m, in \u001b[0;36margmap_betweenness_centrality_13\u001b[0;34m(G, k, normalized, weight, endpoints, seed, backend, **backend_kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/networkx/utils/backends.py:967\u001b[0m, in \u001b[0;36m_dispatchable.__call__\u001b[0;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m backend \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnetworkx\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    966\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m backend is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morig_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;66;03m# Use `backend_name` in this function instead of `backend`.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# This is purely for aesthetics and to make it easier to search for this\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# variable since \"backend\" is used in many comments and log/error messages.\u001b[39;00m\n\u001b[1;32m    972\u001b[0m backend_name \u001b[38;5;241m=\u001b[39m backend\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/networkx/algorithms/centrality/betweenness.py:137\u001b[0m, in \u001b[0;36mbetweenness_centrality\u001b[0;34m(G, k, normalized, weight, endpoints, seed)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m nodes:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# single source shortest paths\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# use BFS\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m         S, P, sigma, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_single_source_shortest_path_basic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# use Dijkstra's algorithm\u001b[39;00m\n\u001b[1;32m    139\u001b[0m         S, P, sigma, _ \u001b[38;5;241m=\u001b[39m _single_source_dijkstra_path_basic(G, s, weight)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/networkx/algorithms/centrality/betweenness.py:275\u001b[0m, in \u001b[0;36m_single_source_shortest_path_basic\u001b[0;34m(G, s)\u001b[0m\n\u001b[1;32m    273\u001b[0m     Q\u001b[38;5;241m.\u001b[39mappend(w)\n\u001b[1;32m    274\u001b[0m     D[w] \u001b[38;5;241m=\u001b[39m Dv \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m D[w] \u001b[38;5;241m==\u001b[39m Dv \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# this is a shortest path, count paths\u001b[39;00m\n\u001b[1;32m    276\u001b[0m     sigma[w] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sigmav\n\u001b[1;32m    277\u001b[0m     P[w]\u001b[38;5;241m.\u001b[39mappend(v)  \u001b[38;5;66;03m# predecessors\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Computing train node features...\")\n",
    "train_node_features = [\n",
    "    model.build_node_features(A[0].squeeze(0))\n",
    "    for A in tqdm(data_module.train_dataloader())\n",
    "]\n",
    "\n",
    "print(\"Computing val node features...\")\n",
    "val_node_features = [\n",
    "    model.build_node_features(A[0].squeeze(0))\n",
    "    for A in tqdm(data_module.val_dataloader())\n",
    "]\n",
    "\n",
    "from slim import create_test_dataloader\n",
    "\n",
    "test_dataloader = create_test_dataloader(data_dir=\"./data\", batch_size=1)\n",
    "X_val = [model.build_node_features(A[0].squeeze(0)) for A in tqdm(test_dataloader)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 166|200:  83%|████████▎ | 166/200 [08:41<01:46,  3.14s/it, train_loss=0.0397, val_loss=0.0412]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_losses, val_losses, _ = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=data_module.train_dataloader(),\n",
    "    val_dataloader=data_module.val_dataloader(),\n",
    "    train_node_features=train_node_features,\n",
    "    val_node_features=val_node_features,\n",
    "    num_epochs=200,\n",
    "    lr=3e-4,\n",
    "    validate_every=1,\n",
    "    patience=5,\n",
    "    criterion=criterion,\n",
    "    intermediate_losses=True,\n",
    "    skip=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_losses, val_losses, title=\"Losses\", log: bool = False):\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label=\"Train Loss\")\n",
    "    plt.plot(val_losses, label=\"Val Loss\")\n",
    "    if log:\n",
    "        plt.yscale(\"log\")\n",
    "        plt.ylabel(\"Loss (logscale)\")\n",
    "    else:\n",
    "        plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(\n",
    "    train_losses=train_losses,\n",
    "    val_losses=val_losses,\n",
    "    log=True,\n",
    "    title=\"Losses (UNet, 3 down, 3 up, hidden dim 15)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MatrixVectorizer import MatrixVectorizer\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "def evaluation_metrics(pred, true, print: bool = False, n_jobs=1):\n",
    "\n",
    "    def compute_metrics(i):\n",
    "        # Convert adjacency matrices to NetworkX graphs\n",
    "        pred_graph = nx.from_numpy_array(pred[i], edge_attr=\"weight\")\n",
    "        gt_graph = nx.from_numpy_array(true[i], edge_attr=\"weight\")\n",
    "\n",
    "        # Compute centrality measures\n",
    "        pred_bc = nx.betweenness_centrality(pred_graph, weight=\"weight\")\n",
    "        pred_ec = nx.eigenvector_centrality(pred_graph, weight=\"weight\")\n",
    "        pred_pc = nx.pagerank(pred_graph, weight=\"weight\")\n",
    "\n",
    "        gt_bc = nx.betweenness_centrality(gt_graph, weight=\"weight\")\n",
    "        gt_ec = nx.eigenvector_centrality(gt_graph, weight=\"weight\")\n",
    "        gt_pc = nx.pagerank(gt_graph, weight=\"weight\")\n",
    "\n",
    "        # Convert centrality dictionaries to lists\n",
    "        pred_bc_values = list(pred_bc.values())\n",
    "        pred_ec_values = list(pred_ec.values())\n",
    "        pred_pc_values = list(pred_pc.values())\n",
    "\n",
    "        gt_bc_values = list(gt_bc.values())\n",
    "        gt_ec_values = list(gt_ec.values())\n",
    "        gt_pc_values = list(gt_pc.values())\n",
    "\n",
    "        # Compute MAEs\n",
    "        mae_bc = mean_absolute_error(pred_bc_values, gt_bc_values)\n",
    "        mae_ec = mean_absolute_error(pred_ec_values, gt_ec_values)\n",
    "        mae_pc = mean_absolute_error(pred_pc_values, gt_pc_values)\n",
    "\n",
    "        # Vectorize matrices\n",
    "        pred_1d = MatrixVectorizer.vectorize(pred[i])\n",
    "        gt_1d = MatrixVectorizer.vectorize(true[i])\n",
    "\n",
    "        return mae_bc, mae_ec, mae_pc, pred_1d, gt_1d\n",
    "\n",
    "    mae_bc = []\n",
    "    mae_ec = []\n",
    "    mae_pc = []\n",
    "\n",
    "    pred_1d_list = []\n",
    "    gt_1d_list = []\n",
    "\n",
    "    num_test_samples = len(pred)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=n_jobs) as executor:\n",
    "        results = list(executor.map(compute_metrics, range(num_test_samples)))\n",
    "\n",
    "    for result in results:\n",
    "        mae_bc.append(result[0])\n",
    "        mae_ec.append(result[1])\n",
    "        mae_pc.append(result[2])\n",
    "        pred_1d_list.append(result[3])\n",
    "        gt_1d_list.append(result[4])\n",
    "\n",
    "    # Compute average MAEs\n",
    "    avg_mae_bc = sum(mae_bc) / len(mae_bc)\n",
    "    avg_mae_ec = sum(mae_ec) / len(mae_ec)\n",
    "    avg_mae_pc = sum(mae_pc) / len(mae_pc)\n",
    "\n",
    "    # Concatenate flattened matrices\n",
    "    pred_1d = np.concatenate(pred_1d_list)\n",
    "    gt_1d = np.concatenate(gt_1d_list)\n",
    "\n",
    "    # Compute metrics\n",
    "    mae = mean_absolute_error(pred_1d, gt_1d)\n",
    "    pcc = pearsonr(pred_1d, gt_1d)[0]\n",
    "    js_dis = jensenshannon(pred_1d, gt_1d)\n",
    "\n",
    "    if print:\n",
    "        print(\"MAE: \", mae)\n",
    "        print(\"PCC: \", pcc)\n",
    "        print(\"Jensen-Shannon Distance: \", js_dis)\n",
    "        print(\"Average MAE betweenness centrality:\", avg_mae_bc)\n",
    "        print(\"Average MAE eigenvector centrality:\", avg_mae_ec)\n",
    "        print(\"Average MAE PageRank centrality:\", avg_mae_pc)\n",
    "\n",
    "    return {\n",
    "        \"mae\": mae,\n",
    "        \"pcc\": pcc,\n",
    "        \"js_dis\": js_dis,\n",
    "        \"avg_mae_bc\": avg_mae_bc,\n",
    "        \"avg_mae_ec\": avg_mae_ec,\n",
    "        \"avg_mae_pc\": avg_mae_pc,\n",
    "    }\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, dataloader, X_val=None, n_jobs=1):\n",
    "    \"\"\"\n",
    "    Runs forward pass, calculates binary predictions (threshold=0.5),\n",
    "    and returns the accuracy score.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    true = []\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    progress_bar.set_description(\"Evaluating...\")\n",
    "    for i, batch in progress_bar:\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.squeeze(0)\n",
    "        targets = targets.squeeze(0)\n",
    "        inputs.to(model.device)\n",
    "        if X_val is not None:\n",
    "            X = X_val[i]\n",
    "        else:\n",
    "            X = None\n",
    "        outputs, _, _ = model(A=inputs, X=X)\n",
    "        preds.append(outputs.detach().cpu().numpy())\n",
    "        true.append(targets.detach().cpu().numpy())\n",
    "\n",
    "    batch_metrics = evaluation_metrics(preds, true, n_jobs=n_jobs)\n",
    "    # Convert to python float\n",
    "    batch_metrics = {k: float(v) for k, v in batch_metrics.items()}\n",
    "\n",
    "    return batch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|██████████| 34/34 [00:00<00:00, 129.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae': 0.16439081728458405, 'pcc': 0.47462210059165955, 'js_dis': 0.3106870651245117, 'avg_mae_bc': 0.018905860180731697, 'avg_mae_ec': 0.013103879869223584, 'avg_mae_pc': 0.0005575910534142903}\n"
     ]
    }
   ],
   "source": [
    "## Evaluation metrics\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "\n",
    "eval_metrics = evaluate_model(\n",
    "    model,\n",
    "    data_module.val_dataloader(),\n",
    "    X_val=val_node_features,\n",
    ")\n",
    "\n",
    "print(eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"outputs/unet/eval_metrics-27-02.json\", \"w\") as f:\n",
    "    json.dump({k: float(v) for k, v in eval_metrics.items()}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MatrixVectorizer import MatrixVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, dataloader, X_test=None):\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    progress_bar.set_description(\"Predicting...\")\n",
    "    for i, batch in progress_bar:\n",
    "\n",
    "        inputs = batch.squeeze(0)\n",
    "        inputs.to(model.device)\n",
    "        X = X_test[i] if X_test is not None else None\n",
    "        outputs, _, _ = model(inputs, X=X)\n",
    "        preds.append(outputs.detach().cpu().numpy())\n",
    "\n",
    "    # Vectorize matrices\n",
    "    preds = [MatrixVectorizer.vectorize(p) for p in preds]\n",
    "    preds = np.array(preds)\n",
    "\n",
    "    # Submission format\n",
    "    print(preds.shape)\n",
    "    submission_df = pd.DataFrame(\n",
    "        {\"ID\": range(1, len(preds.flatten()) + 1), \"Predicted\": preds.flatten()}\n",
    "    )\n",
    "    submission_df.to_csv(\"outputs/unet/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 112/112 [00:00<00:00, 167.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 35778)\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import slim\n",
    "\n",
    "importlib.reload(slim)\n",
    "\n",
    "\n",
    "predict(model, test_dataloader, X_test=X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.428091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.548489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.511098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.312395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.287518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007131</th>\n",
       "      <td>4007132</td>\n",
       "      <td>0.151048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007132</th>\n",
       "      <td>4007133</td>\n",
       "      <td>0.075221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007133</th>\n",
       "      <td>4007134</td>\n",
       "      <td>0.141444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007134</th>\n",
       "      <td>4007135</td>\n",
       "      <td>0.055945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007135</th>\n",
       "      <td>4007136</td>\n",
       "      <td>0.090916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4007136 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID  Predicted\n",
       "0              1   0.428091\n",
       "1              2   0.548489\n",
       "2              3   0.511098\n",
       "3              4   0.312395\n",
       "4              5   0.287518\n",
       "...          ...        ...\n",
       "4007131  4007132   0.151048\n",
       "4007132  4007133   0.075221\n",
       "4007133  4007134   0.141444\n",
       "4007134  4007135   0.055945\n",
       "4007135  4007136   0.090916\n",
       "\n",
       "[4007136 rows x 2 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"outputs/unet/submission.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 70.7M/70.7M [00:02<00:00, 27.8MB/s]\n",
      "Successfully submitted to DGL 2025: Brain Graph Super-Resolution Challenge"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c dgl-2025-brain-graph-super-resolution-challenge -f outputs/unet/submission.csv -m \"UNet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"outputs/unet/unet-27-02.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
